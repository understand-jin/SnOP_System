import streamlit as st
import pandas as pd
from datetime import datetime, timedelta
import matplotlib.pyplot as plt
import seaborn as sns
import matplotlib.font_manager as fm
import os
import plotly.express as px
import matplotlib.ticker as ticker
import plotly.graph_objects as go
import math
import numpy as np
from pathlib import Path
import re
from utils import get_stock_csv_path, save_stock_csv, load_stock_csv

# âœ… í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="Stock Data Analysis", layout="wide")

# --- [ì¶”ê°€] ì»¤ìŠ¤í…€ CSS (í”„ë¦¬ë¯¸ì—„ UI ìŠ¤íƒ€ì¼ë§) ---
st.markdown("""
<style>
    /* ì „ì²´ ë°°ê²½ ë° í°íŠ¸ ì„¤ì • */
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap');
    
    .main {
        background-color: #f8f9fa;
    }
    
    /* ì¹´ë“œí˜• ì»¨í…Œì´ë„ˆ ìŠ¤íƒ€ì¼ */
    .stContainer {
        background-color: #ffffff;
        padding: 2rem;
        border-radius: 12px;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.05);
        margin-bottom: 1.5rem;
        border: 1px solid #e9ecef;
    }
    
    /* ì œëª© ìŠ¤íƒ€ì¼ */
    .main-title {
        font-family: 'Inter', sans-serif;
        color: #1e293b;
        font-weight: 700;
        font-size: 2.5rem;
        margin-bottom: 0.5rem;
    }
    
    .sub-title {
        color: #64748b;
        font-size: 1.1rem;
        margin-bottom: 2rem;
    }
    
    /* ë©”íŠ¸ë¦­ ë°•ìŠ¤ ìŠ¤íƒ€ì¼ */
    [data-testid="stMetric"] {
        border: 1px solid #e9ecef;
        padding: 15px 20px;
        border-radius: 12px;
        background-color: #ffffff;
        box-shadow: 0 2px 4px rgba(0,0,0,0.02);
    }

    [data-testid="stMetricValue"] {
        font-size: 1.8rem;
        font-weight: 700;
        color: #0f172a;
    }
    
    [data-testid="stMetricLabel"] {
        font-size: 0.9rem;
        color: #64748b;
        font-weight: 600;
    }

    /* íƒ­ ìŠ¤íƒ€ì¼ ê°œì„  */
    .stTabs [data-baseweb="tab-list"] {
        gap: 8px;
        background-color: transparent;
    }

    .stTabs [data-baseweb="tab"] {
        height: 45px;
        white-space: pre-wrap;
        background-color: #f1f5f9;
        border-radius: 8px 8px 0px 0px;
        color: #475569;
        font-weight: 600;
        padding: 10px 20px;
    }

    .stTabs [aria-selected="true"] {
        background-color: #ffffff !important;
        color: #2563eb !important;
        border-bottom: 2px solid #2563eb !important;
    }
</style>
""", unsafe_allow_html=True)

with st.container():
    st.markdown('<h1 class="main-title">ğŸ“ˆ Stock Data Analysis</h1>', unsafe_allow_html=True)
    st.markdown('<p class="sub-title">ì¬ê³  í˜„í™© ë° ìœ íš¨ê¸°í•œ ë¦¬ìŠ¤í¬ ì‹¬ì¸µ ë¶„ì„ ëŒ€ì‹œë³´ë“œ</p>', unsafe_allow_html=True)

# âœ… ìƒìˆ˜ ì„¤ì • (ê¸°ë³¸ ìœ ì§€)
PRICE_DF_KEY = "1. ê²°ì‚° ì¬ê³ ìˆ˜ë¶ˆë¶€(ì›ê°€).xls"
STOCK_DF_KEY = "2. ë°°ì¹˜ ì¬ê³ ìˆ˜ë¶ˆë¶€(ë°°ì¹˜).xls"
EXPIRY_DF_KEY = "3. ì°½ê³ ë³„ ì¬ê³ í˜„í™©(ìœ íš¨ê¸°í•œ)_1.19.xls"
SALES_DF_KEY = "5. 3ê°œì›” ë§¤ì¶œ(ìì¬ë³„).xls"
CLASSIFICATION_DF_KEY = "ëŒ€ë¶„ë¥˜_ì†Œë¶„ë¥˜_Sheet1.xlsx"

BATCH_COL, MAT_COL, MAT_NAME_COL = "ë°°ì¹˜", "ìì¬", "ìì¬ ë‚´ì—­"
EXPIRY_COL, QTY_SRC_COL, UNIT_COST_COL = "ìœ íš¨ ê¸°í•œ", "Stock Quantity on Period End", "ë‹¨ìœ„ì›ê°€"
VALUE_COL, BUCKET_COL, DAYS_COL = "Stock Value on Period End", "expiry_bucket", "days_to_expiry"

# âœ… í™˜ê²½ ì„¤ì • (í°íŠ¸ ë“±)
def set_korean_font():
    # ê²½ë¡œ ì„¤ì •ì€ ì‚¬ìš©ì í™˜ê²½ì— ë§ì¶° ì¡°ì • í•„ìš”
    font_path = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "assets", "fonts", "NanumGothic-Regular.ttf"))
    if os.path.exists(font_path):
        fm.fontManager.addfont(font_path)
        plt.rcParams["font.family"] = fm.FontProperties(fname=font_path).get_name()
    else:
        plt.rcParams["font.family"] = "Malgun Gothic"
    plt.rcParams["axes.unicode_minus"] = False

set_korean_font()
sns.set_theme(style="whitegrid", font=plt.rcParams["font.family"])

def normalize_mat_code(x):
    # ìˆ«ìì²˜ëŸ¼ ìƒê¸´ ê±´ ì •ìˆ˜ë¡œ ë°”ê¿¨ë‹¤ê°€ ë¬¸ìì—´í™” (123.0 -> "123")
    # ë¬¸ì ì„ì¸ ê±´ ê·¸ëŒ€ë¡œ ë¬¸ìì—´
    s = str(x).strip()
    try:
        # 123.0, 123 ê°™ì€ ì¼€ì´ìŠ¤ í†µì¼
        return str(int(float(s)))
    except:
        return s

# âœ… ë°ì´í„° ì²˜ë¦¬ í•¨ìˆ˜ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
def to_numeric_safe(s): return pd.to_numeric(s, errors="coerce").fillna(0)


def build_final_df(dfs_dict, year_str, month_str):
    # 1. í•„ìˆ˜ íŒŒì¼ ì¡´ì¬ í™•ì¸ (ë§¤ì¶œ íŒŒì¼ í¬í•¨ 4ê°œ)
    required_keys = [PRICE_DF_KEY, STOCK_DF_KEY, EXPIRY_DF_KEY, SALES_DF_KEY]
    for key in required_keys:
        if key not in dfs_dict:
            st.error(f"âŒ '{year_str} {month_str}' í´ë”ì— í•„ìˆ˜ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {key}")
            st.stop()
            
    # --- [Step 1] ë‹¨ìœ„ì›ê°€ ê³„ì‚° (1ë²ˆ íŒŒì¼ í™œìš©) ---
    df_price = dfs_dict[PRICE_DF_KEY]
    tmp = df_price[[MAT_COL, "ê¸°ë§(ìˆ˜ëŸ‰)", "ê¸°ë§(ê¸ˆì•¡)í•©ê³„"]].copy()
    tmp["ê¸°ë§(ìˆ˜ëŸ‰)"] = to_numeric_safe(tmp["ê¸°ë§(ìˆ˜ëŸ‰)"])
    tmp["ê¸°ë§(ê¸ˆì•¡)í•©ê³„"] = to_numeric_safe(tmp["ê¸°ë§(ê¸ˆì•¡)í•©ê³„"])
    unit_cost_df = tmp.groupby(MAT_COL, as_index=False).sum()
    unit_cost_df[UNIT_COST_COL] = unit_cost_df.apply(
        lambda r: r["ê¸°ë§(ê¸ˆì•¡)í•©ê³„"] / r["ê¸°ë§(ìˆ˜ëŸ‰)"] if r["ê¸°ë§(ìˆ˜ëŸ‰)"] > 0 else 0, axis=1
    )

    # --- [Step 1-ì¶”ê°€] ëŒ€ë¶„ë¥˜/ì†Œë¶„ë¥˜ ë§¤í•‘ ë¶™ì´ê¸° (ë¶„ë¥˜ íŒŒì¼ í™œìš©) ---
    # 1ï¸âƒ£ íƒ€ì… í†µì¼ (ì¤‘ìš”)
    df_cls = dfs_dict[CLASSIFICATION_DF_KEY].copy()
    unit_cost_df[MAT_COL] = unit_cost_df[MAT_COL].astype(str).str.strip()
    df_cls[MAT_COL] = df_cls[MAT_COL].astype(str).str.strip()

    # 2ï¸âƒ£ ìì¬ â†’ ëŒ€ë¶„ë¥˜ / ì†Œë¶„ë¥˜ ë§¤í•‘ dict ìƒì„±
    major_map = df_cls.drop_duplicates(subset=[MAT_COL]) \
                    .set_index(MAT_COL)["ëŒ€ë¶„ë¥˜"]

    minor_map = df_cls.drop_duplicates(subset=[MAT_COL]) \
                    .set_index(MAT_COL)["ì†Œë¶„ë¥˜"]

    # 3ï¸âƒ£ unit_cost_dfì— ë§¤í•‘í•´ì„œ ì»¬ëŸ¼ ìƒì„±
    unit_cost_df["ëŒ€ë¶„ë¥˜"] = unit_cost_df[MAT_COL].map(major_map)
    unit_cost_df["ì†Œë¶„ë¥˜"] = unit_cost_df[MAT_COL].map(minor_map)

    # 4ï¸âƒ£ ë§¤í•‘ ì‹¤íŒ¨í•œ ê²½ìš° ì²˜ë¦¬
    unit_cost_df["ëŒ€ë¶„ë¥˜"] = unit_cost_df["ëŒ€ë¶„ë¥˜"].fillna("ë¯¸ë¶„ë¥˜")
    unit_cost_df["ì†Œë¶„ë¥˜"] = unit_cost_df["ì†Œë¶„ë¥˜"].fillna("ë¯¸ë¶„ë¥˜")

    unit_cost_df[MAT_COL] = pd.to_numeric(unit_cost_df[MAT_COL], errors="coerce")

    # --- [Step 2] ì¬ê³  ì •ë³´ì™€ ìœ íš¨ê¸°í•œ ë³‘í•© (2, 3ë²ˆ íŒŒì¼ í™œìš©) ---
    df_stock = dfs_dict[STOCK_DF_KEY]
    df_expiry = dfs_dict[EXPIRY_DF_KEY][[BATCH_COL, EXPIRY_COL]].drop_duplicates(subset=[BATCH_COL])
    merged = df_stock.merge(df_expiry, on=BATCH_COL, how="left")
    
    merged[QTY_SRC_COL] = to_numeric_safe(merged[QTY_SRC_COL])
    merged = merged[merged[QTY_SRC_COL] > 0].copy()
    
    # --- [Step 3] ìœ íš¨ê¸°í•œ ë²„í‚·íŒ… (D-Day ê³„ì‚°) ---
    today = pd.Timestamp(datetime.now().date())
    merged[EXPIRY_COL] = pd.to_datetime(merged[EXPIRY_COL], errors="coerce")
    merged[DAYS_COL] = (merged[EXPIRY_COL] - today).dt.days
    
    def bucketize(days):
        if pd.isna(days): return "ìœ íš¨ê¸°í•œ ì—†ìŒ"
        if days <= 0: return "íê¸°í™•ì •(ìœ íš¨ê¸°í•œ ì§€ë‚¨)"
        if days <= 90: return "3ê°œì›” ë¯¸ë§Œ"
        if days <= 180: return "6ê°œì›” ë¯¸ë§Œ"
        if days <= 210: return "7ê°œì›” ë¯¸ë§Œ"  
        if days <= 270: return "9ê°œì›” ë¯¸ë§Œ"
        if days <= 365: return "12ê°œì›” ë¯¸ë§Œ"
        return "12ê°œì›” ì´ìƒ"
    
    merged[BUCKET_COL] = merged[DAYS_COL].apply(bucketize)
    
    # --- [Step 4] ì¬ê³  ê°€ì¹˜ ì‚°ì¶œ (ìˆ˜ëŸ‰ * ë‹¨ìœ„ì›ê°€) ---
    merged = merged.merge(unit_cost_df[[MAT_COL, UNIT_COST_COL, "ëŒ€ë¶„ë¥˜", "ì†Œë¶„ë¥˜"]], on=MAT_COL, how="left")
    merged[UNIT_COST_COL] = merged[UNIT_COST_COL].fillna(0)
    merged[VALUE_COL] = merged[QTY_SRC_COL] * merged[UNIT_COST_COL]
    
    # --- [Step 5] ìì¬ë³„ ì›”í‰ê·  ë§¤ì¶œ(3í‰íŒ) ìë™ ê³„ì‚° (5ë²ˆ íŒŒì¼ í™œìš©) ---
    df_sales = dfs_dict[SALES_DF_KEY].copy()
    df_sales['ìˆœë§¤ì¶œìˆ˜ëŸ‰'] = to_numeric_safe(df_sales['ìˆœë§¤ì¶œìˆ˜ëŸ‰'])
    
    # 1. ìì¬ë³„ ì‹¤ì œ ë°ì´í„°ê°€ ì¡´ì¬í•˜ëŠ” ê°œì›” ìˆ˜ ì¹´ìš´íŠ¸ (nunique ì‚¬ìš©)
    # í•œ ìì¬ê°€ 202510, 202511 ë‘ ë‹¬ì¹˜ ë°ì´í„°ë§Œ ìˆë‹¤ë©´ ê°œì›”ìˆ˜ëŠ” 2ê°€ ë¨
    month_counts = df_sales.groupby('ìì¬ì½”ë“œ')['ë…„ì›”'].nunique().reset_index()
    month_counts.columns = ['ìì¬ì½”ë“œ', 'ê°œì›”ìˆ˜']
    
    # 2. ìì¬ë³„ ì „ì²´ ìˆœë§¤ì¶œìˆ˜ëŸ‰ í•©ê³„ ê³„ì‚°
    total_sales = df_sales.groupby('ìì¬ì½”ë“œ', as_index=False)['ìˆœë§¤ì¶œìˆ˜ëŸ‰'].sum()
    
    # 3. í‰ê· (3í‰íŒ) ê³„ì‚°: (ì „ì²´ í•©ê³„ / ì‹¤ì œ ë°ì´í„° ê°œì›”ìˆ˜)
    sales_avg = total_sales.merge(month_counts, on='ìì¬ì½”ë“œ')
    sales_avg['3í‰íŒ'] = sales_avg.apply(
        lambda r: r['ìˆœë§¤ì¶œìˆ˜ëŸ‰'] / r['ê°œì›”ìˆ˜'] if r['ê°œì›”ìˆ˜'] > 0 else 0, axis=1
    )
    

    # --- [ìˆ˜ì •] ìµœì¢… ë°ì´í„°í”„ë ˆì„ì— '3í‰íŒ'ê³¼ 'ê°œì›”ìˆ˜' í•¨ê»˜ ì¶”ê°€ ---
    merged = merged.merge(
        sales_avg[['ìì¬ì½”ë“œ', '3í‰íŒ', 'ê°œì›”ìˆ˜']], # ê°œì›”ìˆ˜ ì»¬ëŸ¼ ì¶”ê°€
        left_on=MAT_COL, 
        right_on='ìì¬ì½”ë“œ', 
        how="left"
    )
    
    # --- [Step 6] ë°ì´í„° ì •ë¦¬ ë° ë°˜í™˜ ---
    if 'ìì¬ì½”ë“œ' in merged.columns:
        merged.drop(columns=['ìì¬ì½”ë“œ'], inplace=True)
    merged['3í‰íŒ'] = merged['3í‰íŒ'].fillna(0)
    
    # âœ… "ì¬ê³ ì¼ìˆ˜" ì»¬ëŸ¼ ì¶”ê°€: Stock Quantity / (3í‰íŒ / 30)
    # 3í‰íŒì´ 0ì¸ ê²½ìš° ë§¤ìš° í° ê°’(999)ìœ¼ë¡œ ì±„ì›€
    merged['ì¬ê³ ì¼ìˆ˜'] = merged.apply(
        lambda r: r[QTY_SRC_COL] / (r['3í‰íŒ'] / 30.0) if r['3í‰íŒ'] > 0 else 999.0, 
        axis=1
    )
    
    return merged

# =====================================================
# ğŸš€ ë©”ì¸ ë¡œì§ ì‹œì‘
# =====================================================
all_dfs_store = st.session_state.get("dfs", {})

if not all_dfs_store:
    st.warning("ë¨¼ì € ì—…ë¡œë“œ í˜ì´ì§€ì—ì„œ ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")
    st.stop()

# --- ğŸ“… [ìˆ˜ì •] ë¶„ì„ ëŒ€ìƒ ì—°ë„ ë° ì›” ì„ íƒ ---
st.sidebar.header("ğŸ“‚ ë¶„ì„ ëŒ€ìƒ ì„ íƒ")
current_year = datetime.now().year
selected_year = st.sidebar.selectbox(
    "ğŸ“… ì—°ë„ ì„ íƒ",
    options=[f"{y}ë…„" for y in range(2023, 2041)],
    index=range(2023, 2041).index(current_year) if current_year in range(2023, 2041) else 0
)

selected_month = st.sidebar.selectbox(
    "ğŸ“† ì›” ì„ íƒ",
    options=[f"{m}ì›”" for m in range(1, 13)],
    index=datetime.now().month - 1
)

# ì„ íƒëœ ì—°ë„/ì›”ì˜ ë°ì´í„° ë­‰ì¹˜ ê°€ì ¸ì˜¤ê¸° (ì„¸ì…˜ ìƒíƒœ)
year_data = all_dfs_store.get(selected_year, {})
target_dfs = year_data.get(selected_month)

BASE_DATA_DIR = Path("Datas")

# ë¡œì»¬ ìºì‹œ ìš°ì„  ë¡œë“œ ë¡œì§
stock_csv_path = get_stock_csv_path(selected_year, selected_month)
use_cache = stock_csv_path.exists()

# (ì„ íƒ) ì‚¬ì´ë“œ/í™”ë©´ì— ìƒíƒœ í‘œì‹œ
st.caption(f"ğŸ“Œ ë¡œì»¬ ìºì‹œ ìƒíƒœ: {'âœ… ìˆìŒ (Stock.csv ë¡œë“œ)' if use_cache else 'âŒ ì—†ìŒ (ì—…ë¡œë“œ ë°ì´í„°ë¡œ ìƒì„±)'}")

# 2) final_df ìƒì„±: ìºì‹œ ìˆìœ¼ë©´ ë¡œë“œ, ì—†ìœ¼ë©´ ìƒì„± í›„ ì €ì¥
if use_cache:
    with st.spinner(f"{selected_year} {selected_month} Stock.csv ìºì‹œ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
        final_df = load_stock_csv(selected_year, selected_month)
    st.success(f"âœ… ìºì‹œ ë¡œë“œ ì™„ë£Œ: {stock_csv_path}")

elif target_dfs is not None:
    # ìºì‹œê°€ ì—†ì„ ë•Œë§Œ ê¸°ì¡´ UI/ë¹Œë“œ ë¡œì§ ì‹¤í–‰
    with st.expander(f"ğŸ“ {selected_year} {selected_month} ë¶„ì„ ëŒ€ìƒ íŒŒì¼ í™•ì¸", expanded=False):
        file_info = []
        for f_name, f_df in target_dfs.items():
            file_info.append({"íŒŒì¼ëª…": f_name, "í–‰ ìˆ˜": len(f_df), "ì»¬ëŸ¼ ìˆ˜": f_df.shape[1]})
        st.table(pd.DataFrame(file_info))

    # ìµœì¢… ê°€ê³µ ë°ì´í„° ìƒì„±
    with st.spinner(f"{selected_year} {selected_month} ë°ì´í„°ë¥¼ í†µí•© ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
        final_df = build_final_df(target_dfs, selected_year, selected_month)

    # âœ… ìƒì„± í›„ ë¡œì»¬ì— ì €ì¥
    saved_path = save_stock_csv(final_df, selected_year, selected_month)
    st.success(f"âœ… Stock.csv ì €ì¥ ì™„ë£Œ: {saved_path}")

else:
    st.warning(f"âš ï¸ {selected_year} {selected_month}ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    st.info("ë¨¼ì € ì—…ë¡œë“œ í˜ì´ì§€ì—ì„œ ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ê±°ë‚˜, ê¸°ì¡´ ë¶„ì„ ê²°ê³¼(Stock.csv)ê°€ ìˆëŠ”ì§€ í™•ì¸í•´ ì£¼ì„¸ìš”.")
    st.stop()


# -----------------------------------------------------
# 1ï¸âƒ£ ê¸°ê°„ë³„ ìœ„í—˜ ìì¬ ìš”ì•½ (ON)
# -----------------------------------------------------
with st.container():
    st.markdown("### ğŸ“Š í•œëˆˆì— ë³´ëŠ” ì¬ê³  ë¦¬ìŠ¤í¬")
    
    # ìƒë‹¨ ìš”ì•½ ì§€í‘œ (KPI)
    total_value = final_df[VALUE_COL].sum()
    total_count = final_df[MAT_COL].nunique()
    
    # ìœ„í—˜ êµ¬ê°„(9ê°œì›” ë¯¸ë§Œ) í•„í„°
    risk_buckets_9m = ["íê¸°í™•ì •(ìœ íš¨ê¸°í•œ ì§€ë‚¨)", "1ê°œì›” ë¯¸ë§Œ", "2ê°œì›” ë¯¸ë§Œ", "3ê°œì›” ë¯¸ë§Œ", "4ê°œì›” ë¯¸ë§Œ", "5ê°œì›” ë¯¸ë§Œ", "6ê°œì›” ë¯¸ë§Œ", "7ê°œì›” ë¯¸ë§Œ", "8ê°œì›” ë¯¸ë§Œ", "9ê°œì›” ë¯¸ë§Œ"]
    risk_df_9m = final_df[final_df[BUCKET_COL].isin(risk_buckets_9m)]
    risk_value_9m = risk_df_9m[VALUE_COL].sum()
    risk_percent_9m = (risk_value_9m / total_value * 100) if total_value > 0 else 0
    
    m1, m2, m3 = st.columns(3)
    m1.metric("ì´ ì¬ê³  ê°€ì¹˜", f"â‚©{total_value:,.0f}")
    m2.metric("9ê°œì›” ë¯¸ë§Œ ì¬ê³  ê¸ˆì•¡", f"â‚©{risk_value_9m:,.0f}")
    m3.metric("ë¶„ì„ ëŒ€ìƒ ìì¬ ìˆ˜", f"{total_count:,}ì¢…")

    st.markdown("---")
    st.markdown(f"#### ğŸš¨ {selected_year} {selected_month} ê¸°ê°„ë³„ ìƒì„¸ ìš”ì•½")
    tab6, tab7, tab9, tab12 = st.tabs(
        ["âš ï¸ 6ê°œì›” ë¯¸ë§Œ", "ğŸ”” 7ê°œì›” ë¯¸ë§Œ", "â„¹ï¸ 9ê°œì›” ë¯¸ë§Œ", "ğŸ“… 12ê°œì›” ë¯¸ë§Œ"]
    )

# def display_risk_summary(target_buckets, tab_obj, title):
#     with tab_obj:
#         risk_df = final_df[final_df[BUCKET_COL].isin(target_buckets)].copy()
#         if risk_df.empty:
#             st.success(f"âœ… {title} ë‚´ì— í•´ë‹¹í•˜ëŠ” ìì¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
#             return

#         # âœ… ìì¬ ë‹¨ìœ„ ìš”ì•½ + ë°°ì¹˜ ì •ë³´ í¬í•¨
#         summary = (
#             risk_df.groupby([MAT_COL, MAT_NAME_COL], as_index=False)
#             .agg(
#                 ë°°ì¹˜ìˆ˜=("ë°°ì¹˜", "nunique"),
#                 ë°°ì¹˜ëª©ë¡=("ë°°ì¹˜", lambda s: ", ".join(map(str, pd.Series(s).dropna().unique()[:10]))),
#                 **{QTY_SRC_COL: (QTY_SRC_COL, "sum"),
#                    VALUE_COL: (VALUE_COL, "sum")}
#             )
#             .sort_values(VALUE_COL, ascending=False)
#             .reset_index(drop=True)
#         )

#         # (1) âœ… ë©”íŠ¸ë¦­ì€ 1:1ë¡œë§Œ
#         c1, c2 = st.columns(2)
#         c1.metric(f"{title} ìì¬ ìˆ˜", f"{len(summary)}ì¢…")
#         c2.metric("ì´ ìœ„í—˜ ê¸ˆì•¡", f"â‚©{summary[VALUE_COL].sum():,.0f}")

#         # (2) âœ… í‘œëŠ” ë°”ë¡œ ì•„ë˜ + ë°°ì¹˜ ì •ë³´ ì»¬ëŸ¼ í¬í•¨
#         disp = summary.copy()
#         disp[VALUE_COL] = disp[VALUE_COL].map(lambda x: f"{x:,.0f}")
#         disp[QTY_SRC_COL] = disp[QTY_SRC_COL].map(lambda x: f"{x:,.0f}")

#         disp = disp.rename(columns={QTY_SRC_COL: "ë¶€ì§„ì¬ê³  ìˆ˜ëŸ‰", VALUE_COL: "ë¶€ì§„ì¬ê³  ê¸ˆì•¡"})
#         # ì»¬ëŸ¼ ìˆœì„œ ë³´ê¸° ì¢‹ê²Œ ì •ë¦¬ (ì›í•˜ë©´ ë” ìˆ˜ì • ê°€ëŠ¥)
#         show_cols = [MAT_COL, MAT_NAME_COL, "ë°°ì¹˜ìˆ˜", "ë°°ì¹˜ëª©ë¡", "ë¶€ì§„ì¬ê³  ìˆ˜ëŸ‰", "ë¶€ì§„ì¬ê³  ê¸ˆì•¡"]
#         st.dataframe(disp[show_cols], use_container_width=True, height=600)

def display_risk_summary(target_buckets, tab_obj, title):
    with tab_obj:
        risk_df = final_df.copy()

        if risk_df.empty:
            st.success(f"âœ… {title} ë‚´ì— í•´ë‹¹í•˜ëŠ” ìì¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        # âœ… ì»¬ëŸ¼ëª…
        EXPIRY_COL = "ìœ íš¨ ê¸°í•œ"     # ë§Œë£Œì¼(ë‚ ì§œ)
        SALES_COL  = "3í‰íŒ"
        DAYS_COL   = "days_to_expiry"

        # 1) ì˜¤ëŠ˜ ê¸°ì¤€ ì¬ê³„ì‚°
        today = pd.Timestamp.today().normalize()  # ì˜¤ëŠ˜ 00:00 ê¸°ì¤€ (ì‹œê°„ ì˜í–¥ ì œê±°)

        risk_df[EXPIRY_COL] = pd.to_datetime(risk_df[EXPIRY_COL], errors="coerce")
        risk_df[DAYS_COL] = (risk_df[EXPIRY_COL] - today).dt.days

        def to_bucket(days):
            if pd.isna(days):
                return "ìœ íš¨ê¸°í•œ ì—†ìŒ"
            if days < 0:
                return "íê¸°í™•ì •(ìœ íš¨ê¸°í•œ ì§€ë‚¨)"
            if days < 30:
                return "1ê°œì›” ë¯¸ë§Œ"
            if days < 60:
                return "2ê°œì›” ë¯¸ë§Œ"
            if days < 90:
                return "3ê°œì›” ë¯¸ë§Œ"
            if days < 120:
                return "4ê°œì›” ë¯¸ë§Œ"
            if days < 150:
                return "5ê°œì›” ë¯¸ë§Œ"
            if days < 180:
                return "6ê°œì›” ë¯¸ë§Œ"
            if days < 210:
                return "7ê°œì›” ë¯¸ë§Œ"
            if days < 240:
                return "8ê°œì›” ë¯¸ë§Œ"
            if days < 270:
                return "9ê°œì›” ë¯¸ë§Œ"
            if days < 300:
                return "10ê°œì›” ë¯¸ë§Œ"
            if days < 330:
                return "11ê°œì›” ë¯¸ë§Œ"
            if days < 365:
                return "12ê°œì›” ë¯¸ë§Œ"
            return "12ê°œì›” ì´ìƒ"

        risk_df[BUCKET_COL] = risk_df[DAYS_COL].apply(to_bucket)

        # âœ… ì—¬ê¸°ì„œ ì´ì œ target_bucketsë¡œ í•„í„°ë§
        risk_df = risk_df[risk_df[BUCKET_COL].isin(target_buckets)].copy()

        if risk_df.empty:
            st.success(f"âœ… {title} ë‚´ì— í•´ë‹¹í•˜ëŠ” ìì¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # 3) (ìì¬+ë°°ì¹˜) ë‹¨ìœ„ í‘œ
        summary = (
            risk_df.groupby([MAT_COL, MAT_NAME_COL, "ë°°ì¹˜"], as_index=False)
            .agg(
                **{
                    QTY_SRC_COL: (QTY_SRC_COL, "sum"),
                    VALUE_COL: (VALUE_COL, "sum"),
                    DAYS_COL: (DAYS_COL, "min"),
                    EXPIRY_COL: (EXPIRY_COL, "min"),
                    SALES_COL: (SALES_COL, "first"),
                    BUCKET_COL: (BUCKET_COL, "first"),
                }
            )
            # âœ… ì¶”ì²œ: ê¸‰í•œ ìˆœìœ¼ë¡œ ë³´ê³  ì‹¶ìœ¼ë©´ ì•„ë˜ë¡œ ë°”ê¿”ë„ ë¨
            .sort_values([DAYS_COL, VALUE_COL], ascending=[True, False])
            #.sort_values(VALUE_COL, ascending=False)
            .reset_index(drop=True)
        )

        # 4) ë©”íŠ¸ë¦­
        c1, c2 = st.columns(2)
        c1.metric(f"{title} ë°°ì¹˜ ìˆ˜", f"{summary['ë°°ì¹˜'].nunique()}ê°œ")
        c2.metric("ì´ ìœ„í—˜ ê¸ˆì•¡", f"â‚©{summary[VALUE_COL].sum():,.0f}")

        # 5) í¬ë§· & í‘œì‹œ
        disp = summary.copy()
        disp[EXPIRY_COL] = pd.to_datetime(disp[EXPIRY_COL], errors="coerce").dt.strftime("%Y-%m-%d")

        disp[VALUE_COL] = disp[VALUE_COL].map(lambda x: f"{x:,.0f}")
        disp[QTY_SRC_COL] = disp[QTY_SRC_COL].map(lambda x: f"{x:,.0f}")
        disp[SALES_COL] = disp[SALES_COL].map(lambda x: f"{x:,.0f}" if pd.notna(x) else x)

        disp = disp.rename(columns={
            QTY_SRC_COL: "ë¶€ì§„ì¬ê³  ìˆ˜ëŸ‰",
            VALUE_COL: "ë¶€ì§„ì¬ê³  ê¸ˆì•¡",
            DAYS_COL: "ë‚¨ì€ ì¼(Day)",
            EXPIRY_COL: "ìœ íš¨ê¸°ê°„",
            SALES_COL: "3í‰íŒ",
            BUCKET_COL: "ë²„í‚·",
        })

        show_cols = [
            MAT_COL, MAT_NAME_COL, "ë°°ì¹˜",
            "ë²„í‚·", "ìœ íš¨ê¸°ê°„", "ë‚¨ì€ ì¼(Day)", "3í‰íŒ",
            "ë¶€ì§„ì¬ê³  ìˆ˜ëŸ‰", "ë¶€ì§„ì¬ê³  ê¸ˆì•¡",
        ]
        st.dataframe(disp[show_cols], use_container_width=True, height=600)


risk_base = ["íê¸°í™•ì •(ìœ íš¨ê¸°í•œ ì§€ë‚¨)", "1ê°œì›” ë¯¸ë§Œ", "2ê°œì›” ë¯¸ë§Œ", "3ê°œì›” ë¯¸ë§Œ", "4ê°œì›” ë¯¸ë§Œ", "5ê°œì›” ë¯¸ë§Œ"]
display_risk_summary(risk_base + ["6ê°œì›” ë¯¸ë§Œ"], tab6, "6ê°œì›” ë¯¸ë§Œ")
display_risk_summary(["7ê°œì›” ë¯¸ë§Œ"], tab7, "7ê°œì›” ë¯¸ë§Œ")
display_risk_summary(["8ê°œì›” ë¯¸ë§Œ", "9ê°œì›” ë¯¸ë§Œ"], tab9, "9ê°œì›” ë¯¸ë§Œ")
display_risk_summary(["10ê°œì›” ë¯¸ë§Œ", "11ê°œì›” ë¯¸ë§Œ", "12ê°œì›” ë¯¸ë§Œ"], tab12,"12ê°œì›” ë¯¸ë§Œ")


# -----------------------------------------------------
# 2ï¸âƒ£ ìì¬-ë°°ì¹˜ ë‹¨ìœ„ ìƒì„¸ ë¶„ì„ ë° ì‹œê°í™” (OFF)
# -----------------------------------------------------
def render_batch_analysis_section(final_df, MAT_COL, MAT_NAME_COL, BATCH_COL, BUCKET_COL, QTY_SRC_COL, VALUE_COL):
    """
    ìì¬-ë°°ì¹˜ë³„ ìƒì„¸ ë¶„ì„ ì„¹ì…˜ì„ ë Œë”ë§í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.
    ê¸°ì¡´ ë¡œì§ì„ ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ë©° ë§¤ê°œë³€ìˆ˜ë¡œ í•„ìš”í•œ ìƒìˆ˜ë“¤ì„ ë°›ìŠµë‹ˆë‹¤.
    """
    with st.container():
        st.subheader("ğŸ” ìì¬-ë°°ì¹˜ë³„ ìƒì„¸ ë¶„ì„ (6/7/9ê°œì›” ì§‘ì¤‘)")

        target_risks_all = ["3ê°œì›” ë¯¸ë§Œ", "6ê°œì›” ë¯¸ë§Œ", "7ê°œì›” ë¯¸ë§Œ", "9ê°œì›” ë¯¸ë§Œ", "íê¸°í™•ì •(ìœ íš¨ê¸°í•œ ì§€ë‚¨)"]
        df_risk_all = final_df[final_df[BUCKET_COL].isin(target_risks_all)].copy()

        if not df_risk_all.empty:
            top_mats = (
                df_risk_all.groupby([MAT_COL, MAT_NAME_COL], as_index=False)[VALUE_COL].sum()
                .sort_values(VALUE_COL, ascending=False)
            )
            top_mats["label"] = top_mats[MAT_COL].astype(str) + " | " + top_mats[MAT_NAME_COL].astype(str)
            
            col_sel, col_chk = st.columns([2, 1])
            with col_sel:
                selected_label = st.selectbox("ìƒì„¸ ì¡°ì‚¬ê°€ í•„ìš”í•œ ìì¬ë¥¼ ì„ íƒí•˜ì„¸ìš”", options=top_mats["label"].tolist())
                selected_mat = selected_label.split(" | ")[0]
            with col_chk:
                show_all_batches = st.checkbox("ëª¨ë“  ìœ„í—˜ ë°°ì¹˜ ë³´ê¸° (ê¸ˆì•¡ìˆœ)", value=False)

            if show_all_batches:
                view_df = df_risk_all.sort_values(VALUE_COL, ascending=False).reset_index(drop=True)
            else:
                view_df = df_risk_all[df_risk_all[MAT_COL].astype(str) == selected_mat].sort_values(VALUE_COL, ascending=False).reset_index(drop=True)

            st.write(f"### ğŸ“ ìƒì„¸ ë¦¬ìŠ¤íŠ¸ (ë¶„ì„ ëŒ€ìƒ: {selected_label if not show_all_batches else 'ì „ì²´ ìœ„í—˜ ë°°ì¹˜'})")
            
            v_disp = view_df[[MAT_COL, MAT_NAME_COL, BATCH_COL, BUCKET_COL, QTY_SRC_COL, VALUE_COL]].copy()
            v_disp[VALUE_COL] = v_disp[VALUE_COL].map('{:,.0f}'.format)
            v_disp[QTY_SRC_COL] = v_disp[QTY_SRC_COL].map('{:,.0f}'.format)
            st.dataframe(v_disp, use_container_width=True)

            if not show_all_batches:
                chart_targets = ["6ê°œì›” ë¯¸ë§Œ", "7ê°œì›” ë¯¸ë§Œ", "9ê°œì›” ë¯¸ë§Œ"]
                chart_df = view_df[view_df[BUCKET_COL].isin(chart_targets)].copy()

                if not chart_df.empty:
                    fig, ax = plt.subplots(figsize=(10, 4)) 
                    sns.barplot(
                        data=chart_df, 
                        x=BATCH_COL, 
                        y=VALUE_COL, 
                        hue=BUCKET_COL, 
                        palette="viridis",
                        ax=ax,
                        errorbar=None,
                        width=0.7 
                    )
                    
                    ax.set_title(f"ğŸ“ [{selected_label}] ë°°ì¹˜ë³„ ìƒì„¸ ê°€ì¹˜ ë¶„ì„ (6/7/9ê°œì›” ë¯¸ë§Œ)", fontsize=15, pad=20)
                    ax.set_xlabel("ë°°ì¹˜ ë²ˆí˜¸", fontsize=12)
                    ax.set_ylabel("ì¬ê³  ê°€ì¹˜ (Stock Value)", fontsize=12)

                    ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, p: format(int(x), ',')))
                    ax.legend(title="ìœ„í—˜ êµ¬ê°„", bbox_to_anchor=(1.05, 1), loc='upper left')
                    
                    sns.despine()
                    plt.xticks(rotation=0, ha="right")
                    plt.tight_layout()
                    st.pyplot(fig, use_container_width=True)
                else:
                    st.info("ğŸ’¡ ì„ íƒí•œ ìì¬ì—ëŠ” 6/7/9ê°œì›” ë¯¸ë§Œì— í•´ë‹¹í•˜ëŠ” ë°°ì¹˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.info("ê´€ë¦¬ ëŒ€ìƒ ìœ„í—˜ ì¬ê³ ê°€ ì—†ìŠµë‹ˆë‹¤.")
#render_batch_analysis_section(final_df, MAT_COL, MAT_NAME_COL, BATCH_COL, BUCKET_COL, QTY_SRC_COL, VALUE_COL)

# -----------------------------------------------------
# 3ï¸âƒ£ êµ­ê°€ë³„ ì¬ê³  ê°€ì¹˜ ë¶„í¬(ì§€ë„), ìš”ì•½ ì§€í‘œ(Metric), ìƒì„¸ ë¦¬ìŠ¤í¬ í…Œì´ë¸” ì‹œê°í™” (OFF)
# -----------------------------------------------------
def render_country_stock_analysis(final_df, VALUE_COL, BUCKET_COL, selected_year, selected_month):
    """
    êµ­ê°€ë³„ ì¬ê³  ê°€ì¹˜ ë¶„í¬(ì§€ë„), ìš”ì•½ ì§€í‘œ(Metric), ìƒì„¸ ë¦¬ìŠ¤í¬ í…Œì´ë¸”ì„ ë Œë”ë§í•©ë‹ˆë‹¤.
    """
    # ë‚´ë¶€ í•¨ìˆ˜: êµ­ê°€ ë¶„ë¥˜ ë¡œì§
    def classify_country(location_code):
        if pd.isna(location_code) or str(location_code).strip() == "":
            return "êµ­ë‚´"
        loc = str(location_code).split('.')[0].strip()
        if loc in ["6030", "7030", "7040"]:
            return "China"
        elif loc == "6080":
            return "United States"
        elif loc == "7090":
            return "Japan"
        else:
            return "êµ­ë‚´"

    st.subheader("ğŸŒ êµ­ê°€ë³„ ì „ì²´ ì¬ê³  ê°€ì¹˜ ë¶„í¬")

    # 1. ë°ì´í„° ì „ì²˜ë¦¬
    geo_df = final_df.copy()
    geo_df['ì €ì¥ ìœ„ì¹˜'] = pd.to_numeric(geo_df['ì €ì¥ ìœ„ì¹˜'], errors='coerce')
    geo_df['Country'] = geo_df['ì €ì¥ ìœ„ì¹˜'].apply(classify_country)

    # êµ­ê°€ë³„ í•©ê³„ ê³„ì‚°
    country_summary = geo_df.groupby('Country')[VALUE_COL].sum().reset_index()
    total_global_val = country_summary[VALUE_COL].sum()

    if total_global_val > 0:
        country_summary['ë¹„ì¤‘(%)'] = (country_summary[VALUE_COL] / total_global_val * 100).round(3)
    else:
        country_summary['ë¹„ì¤‘(%)'] = 0

    country_summary['Country_Map'] = country_summary['Country'].replace({'êµ­ë‚´': 'South Korea'})

    # 2. ìƒë‹¨ ìš”ì•½ ì§€í‘œ (Metric Widgets)
    st.write("#### ğŸ“Š ì£¼ìš” ì§€ì—­ë³„ ì¬ê³  ìì‚° ìš”ì•½")
    m1, m2, m3, m4 = st.columns(4)

    def render_region_metric(label, col_obj):
        row = country_summary[country_summary['Country'] == label]
        if not row.empty:
            val = row[VALUE_COL].values[0]
            pct = row['ë¹„ì¤‘(%)'].values[0]
            col_obj.metric(label, f"â‚©{val:,.0f}", f"{pct:.3f}%")
        else:
            col_obj.metric(label, "â‚©0", "0.000%")

    render_region_metric("êµ­ë‚´", m1)
    render_region_metric("China", m2)
    render_region_metric("United States", m3)
    render_region_metric("Japan", m4)

    # 3. Plotly ê¸€ë¡œë²Œ ì§€ë„ (Blues ìŠ¤ì¼€ì¼ ì ìš©)
    fig_map = px.choropleth(
        country_summary,
        locations="Country_Map",
        locationmode="country names",
        color=VALUE_COL,
        hover_name="Country",
        hover_data={VALUE_COL: ':,.0f', 'ë¹„ì¤‘(%)': ':.3f%', 'Country_Map': False},
        color_continuous_scale="Reds", 
        title=f"ğŸŒ {selected_year} {selected_month} ê¸€ë¡œë²Œ ê±°ì ë³„ ì¬ê³  ê°€ì¹˜ í•©ê³„",
        labels={VALUE_COL: "ì¬ê³  ê°€ì¹˜(â‚©)", "ë¹„ì¤‘(%)": "ê¸€ë¡œë²Œ ë¹„ì¤‘"}
    )

    fig_map.update_layout(
        margin={"r":0,"t":50,"l":0,"b":0},
        geo=dict(showframe=False, showcoastlines=True, landcolor="lightgray")
    )
    st.plotly_chart(fig_map, use_container_width=True)

    # 4. ìƒì„¸ ë¶„ì„ í…Œì´ë¸” (Expander)
    with st.expander("ğŸ“ ì§€ì—­ë³„ & ìœ„í—˜êµ¬ê°„ë³„ ìƒì„¸ ë¶„ì„ í…Œì´ë¸”"):
        target_buckets = ["6ê°œì›” ë¯¸ë§Œ", "7ê°œì›” ë¯¸ë§Œ", "9ê°œì›” ë¯¸ë§Œ", "íê¸°í™•ì •(ìœ íš¨ê¸°í•œ ì§€ë‚¨)", "3ê°œì›” ë¯¸ë§Œ"]
        pivot_risk = geo_df.pivot_table(
            index='Country',
            columns=BUCKET_COL,
            values=VALUE_COL,
            aggfunc='sum',
            fill_value=0
        ).reset_index()

        existing_cols = [col for col in target_buckets if col in pivot_risk.columns]
        table_display = pivot_risk[['Country'] + existing_cols].copy()
        table_display['ìœ„í—˜ì¬ê³  í•©ê³„'] = table_display[existing_cols].sum(axis=1)
        
        st.write("##### ğŸ“ êµ­ê°€ë³„ ìœ íš¨ê¸°í•œ ë¦¬ìŠ¤í¬ í˜„í™© (ë‹¨ìœ„: ì›)")
        st.dataframe(
            table_display.sort_values('ìœ„í—˜ì¬ê³  í•©ê³„', ascending=False).style.format({
                col: '{:,.0f}' for col in table_display.columns if col != 'Country'
            }),
            use_container_width=True
        )
        st.caption("â€» ìœ„ í…Œì´ë¸”ì€ ì „ì²´ ì¬ê³  ì¤‘ ìœ íš¨ê¸°í•œ ë¦¬ìŠ¤í¬ê°€ ìˆëŠ” í•­ëª©ë§Œ ì¶”ë ¤ì„œ êµ­ê°€ë³„ë¡œ í•©ì‚°í•œ ê²°ê³¼ì…ë‹ˆë‹¤.")
#render_country_stock_analysis(final_df, VALUE_COL, BUCKET_COL, selected_year, selected_month)


# -----------------------------------------------------
# 4ï¸âƒ£ ì¬ê³ ì†Œì§„ì‹œë®¬ë ˆì´ì…˜ (FEFO + D-180 ë„ë‹¬ ì¦‰ì‹œ íŒë§¤ì¤‘ë‹¨) (ON)
# -----------------------------------------------------
def simulate_batches_by_product(
    df: pd.DataFrame,
    product_cols=("ìì¬", "ìì¬ ë‚´ì—­"),            # (MAT_COL, MAT_NAME_COL)
    batch_col="ë°°ì¹˜",                          # BATCH_COL
    days_col="ìœ íš¨ ê¸°í•œ",                      # DAYS_COL  (ë‚¨ì€ ì¼ìˆ˜ ì»¬ëŸ¼)
    qty_col="Stock Quantity on Period End",     # QTY_SRC_COL
    monthly_sales_col="3í‰íŒ",                  # ì›” íŒë§¤ëŸ‰
    risk_days=180,                              # D-180
    step_days=30,                               # 30ì¼ ë‹¨ìœ„
    today=None
):
    """
    ì œí’ˆë³„ë¡œ ë°°ì¹˜ë¥¼ ìœ íš¨ê¸°í•œ(ë‚¨ì€ì¼ìˆ˜) ì§§ì€ ìˆœìœ¼ë¡œ ì •ë ¬í•œ ë’¤,
    ê°€ì¥ ë¨¼ì € ë§Œë£Œë˜ëŠ” ë°°ì¹˜ë¶€í„° ì›”í‰ê·  íŒë§¤ëŸ‰(3í‰íŒ) ê¸°ì¤€ìœ¼ë¡œ íŒë§¤(ì°¨ê°) ì‹œë®¬ë ˆì´ì…˜.

    âœ… ë³€ê²½ì (ìš”êµ¬ì‚¬í•­ ë°˜ì˜):
      - ìœ íš¨ê¸°í•œì´ 6ê°œì›” ë¯¸ë§Œ(D-180 ì´í•˜)ì´ ë˜ëŠ” ì‹œì (risk_entry_date)ë¶€í„°ëŠ” íŒë§¤ ë¶ˆê°€
      - ë§Œì•½ 30ì¼ íŒë§¤ êµ¬ê°„ ì¤‘ê°„ì— risk_entry_dateê°€ ë¼ë©´, risk_entry_date ì§ì „ê¹Œì§€ë§Œ "ë¶€ë¶„íŒë§¤(ì¼í• )" í›„ ì¦‰ì‹œ ì¤‘ë‹¨í•˜ê³  ë‹¤ìŒ ë°°ì¹˜ë¡œ ë„˜ì–´ê°

    íŒë§¤ ì¤‘ë‹¨ ì¡°ê±´:
      - ì¬ê³ ê°€ 0ì´ ë¨ (sold_out)
      - ìœ íš¨ê¸°í•œì´ risk_days ì´í•˜ê°€ ë¨ (risk_reached)  â† risk_entry_date ë„ë‹¬ ì¦‰ì‹œ íŒë§¤ ì¤‘ë‹¨

    ë°˜í™˜:
      - detail_df: ë°°ì¹˜ë³„ íŒë§¤ ì‹œì‘/ì¢…ë£Œ/ì¤‘ë‹¨ì‚¬ìœ /ì”ëŸ‰/ìœ„í—˜ì§„ì…ì¼ ë“± ì´ë ¥
      - updated_df: ì‹œë®¬ë ˆì´ì…˜ í›„ ë°°ì¹˜ë³„ ì”ëŸ‰(qty_col ì—…ë°ì´íŠ¸)
    """

    if today is None:
        today = datetime.now().date()
    elif isinstance(today, datetime):
        today = today.date()

    df0 = df.copy()

    # ìˆ«ìí˜• ì •ë¦¬ (NaN ë°©ì–´)
    df0[days_col] = pd.to_numeric(df0[days_col], errors="coerce").fillna(0).astype(int)
    df0[qty_col] = pd.to_numeric(df0[qty_col], errors="coerce").fillna(0.0)
    df0[monthly_sales_col] = pd.to_numeric(df0[monthly_sales_col], errors="coerce").fillna(0.0)

    detail_rows = []
    updated = df0.copy()

    grp_cols = list(product_cols)

    for prod_key, g in df0.groupby(grp_cols, dropna=False):
        g = g.copy()

        # (1) ë°°ì¹˜: ìœ íš¨ê¸°í•œ ì§§ì€ ìˆœ ì •ë ¬ (FEFO)
        g = g.sort_values(days_col, ascending=True)

        # ì œí’ˆ íŒë§¤ëŸ‰: ë°°ì¹˜ë§ˆë‹¤ ë™ì¼í•˜ë‹¤ê³  ê°€ì •(ëŒ€í‘œê°’ ì‚¬ìš©)
        monthly_sales = float(g[monthly_sales_col].iloc[0]) if len(g) else 0.0

        # ì´ ì œí’ˆì˜ ì‹œê°„ì€ "ì˜¤ëŠ˜"ë¶€í„° ì‹œì‘
        current_date = today

        # ë°°ì¹˜ ìƒíƒœ ì €ì¥
        batches = []
        for _, row in g.iterrows():
            init_days = int(row[days_col])
            init_qty = float(row[qty_col])
            batches.append({
                "prod_key": prod_key,
                "batch": row[batch_col],
                "init_days": init_days,
                "qty": init_qty
            })

        # helper: íŠ¹ì • ë‚ ì§œì—ì„œ ë‚¨ì€ ì¼ìˆ˜ ê³„ì‚°(ì‹œê°„ ê²½ê³¼ ë°˜ì˜)
        def remaining_days(init_days, date_):
            return init_days - (date_ - today).days

        # ë°°ì¹˜ë“¤ì„ ìˆœì„œëŒ€ë¡œ ì²˜ë¦¬
        for b in batches:
            batch_id = b["batch"]
            init_days = b["init_days"]
            init_qty = b["qty"]

            # ìœ„í—˜ì§„ì…ì¼(ì–¸ì œ D-180 ë˜ëŠ”ì§€)
            if init_days <= risk_days:
                risk_entry_date = today
            else:
                risk_entry_date = today + timedelta(days=(init_days - risk_days))

            # ë°°ì¹˜ì— ë„ì°©í•œ ì‹œì (í˜„ì¬ì‹œê°„)ì—ì„œ ë‚¨ì€ ì¼ìˆ˜
            days_now = remaining_days(init_days, current_date)

            # ê¸°ë¡ìš© ë³€ìˆ˜
            sell_start_date = None
            sell_end_date = None
            stop_reason = None
            qty_sold_total = 0.0
            months_sold = 0
            sold_days_total = 0  # âœ… ë¶€ë¶„íŒë§¤ë¥¼ ìœ„í•´ ì‹¤ì œ íŒë§¤ì¼ìˆ˜ ëˆ„ì 

            # íŒë§¤ëŸ‰ 0ì´ë©´ íŒë§¤ ë¶ˆê°€
            if monthly_sales <= 0:
                sell_start_date = None
                sell_end_date = current_date
                stop_reason = "no_sales"
                days_left_at_stop = remaining_days(init_days, current_date)

                detail_rows.append({
                    product_cols[0]: prod_key[0] if isinstance(prod_key, tuple) else prod_key,
                    product_cols[1]: prod_key[1] if isinstance(prod_key, tuple) and len(prod_key) > 1 else None,
                    batch_col: batch_id,
                    "init_qty": init_qty,
                    "init_days": init_days,
                    "risk_entry_date": risk_entry_date,
                    "sell_start_date": sell_start_date,
                    "sell_end_date": sell_end_date,
                    "months_sold": months_sold,
                    "sold_days_total": sold_days_total,
                    "qty_sold": qty_sold_total,
                    "remaining_qty": max(0.0, b["qty"]),
                    "days_left_at_stop": days_left_at_stop,
                    "stop_reason": stop_reason
                })
                continue

            # ì´ë¯¸ ìœ„í—˜ êµ¬ê°„ì´ë©´ ì‹œì‘ë„ ëª»í•¨
            if days_now <= risk_days:
                sell_start_date = None
                sell_end_date = current_date
                stop_reason = "risk_reached_before_start"
                days_left_at_stop = days_now

                detail_rows.append({
                    product_cols[0]: prod_key[0] if isinstance(prod_key, tuple) else prod_key,
                    product_cols[1]: prod_key[1] if isinstance(prod_key, tuple) and len(prod_key) > 1 else None,
                    batch_col: batch_id,
                    "init_qty": init_qty,
                    "init_days": init_days,
                    "risk_entry_date": risk_entry_date,
                    "sell_start_date": sell_start_date,
                    "sell_end_date": sell_end_date,
                    "months_sold": months_sold,
                    "sold_days_total": sold_days_total,
                    "qty_sold": qty_sold_total,
                    "remaining_qty": max(0.0, b["qty"]),
                    "days_left_at_stop": days_left_at_stop,
                    "stop_reason": stop_reason
                })
                continue

            # (2)(3)(4) íŒë§¤ ì‹œë®¬ë ˆì´ì…˜
            sell_start_date = current_date
            daily_sales = monthly_sales / step_days if step_days > 0 else 0.0

            while True:
                days_now = remaining_days(init_days, current_date)

                # âœ… ìœ„í—˜ ë„ë‹¬(=D-180 ì´í•˜) ì¦‰ì‹œ íŒë§¤ ì¤‘ë‹¨
                if days_now <= risk_days:
                    sell_end_date = current_date
                    stop_reason = "risk_reached"
                    break

                # ì¬ê³  0ì´ë©´ ì¢…ë£Œ
                if b["qty"] <= 0:
                    sell_end_date = current_date
                    stop_reason = "sold_out"
                    break

                next_date = current_date + timedelta(days=step_days)
                days_until_risk = (risk_entry_date - current_date).days  # ìœ„í—˜ì§„ì…ê¹Œì§€ ë‚¨ì€ ì¼ìˆ˜

                # âœ… ì´ë²ˆ 30ì¼ êµ¬ê°„ ì¤‘ê°„ì— risk_entry_dateê°€ ë“¤ì–´ì˜¤ë©´:
                # risk_entry_date ì§ì „ê¹Œì§€ë§Œ "ë¶€ë¶„íŒë§¤(ì¼í• )" í›„ ì¦‰ì‹œ ì¤‘ë‹¨
                if 0 < days_until_risk < step_days:
                    sellable_days = days_until_risk
                    sellable_qty = daily_sales * sellable_days

                    sell_qty = min(b["qty"], sellable_qty)
                    b["qty"] -= sell_qty
                    qty_sold_total += sell_qty
                    sold_days_total += sellable_days

                    # ì‹œê°„ì€ ìœ„í—˜ì§„ì…ì¼ë¡œ ì •í™•íˆ ì´ë™
                    current_date = risk_entry_date

                    sell_end_date = current_date
                    stop_reason = "risk_reached"
                    break

                # âœ… ì´ë²ˆ êµ¬ê°„ì—ëŠ” ìœ„í—˜ì§„ì… ì—†ìŒ => 30ì¼ì¹˜ ì •ìƒ íŒë§¤
                sell_qty = min(b["qty"], monthly_sales)
                b["qty"] -= sell_qty
                qty_sold_total += sell_qty
                months_sold += 1
                sold_days_total += step_days

                current_date = next_date

            days_left_at_stop = remaining_days(init_days, sell_end_date)

            detail_rows.append({
                product_cols[0]: prod_key[0] if isinstance(prod_key, tuple) else prod_key,
                product_cols[1]: prod_key[1] if isinstance(prod_key, tuple) and len(prod_key) > 1 else None,
                batch_col: batch_id,
                "init_qty": init_qty,
                "init_days": init_days,
                "risk_entry_date": risk_entry_date,
                "sell_start_date": sell_start_date,
                "sell_end_date": sell_end_date,
                "months_sold": months_sold,
                "sold_days_total": sold_days_total,
                "qty_sold": qty_sold_total,
                "remaining_qty": max(0.0, b["qty"]),
                "days_left_at_stop": days_left_at_stop,
                "stop_reason": stop_reason
            })

        # updated_dfì— ë°˜ì˜: ì œí’ˆ/ë°°ì¹˜ ê¸°ì¤€ìœ¼ë¡œ qty ì—…ë°ì´íŠ¸
        for b in batches:
            updated.loc[
                (updated[product_cols[0]] == (prod_key[0] if isinstance(prod_key, tuple) else prod_key)) &
                (updated[batch_col] == b["batch"]),
                qty_col
            ] = max(0.0, b["qty"])

    detail_df = pd.DataFrame(detail_rows)
    return detail_df, updated

# -----------------------------------------------------
# 5ï¸âƒ£ ì¬ê³ ì†Œì§„ì‹œë®¬ë ˆì´ì…˜ + ì†Œë¶„ë¥˜ ê°„íŠ¸ ì°¨íŠ¸ (ON)
# -----------------------------------------------------
# =========================================================
# 0) ì¤€ë¹„: ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰ â†’ gantt_df ìƒì„±
# =========================================================
base_today = datetime.now().date()

detail_df, df_after = simulate_batches_by_product(
    df=final_df,
    product_cols=(MAT_COL, MAT_NAME_COL),
    batch_col=BATCH_COL,
    days_col=DAYS_COL,
    qty_col=QTY_SRC_COL,
    monthly_sales_col="3í‰íŒ",
    risk_days=180,
    step_days=30,
    today=base_today,
)

gantt_df = detail_df.copy()

# ì†Œë¶„ë¥˜ ë¶™ì´ê¸°
if "ì†Œë¶„ë¥˜" not in gantt_df.columns:
    mat_to_cls = final_df[[MAT_COL, "ëŒ€ë¶„ë¥˜", "ì†Œë¶„ë¥˜"]].drop_duplicates(subset=[MAT_COL])
    gantt_df = gantt_df.merge(mat_to_cls, on=MAT_COL, how="left")
    gantt_df["ì†Œë¶„ë¥˜"] = gantt_df["ì†Œë¶„ë¥˜"].fillna("ë¯¸ë¶„ë¥˜")

# no_sales ì œì™¸
if "stop_reason" in gantt_df.columns:
    gantt_df = gantt_df[gantt_df["stop_reason"] != "no_sales"].copy()

# ë‚ ì§œ ì»¬ëŸ¼ datetime ë³€í™˜
for c in ["sell_start_date", "sell_end_date", "risk_entry_date"]:
    if c in gantt_df.columns:
        gantt_df[c] = pd.to_datetime(gantt_df[c], errors="coerce")

# íŒë§¤ ì‹œì‘/ë ì—†ëŠ” í–‰ ì œì™¸
gantt_df = gantt_df.dropna(subset=["sell_start_date", "sell_end_date"]).copy()

# =========================================================
# 1) ì†Œë¶„ë¥˜ ì„ íƒ UI
# =========================================================
with st.container():
    st.markdown("### ğŸ—“ï¸ ì†Œë¶„ë¥˜ë³„ ë°°ì¹˜ íŒë§¤ ì‹œë®¬ë ˆì´ì…˜")
    
    gantt_df["mat_label"] = gantt_df[MAT_COL].astype(str) + " | " + gantt_df[MAT_NAME_COL].astype(str)

# âœ… ë¶€ì§„ì¬ê³ (remaining_qty > 0)ê°€ ìˆëŠ” ì†Œë¶„ë¥˜ë§Œ í•„í„°ë§
risk_subcats = gantt_df[gantt_df["remaining_qty"].fillna(0) > 0]["ì†Œë¶„ë¥˜"].unique().tolist()

subcat_meta = (
    gantt_df[gantt_df["ì†Œë¶„ë¥˜"].isin(risk_subcats)]
    .fillna("ë¯¸ë¶„ë¥˜")
    .drop_duplicates(subset=["ì†Œë¶„ë¥˜"], keep="first")
    .copy()
)

if subcat_meta.empty:
    st.info("í˜„ì¬ ë¶„ì„ ë°ì´í„° ì¤‘ 'ë¶€ì§„ì¬ê³ 'ê°€ ë°œìƒí•˜ëŠ” í’ˆëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

subcat_meta["ui_label"] = (
    subcat_meta["ëŒ€ë¶„ë¥˜"].astype(str)
    + "("
    + subcat_meta["ì†Œë¶„ë¥˜"].astype(str)
    + ") | "
    + subcat_meta["ì†Œë¶„ë¥˜"].astype(str)
)

label_to_subcat = dict(zip(subcat_meta["ui_label"], subcat_meta["ì†Œë¶„ë¥˜"]))
ui_options = ["(ì „ì²´)"] + sorted(subcat_meta["ui_label"].unique().tolist())
selected_ui = st.selectbox("ì†Œë¶„ë¥˜ ì„ íƒ (ë¶€ì§„ì¬ê³  ë°œìƒ ì†Œë¶„ë¥˜ë§Œ í‘œì‹œ)", options=ui_options)

selected_subcat = None if selected_ui == "(ì „ì²´)" else label_to_subcat[selected_ui]

# (ì „ì²´) ì„ íƒ ì‹œì—ë„ 'ë¶€ì§„ì¬ê³ 'ê°€ ìˆëŠ” ë°ì´í„°ë§Œ ë³´ì—¬ì£¼ê³  ì‹¶ë‹¤ë©´ ì•„ë˜ í•„í„° ì¶”ê°€ ê°€ëŠ¥
# ì—¬ê¸°ì„œëŠ” ì‚¬ìš©ìê°€ "í•´ë‹¹ ì• ë“¤ë§Œ ì„ íƒí•´ì„œ... ë³´ì—¬ì£¼ë„ë¡" í–ˆìœ¼ë¯€ë¡œ, 
# view_df ìì²´ë„ ë¶€ì§„ì¬ê³ ê°€ ìˆëŠ” subcatë“¤ë¡œ ì œí•œí•©ë‹ˆë‹¤.
if selected_subcat is None:
    view_df = gantt_df[gantt_df["ì†Œë¶„ë¥˜"].isin(risk_subcats)].copy()
else:
    view_df = gantt_df[gantt_df["ì†Œë¶„ë¥˜"].fillna("ë¯¸ë¶„ë¥˜") == selected_subcat].copy()

if selected_subcat is not None:
    st.caption(
        f"ì„ íƒ ì†Œë¶„ë¥˜: {selected_ui}  |  ì œí’ˆ ìˆ˜: {view_df[MAT_COL].nunique()}ê°œ / ë°°ì¹˜ ìˆ˜: {view_df[BATCH_COL].nunique()}ê°œ"
    )

# =========================================================
# 1.5) ë¶€ì§„ì¬ê³  ìš”ì•½ ì§€í‘œ (KPI) - (ì „ì²´) ë° ì†Œë¶„ë¥˜ ê³µí†µ
# =========================================================
risk_view_df = view_df[view_df["remaining_qty"].fillna(0) > 0].copy()
if not risk_view_df.empty:
    # ë‹¨ìœ„ì›ê°€ ì •ë³´ê°€ ì—†ìœ¼ë©´ final_dfì—ì„œ ê°€ì ¸ì˜´
    if "ë‹¨ìœ„ì›ê°€" not in risk_view_df.columns:
        unit_cost_map = (
            final_df[[MAT_COL, "ë‹¨ìœ„ì›ê°€"]]
            .dropna(subset=[MAT_COL, "ë‹¨ìœ„ì›ê°€"])
            .drop_duplicates(subset=[MAT_COL])
        )
        risk_view_df = risk_view_df.merge(unit_cost_map, on=MAT_COL, how="left")

    risk_view_df["ë‹¨ìœ„ì›ê°€"] = pd.to_numeric(risk_view_df["ë‹¨ìœ„ì›ê°€"], errors="coerce").fillna(0)
    risk_view_df["remaining_amount"] = risk_view_df["remaining_qty"].fillna(0) * risk_view_df["ë‹¨ìœ„ì›ê°€"]

    kpi1, kpi2, kpi3 = st.columns(3)
    with kpi1:
        st.metric("ë¶€ì§„ì¬ê³  ë°°ì¹˜ ìˆ˜", f"{risk_view_df[BATCH_COL].nunique()}ê°œ")
    with kpi2:
        st.metric("ì˜ˆìƒ ë¶€ì§„ì¬ê³  ê¸ˆì•¡ í•©ê³„", f"â‚©{risk_view_df['remaining_amount'].sum():,.0f}")
    with kpi3:
        first_date = risk_view_df["risk_entry_date"].min()
        st.metric("ê°€ì¥ ë¹ ë¥¸ ë¶€ì§„ì¬ê³  ì§„ì…ì¼", first_date.strftime("%Y-%m-%d") if pd.notna(first_date) else "-")
else:
    st.success("âœ… ì„ íƒí•œ ë²”ìœ„ ë‚´ì—ëŠ” ë¶€ì§„ì¬ê³ ê°€ ë°œìƒí•  ê²ƒìœ¼ë¡œ ì˜ˆìƒë˜ëŠ” ë°°ì¹˜ê°€ ì—†ìŠµë‹ˆë‹¤.")

# =========================================================
# 2) [ë°©ë²• A] ìµœì†Œ ë°°ìˆ˜(minmult_df) ë¨¼ì € ê³„ì‚°
#    â†’ ê·¸ ë‹¤ìŒ ìš”ì•½ í‘œ(table_df)ì— mergeí•´ì„œ "í•œ í‘œ"ë¡œ ì¶œë ¥
# =========================================================
if selected_ui != "(ì „ì²´)" and (not view_df.empty):

    # âœ… ê¸°ì¤€(1.0x)ì—ì„œ ë¶€ì§„ì¬ê³ ê°€ ë‚¨ëŠ” rowë§Œ
    base_risk_df = view_df[view_df["remaining_qty"].fillna(0) > 0].copy()

    if base_risk_df.empty:
        st.success("í˜„ì¬ ì†Œë¶„ë¥˜ëŠ” ê¸°ì¤€ í‰íŒ(1.0x) ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ë¶€ì§„ì¬ê³ ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        # ---------------------------------------------------------
        # (A-1) ìµœì†Œ ë°°ìˆ˜ ê³„ì‚° ëŒ€ìƒ ìì¬ ëª©ë¡
        # ---------------------------------------------------------
        risk_mats = base_risk_df[MAT_COL].dropna().unique().tolist()
        sub_df_base = final_df[final_df[MAT_COL].isin(risk_mats)].copy()

        # st.write("### ğŸ¯ (ë¶€ì§„ì¬ê³  ë°œìƒ ìì¬ë§Œ) ë¶€ì§„ì¬ê³  0ì„ ìœ„í•œ ìµœì†Œ í‰íŒ ë°°ìˆ˜ (ì†Œë¶„ë¥˜ ê¸°ì¤€)")
        # st.caption("â€» ê¸°ì¤€(1.0x)ì—ì„œ ë¶€ì§„ì¬ê³ ê°€ ë°œìƒí•œ ìì¬ë§Œ ëŒ€ìƒìœ¼ë¡œ ìµœì†Œ ë°°ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.")

        if "3í‰íŒ" not in sub_df_base.columns:
            st.warning("final_dfì— '3í‰íŒ' ì»¬ëŸ¼ì´ ì—†ì–´ ìµœì†Œ ë°°ìˆ˜ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            minmult_df = pd.DataFrame(columns=["ìì¬ì½”ë“œ", "ìì¬ë‚´ì—­", "3í‰íŒ", "ë¶€ì§„ì¬ê³  0ì„ ìœ„í•œ ìµœì†Œ ë°°ìˆ˜(ì¶”ì •)", "ë¹„ê³ "])
        else:
            sales_series = pd.to_numeric(sub_df_base["3í‰íŒ"], errors="coerce").fillna(0)
            if sales_series.sum() <= 0:
                st.warning("ì´ ì†Œë¶„ë¥˜ëŠ” 3í‰íŒ ê°’ì´ 0(ë˜ëŠ” ì—†ìŒ)ì´ë¼ ìµœì†Œ ë°°ìˆ˜ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                minmult_df = pd.DataFrame(columns=["ìì¬ì½”ë“œ", "ìì¬ë‚´ì—­", "3í‰íŒ", "ë¶€ì§„ì¬ê³  0ì„ ìœ„í•œ ìµœì†Œ ë°°ìˆ˜(ì¶”ì •)", "ë¹„ê³ "])
            else:
                # ---------- ìœ í‹¸ ----------
                def _risk_summary(detail_k: pd.DataFrame):
                    risk_k = detail_k[detail_k["remaining_qty"].fillna(0) > 0].copy()

                    risk_qty = float(
                        pd.to_numeric(risk_k["remaining_qty"], errors="coerce").fillna(0).sum()
                    ) if not risk_k.empty else 0.0

                    if (not risk_k.empty) and ("remaining_amount" in risk_k.columns):
                        risk_amt = float(pd.to_numeric(risk_k["remaining_amount"], errors="coerce").fillna(0).sum())
                    else:
                        if (not risk_k.empty) and ("ë‹¨ìœ„ì›ê°€" in risk_k.columns):
                            uc = pd.to_numeric(risk_k["ë‹¨ìœ„ì›ê°€"], errors="coerce").fillna(0)
                            rq = pd.to_numeric(risk_k["remaining_qty"], errors="coerce").fillna(0)
                            risk_amt = float((rq * uc).sum())
                        else:
                            risk_amt = np.nan
                    return {"risk_qty": risk_qty, "risk_amt": risk_amt}

                def _run_sim_mat(df_mat: pd.DataFrame, mult: float):
                    df_in = df_mat.copy()
                    df_in["_sales_k"] = pd.to_numeric(df_in["3í‰íŒ"], errors="coerce").fillna(0) * mult

                    detail_k, _ = simulate_batches_by_product(
                        df=df_in,
                        product_cols=(MAT_COL, MAT_NAME_COL),
                        batch_col=BATCH_COL,
                        days_col=DAYS_COL,
                        qty_col=QTY_SRC_COL,
                        monthly_sales_col="_sales_k",
                        risk_days=180,
                        step_days=30,
                        today=base_today,
                    )
                    return detail_k

                def _risk_metric_mat(df_mat: pd.DataFrame, mult: float) -> float:
                    detail_k = _run_sim_mat(df_mat, mult)
                    s = _risk_summary(detail_k)
                    if not np.isnan(s["risk_amt"]):
                        return s["risk_amt"]
                    return s["risk_qty"]

                def _find_min_multiplier_mat(df_mat: pd.DataFrame, lo=1.0, hi=6.0, tol=1e-3, max_iter=50):
                    if _risk_metric_mat(df_mat, lo) <= 0:
                        return lo
                    if _risk_metric_mat(df_mat, hi) > 0:
                        return None

                    a, b = lo, hi
                    for _ in range(max_iter):
                        mid = (a + b) / 2
                        v = _risk_metric_mat(df_mat, mid)
                        if v > 0:
                            a = mid
                        else:
                            b = mid
                        if (b - a) < tol:
                            break
                    return b

                # ---------- ê³„ì‚° ----------
                minmult_rows = []
                for mat in sorted(sub_df_base[MAT_COL].dropna().unique().tolist()):
                    df_mat = sub_df_base[sub_df_base[MAT_COL] == mat].copy()

                    mat_name = ""
                    if MAT_NAME_COL in df_mat.columns and df_mat[MAT_NAME_COL].notna().any():
                        mat_name = str(df_mat[MAT_NAME_COL].dropna().iloc[0])

                    base_sales = float(pd.to_numeric(df_mat["3í‰íŒ"], errors="coerce").fillna(0).iloc[0])

                    if base_sales <= 0:
                        minmult_rows.append({
                            "ìì¬ì½”ë“œ": mat,
                            "ìì¬ë‚´ì—­": mat_name,
                            "3í‰íŒ": base_sales,
                            "ë¶€ì§„ì¬ê³  0ì„ ìœ„í•œ ìµœì†Œ ë°°ìˆ˜(ì¶”ì •)": "- (3í‰íŒ=0)",
                            "ë¹„ê³ ": "íŒë§¤ëŸ‰ 0 â†’ ë°°ìˆ˜ë¡œ ê°œì„  ë¶ˆê°€",
                        })
                        continue

                    min_m = _find_min_multiplier_mat(df_mat, lo=1.0, hi=6.0)

                    minmult_rows.append({
                        "ìì¬ì½”ë“œ": mat,
                        "ìì¬ë‚´ì—­": mat_name,
                        "3í‰íŒ": base_sales,
                        "ë¶€ì§„ì¬ê³  0ì„ ìœ„í•œ ìµœì†Œ ë°°ìˆ˜(ì¶”ì •)": "-" if min_m is None else f"{min_m:.2f}x",
                        "ë¹„ê³ ": "20.0xê¹Œì§€ë„ 0ì´ ì•ˆ ë¨" if min_m is None else "D-180 ê¸°ì¤€ ì”ì¡´ 0 ë‹¬ì„±",
                    })

                minmult_df = pd.DataFrame(minmult_rows).sort_values(["ìì¬ì½”ë“œ"]).reset_index(drop=True)

        # ---------------------------------------------------------
        # (A-2) ìš”ì•½í‘œ(table_df) ìƒì„± + minmult_dfë¥¼ "í•œ í‘œ"ë¡œ merge
        # ---------------------------------------------------------
        st.write(f"### ğŸ§¾ ë¶€ì§„ì¬ê³  ìš”ì•½ (ì†Œë¶„ë¥˜: {selected_subcat})")

        summary_df = view_df[view_df["remaining_qty"].fillna(0) > 0].copy()
        summary_df = summary_df.sort_values(["risk_entry_date", "init_days"], ascending=[True, True])

        UNIT_COST_COL = "ë‹¨ìœ„ì›ê°€"
        if UNIT_COST_COL not in summary_df.columns:
            unit_cost_map = (
                final_df[[MAT_COL, UNIT_COST_COL]]
                .dropna(subset=[MAT_COL, UNIT_COST_COL])
                .drop_duplicates(subset=[MAT_COL])
            )
            summary_df = summary_df.merge(unit_cost_map, on=MAT_COL, how="left")

        summary_df[UNIT_COST_COL] = pd.to_numeric(summary_df[UNIT_COST_COL], errors="coerce").fillna(0)
        summary_df["remaining_amount"] = summary_df["remaining_qty"].fillna(0) * summary_df[UNIT_COST_COL]

        # KPI (ìœ„ì—ì„œ ê³µí†µìœ¼ë¡œ í‘œì‹œí•˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ìƒì„¸ í‘œ ì œëª©ë§Œ ìœ ì§€í•˜ê±°ë‚˜ ìƒëµ ê°€ëŠ¥)
        # ì—¬ê¸°ì„œëŠ” ì´ë¯¸ ìœ„ì—ì„œ ìš”ì•½ ì§€í‘œë¥¼ ë³´ì—¬ì£¼ì—ˆìœ¼ë¯€ë¡œ, í‘œ ë°”ë¡œ ìœ„ì—ëŠ” ì œëª©ë§Œ ë‚¨ê¹ë‹ˆë‹¤.
        # st.write(f"### ğŸ§¾ ë¶€ì§„ì¬ê³  ìƒì„¸ (ì†Œë¶„ë¥˜: {selected_subcat})")
        # ëŒ€ì‹  risk_view_dfë¥¼ í™œìš©í•˜ì—¬ ì•„ë˜ í‘œ(summary_df)ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤.
        summary_df = risk_view_df.copy()
        summary_df = summary_df.sort_values(["risk_entry_date", "init_days"], ascending=[True, True])

        # table_df
        table_df = summary_df.copy()
        table_df = table_df.rename(columns={
            MAT_COL: "ìì¬ì½”ë“œ",
            MAT_NAME_COL: "ìì¬ë‚´ì—­",
            BATCH_COL: "ë°°ì¹˜",
            "risk_entry_date": "ë¶€ì§„ì¬ê³  ì§„ì…ì¼",
            "remaining_qty": "ì˜ˆìƒë¶€ì§„ì¬ê³ ëŸ‰",
            "remaining_amount": "ì˜ˆìƒë¶€ì§„ê¸ˆì•¡",
        })

        # âœ… minmult_df(ìì¬ ë‹¨ìœ„) ë¶™ì´ê¸°
        mult_map = minmult_df[["ìì¬ì½”ë“œ", "3í‰íŒ", "ë¶€ì§„ì¬ê³  0ì„ ìœ„í•œ ìµœì†Œ ë°°ìˆ˜(ì¶”ì •)", "ë¹„ê³ "]].drop_duplicates(subset=["ìì¬ì½”ë“œ"])
        table_df = table_df.merge(mult_map, on="ìì¬ì½”ë“œ", how="left")

        # âœ… ìµœì†Œë°°ìˆ˜ ë¬¸ìì—´("1.20x") -> float(1.20)ë¡œ íŒŒì‹±
        def parse_multiplier(v):
            if pd.isna(v):
                return np.nan
            s = str(v).strip()
            # "-", "- (3í‰íŒ=0)" ê°™ì€ ì¼€ì´ìŠ¤
            if s == "-" or s.startswith("-"):
                return np.nan
            m = re.search(r"([0-9]*\.?[0-9]+)\s*x", s.lower())
            return float(m.group(1)) if m else np.nan

        # 1) ìˆ«ìí˜• 3í‰íŒ í™•ë³´ (ê³„ì‚°ìš© ì›ë³¸)
        sales_num = pd.to_numeric(table_df["3í‰íŒ"], errors="coerce")

        # 2) ìµœì†Œë°°ìˆ˜ float
        mult_num = table_df["ë¶€ì§„ì¬ê³  0ì„ ìœ„í•œ ìµœì†Œ ë°°ìˆ˜(ì¶”ì •)"].apply(parse_multiplier)

        # 3) ê¶Œì¥ íŒë§¤ëŸ‰ / íŒë§¤ ê°œì„ ìœ¨(%)
        table_df["ê¶Œì¥ íŒë§¤ëŸ‰"] = (sales_num * mult_num).round(0)
        table_df["íŒë§¤ ê°œì„ ìœ¨(%)"] = ((mult_num - 1.0) * 100).round(0)

        # 4) í‘œì‹œ í¬ë§· (ìµœì†Œë°°ìˆ˜ ì—†ëŠ” ì• ë“¤ì€ ë¹ˆì¹¸)
        table_df["ê¶Œì¥ íŒë§¤ëŸ‰"] = pd.to_numeric(table_df["ê¶Œì¥ íŒë§¤ëŸ‰"], errors="coerce").apply(
            lambda x: f"{int(x):,}" if pd.notna(x) else "-"
        )
        table_df["íŒë§¤ ê°œì„ ìœ¨(%)"] = pd.to_numeric(table_df["íŒë§¤ ê°œì„ ìœ¨(%)"], errors="coerce").apply(
            lambda x: f"{int(x)}% ì¦ê°€" if pd.notna(x) else "-"
        )

        # í‘œì‹œ ì»¬ëŸ¼
        show_cols = [
                    "ìì¬ì½”ë“œ",
                    "ìì¬ë‚´ì—­",
                    "ë°°ì¹˜",
                    "3í‰íŒ",
                    "ë¶€ì§„ì¬ê³  ì§„ì…ì¼",
                    "ì˜ˆìƒë¶€ì§„ì¬ê³ ëŸ‰",
                    "ì˜ˆìƒë¶€ì§„ê¸ˆì•¡",
                    "ê¶Œì¥ íŒë§¤ëŸ‰",
                    "íŒë§¤ ê°œì„ ìœ¨(%)",
                ]
        show_cols = [c for c in show_cols if c in table_df.columns]
        table_df = table_df[show_cols].copy()

        # ì •ë ¬
        if "ë¶€ì§„ì¬ê³  ì§„ì…ì¼" in table_df.columns:
            table_df = table_df.sort_values(["ë¶€ì§„ì¬ê³  ì§„ì…ì¼", "ì˜ˆìƒë¶€ì§„ê¸ˆì•¡"], ascending=[True, False])

        # í¬ë§·
        if "ë¶€ì§„ì¬ê³  ì§„ì…ì¼" in table_df.columns:
            table_df["ë¶€ì§„ì¬ê³  ì§„ì…ì¼"] = pd.to_datetime(table_df["ë¶€ì§„ì¬ê³  ì§„ì…ì¼"], errors="coerce").dt.strftime("%Y-%m-%d")

        if "ì˜ˆìƒë¶€ì§„ì¬ê³ ëŸ‰" in table_df.columns:
            table_df["ì˜ˆìƒë¶€ì§„ì¬ê³ ëŸ‰"] = (
                pd.to_numeric(table_df["ì˜ˆìƒë¶€ì§„ì¬ê³ ëŸ‰"], errors="coerce")
                .fillna(0).astype(int).map(lambda x: f"{x:,}")
            )

        if "ì˜ˆìƒë¶€ì§„ê¸ˆì•¡" in table_df.columns:
            table_df["ì˜ˆìƒë¶€ì§„ê¸ˆì•¡"] = (
                pd.to_numeric(table_df["ì˜ˆìƒë¶€ì§„ê¸ˆì•¡"], errors="coerce")
                .fillna(0).map(lambda x: f"â‚©{x:,.0f}")
            )

        if "3í‰íŒ" in table_df.columns:
            # minmult_dfì—ì„œ ë“¤ì–´ì˜¨ 3í‰íŒì€ ìˆ«ìì¼ ìˆ˜ë„/ë¬¸ìì¼ ìˆ˜ë„ ìˆì–´ì„œ ì•ˆì „ ë³€í™˜
            _sales = pd.to_numeric(table_df["3í‰íŒ"], errors="coerce").fillna(0).astype(int)
            table_df["3í‰íŒ"] = _sales.map(lambda x: f"{x:,}")

        # âœ… í•œ í‘œ ì¶œë ¥
        st.dataframe(table_df, use_container_width=True, height=320)

# =========================================================
# 3) ê°„íŠ¸ ì°¨íŠ¸ ìƒì„±/í‘œì‹œ
# =========================================================
if view_df.empty:
    st.info("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (no_sales ì œì™¸ í›„ ë‚¨ì€ ë°°ì¹˜ê°€ ì—†ê±°ë‚˜, sell_start/endê°€ ë¹„ì–´ìˆì„ ìˆ˜ ìˆì–´ìš”.)")
else:
    view_df = view_df.copy()
    view_df["expiry_date"] = pd.to_datetime(base_today) + pd.to_timedelta(view_df["init_days"], unit="D")

    sales_bar = view_df.copy()
    sales_bar["phase"] = "íŒë§¤ê¸°ê°„"
    sales_bar = sales_bar.rename(columns={"sell_start_date": "x_start", "sell_end_date": "x_end"})

    sluggish_bar = view_df.copy()
    sluggish_bar = sluggish_bar[sluggish_bar["remaining_qty"].fillna(0) > 0].copy()
    sluggish_bar = sluggish_bar.dropna(subset=["risk_entry_date", "expiry_date"]).copy()
    sluggish_bar["phase"] = "ë¶€ì§„ì¬ê³  êµ¬ê°„"
    sluggish_bar = sluggish_bar.rename(columns={"risk_entry_date": "x_start", "expiry_date": "x_end"})

    plot_df = pd.concat([sales_bar, sluggish_bar], ignore_index=True)
    plot_df["batch_label"] = plot_df["mat_label"].astype(str) + " | " + plot_df[BATCH_COL].astype(str)

    plot_df = plot_df.sort_values(["mat_label", "init_days", "phase"], ascending=[True, True, True])

    color_map = {"íŒë§¤ê¸°ê°„": "#4C78A8", "ë¶€ì§„ì¬ê³  êµ¬ê°„": "#E45756"}

    order_base = plot_df[plot_df["phase"] == "íŒë§¤ê¸°ê°„"].copy()
    if order_base.empty:
        order_base = plot_df.copy()

    order_meta = (
        order_base[["batch_label", "mat_label", "x_start"]]
        .drop_duplicates(subset=["batch_label"])
        .rename(columns={"x_start": "sell_start"})
    )

    order_meta = order_meta.sort_values(["mat_label", "sell_start", "batch_label"], ascending=[True, True, True])
    y_order = order_meta["batch_label"].tolist()

    plot_df = plot_df.merge(order_meta[["batch_label", "sell_start"]], on="batch_label", how="left")
    plot_df = plot_df.sort_values(["mat_label", "sell_start", "phase"], ascending=[True, True, True])

    fig = px.timeline(
        plot_df,
        x_start="x_start",
        x_end="x_end",
        y="batch_label",
        color="phase",
        color_discrete_map=color_map,
        hover_data={
            MAT_COL: True,
            MAT_NAME_COL: True,
            "ì†Œë¶„ë¥˜": True if "ì†Œë¶„ë¥˜" in plot_df.columns else False,
            "stop_reason": True if "stop_reason" in plot_df.columns else False,
            "init_days": True if "init_days" in plot_df.columns else False,
            "init_qty": True if "init_qty" in plot_df.columns else False,
            "qty_sold": True if "qty_sold" in plot_df.columns else False,
            "remaining_qty": True if "remaining_qty" in plot_df.columns else False,
            "sold_days_total": True if "sold_days_total" in plot_df.columns else False,
            "risk_entry_date": True if "risk_entry_date" in plot_df.columns else False,
            "expiry_date": True if "expiry_date" in plot_df.columns else False,
        },
    )

    fig.update_yaxes(categoryorder="array", categoryarray=y_order)
    fig.update_yaxes(autorange="reversed")

    # âœ… ë°°ì¹˜ ìˆ˜ì— ë”°ë¥¸ ë™ì  ë†’ì´ ê³„ì‚° (ìµœì†Œ 400px, ë°°ì¹˜ë‹¹ 30px + ì—¬ë°±)
    dynamic_height = max(400, len(y_order) * 30 + 120)

    fig.update_layout(
        height=dynamic_height,
        margin=dict(t=50, b=50, l=10, r=10),
        xaxis_title="Simulation Timeline",
        yaxis_title="Material | Batch",
        xaxis_title_font=dict(size=14),
        yaxis_title_font=dict(size=14),
        legend=dict(
            orientation="h",
            yanchor="bottom",
            y=1.02,
            xanchor="right",
            x=1
        ),
        plot_bgcolor="white",
        paper_bgcolor="white",
    )

    fig.update_xaxes(
        showgrid=True, 
        gridcolor="#f1f5f9", 
        gridwidth=1,
        dtick="M1", # ë§¤ë‹¬ ê·¸ë¦¬ë“œ
        tickformat="%Y-%m",
        tickfont=dict(size=12)
    )
    fig.update_yaxes(
        showgrid=True, 
        gridcolor="#f1f5f9", 
        gridwidth=1,
        tickfont=dict(size=11)
    )
    
    # ë°” í…Œë‘ë¦¬ ë° íˆ¬ëª…ë„ ì¡°ì ˆ
    fig.update_traces(marker_line_color='white', marker_line_width=1, opacity=0.9)

    st.plotly_chart(fig, use_container_width=True)

# -----------------------------------------------------
# 7ï¸âƒ£ ê°€ê³µëœ ë°ì´í„° ìµœì¢… ë“±ë¡ (ê³„ì¸µ: ì—°ë„ -> ì›” -> ë¶„ì„íƒ€ì…) (ON)
# -----------------------------------------------------
if "stock_data" not in st.session_state:
    st.session_state["stock_data"] = {}

# 1. ì—°ë„ í´ë” ìƒì„±
if selected_year not in st.session_state["stock_data"]:
    st.session_state["stock_data"][selected_year] = {}

# 2. ì›” í´ë” ìƒì„±
if selected_month not in st.session_state["stock_data"][selected_year]:
    st.session_state["stock_data"][selected_year][selected_month] = {}

# 3. "ìœ íš¨ê¸°í•œ ë°ì´í„°"ë¼ëŠ” ì´ë¦„ìœ¼ë¡œ ìµœì¢… ì €ì¥
st.session_state["stock_data"][selected_year][selected_month]["ìœ íš¨ê¸°í•œ"] = {
    "df": final_df,
    "processed_at": datetime.now().strftime('%Y-%m-%d %H:%M:%S')
}

st.sidebar.success(f"âœ… {selected_year} {selected_month} ìœ íš¨ê¸°í•œ ë¶„ì„ ì™„ë£Œ")
with st.container():
    st.write("---")
    d1, d2, _ = st.columns([1, 1, 2])
    with d1:
        csv_bytes = final_df.to_csv(index=False).encode("utf-8-sig")
        st.download_button(
            label="â¬‡ï¸ CSV ë‹¤ìš´ë¡œë“œ", 
            data=csv_bytes, 
            file_name=f"{selected_year}_{selected_month}_ìœ íš¨ê¸°í•œ.csv", 
            mime="text/csv",
            use_container_width=True
        )

