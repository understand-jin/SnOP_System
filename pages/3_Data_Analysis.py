import streamlit as st
import pandas as pd
from datetime import datetime
import matplotlib.pyplot as plt
import seaborn as sns
import matplotlib.font_manager as fm
import os

st.set_page_config(page_title="S&OP - Data Analysis", layout="wide")
st.title("ğŸ“ˆ Data Analysis (Stock)")

# =====================================================
# âœ… dfs key (íŒŒì¼ëª… ê·¸ëŒ€ë¡œ)
# =====================================================
PRICE_DF_KEY = "1. ê²°ì‚° ì¬ê³ ìˆ˜ë¶ˆë¶€(ì›ê°€).xls"
STOCK_DF_KEY = "2. ë°°ì¹˜ ì¬ê³ ìˆ˜ë¶ˆë¶€(ë°°ì¹˜).xls"
EXPIRY_DF_KEY = "3. ì°½ê³ ë³„ ì¬ê³ í˜„í™©(ìœ íš¨ê¸°í•œ)_1.19.xls"

# =====================================================
# âœ… í‘œì¤€ ì»¬ëŸ¼ëª…
# =====================================================
BATCH_COL = "ë°°ì¹˜"
MAT_COL = "ìì¬"
MAT_NAME_COL = "ìì¬ ë‚´ì—­"
EXPIRY_COL = "ìœ íš¨ ê¸°í•œ"
QTY_SRC_COL = "Stock Quantity on Period End"
UNIT_COST_COL = "ë‹¨ìœ„ì›ê°€"
VALUE_COL = "Stock Value on Period End"
BUCKET_COL = "expiry_bucket"
DAYS_COL = "days_to_expiry"

# =====================================================
# âœ… í™˜ê²½ ì„¤ì • (í°íŠ¸ ë“±)
# =====================================================
def set_korean_font():
    font_path = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "assets", "fonts", "NanumGothic-Regular.ttf"))
    if os.path.exists(font_path):
        fm.fontManager.addfont(font_path)
        plt.rcParams["font.family"] = fm.FontProperties(fname=font_path).get_name()
    else:
        plt.rcParams["font.family"] = "Malgun Gothic"
    plt.rcParams["axes.unicode_minus"] = False

set_korean_font()
sns.set_theme(style="whitegrid", font=plt.rcParams["font.family"])

# =====================================================
# ğŸ› ï¸ ë°ì´í„° ì²˜ë¦¬ í•¨ìˆ˜
# =====================================================
def to_numeric_safe(s): return pd.to_numeric(s, errors="coerce").fillna(0)

def build_final_df(dfs):
    # 1. ë‹¨ìœ„ì›ê°€ ê³„ì‚° (1ë²ˆ íŒŒì¼)
    df_price = dfs[PRICE_DF_KEY]
    tmp = df_price[[MAT_COL, "ê¸°ë§(ìˆ˜ëŸ‰)", "ê¸°ë§(ê¸ˆì•¡)í•©ê³„"]].copy()
    tmp["ê¸°ë§(ìˆ˜ëŸ‰)"] = to_numeric_safe(tmp["ê¸°ë§(ìˆ˜ëŸ‰)"])
    tmp["ê¸°ë§(ê¸ˆì•¡)í•©ê³„"] = to_numeric_safe(tmp["ê¸°ë§(ê¸ˆì•¡)í•©ê³„"])
    unit_cost_df = tmp.groupby(MAT_COL, as_index=False).sum()
    unit_cost_df[UNIT_COST_COL] = unit_cost_df.apply(lambda r: r["ê¸°ë§(ê¸ˆì•¡)í•©ê³„"] / r["ê¸°ë§(ìˆ˜ëŸ‰)"] if r["ê¸°ë§(ìˆ˜ëŸ‰)"] > 0 else 0, axis=1)
    
    # 2. ì¬ê³  + ìœ íš¨ê¸°í•œ ë³‘í•© (2ë²ˆ + 3ë²ˆ)
    df_stock = dfs[STOCK_DF_KEY]
    df_expiry = dfs[EXPIRY_DF_KEY][[BATCH_COL, EXPIRY_COL]].drop_duplicates(subset=[BATCH_COL])
    merged = df_stock.merge(df_expiry, on=BATCH_COL, how="left")
    
    # 3. ìˆ˜ëŸ‰ 0ì¸ ë°ì´í„° ì œì™¸
    merged[QTY_SRC_COL] = to_numeric_safe(merged[QTY_SRC_COL])
    merged = merged[merged[QTY_SRC_COL] > 0].copy()
    
    # 4. ìœ íš¨ê¸°í•œ ë²„í‚· ìƒì„±
    today = pd.Timestamp(datetime.now().date())
    merged[EXPIRY_COL] = pd.to_datetime(merged[EXPIRY_COL], errors="coerce")
    merged[DAYS_COL] = (merged[EXPIRY_COL] - today).dt.days
    
    def bucketize(days):
        if pd.isna(days): return "ìœ íš¨ê¸°í•œ ì—†ìŒ"
        if days <= 0: return "íê¸°í™•ì •(ìœ íš¨ê¸°í•œ ì§€ë‚¨)"
        if days <= 90: return "3ê°œì›” ë¯¸ë§Œ"
        if days <= 180: return "6ê°œì›” ë¯¸ë§Œ"
        if days <= 270: return "9ê°œì›” ë¯¸ë§Œ"
        if days <= 365: return "12ê°œì›” ë¯¸ë§Œ"
        return "12ê°œì›” ì´ìƒ"
    
    merged[BUCKET_COL] = merged[DAYS_COL].apply(bucketize)
    
    # 5. ê¸ˆì•¡ ê³„ì‚° ê²°í•©
    merged = merged.merge(unit_cost_df[[MAT_COL, UNIT_COST_COL]], on=MAT_COL, how="left")
    merged[UNIT_COST_COL] = merged[UNIT_COST_COL].fillna(0)
    merged[VALUE_COL] = merged[QTY_SRC_COL] * merged[UNIT_COST_COL]
    
    return merged

# =====================================================
# ğŸš€ ë©”ì¸ ì‹¤í–‰
# =====================================================
dfs = st.session_state.get("dfs")
if not dfs:
    st.warning("ë¨¼ì € ì—…ë¡œë“œ í˜ì´ì§€ì—ì„œ ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")
    st.stop()

final_df = build_final_df(dfs)

# -----------------------------------------------------
# 1ï¸âƒ£ [ìš°ì„  í™•ì¸] ìœ„í—˜ ê¸°ê°„ë³„ ìš”ì•½ (íƒ­ ë©”ë‰´)
# -----------------------------------------------------
st.subheader("ğŸš¨ ê¸°ê°„ë³„ ìœ„í—˜ ìì¬ ìš”ì•½")
st.write("ì˜ì‚¬ê²°ì •ì´ í•„ìš”í•œ ìœ„í—˜ êµ¬ê°„ì„ ì„ íƒí•˜ì„¸ìš”.")

# íƒ­ ìƒì„±
tab3, tab6, tab9 = st.tabs(["ğŸ”¥ 3ê°œì›” ë¯¸ë§Œ", "âš ï¸ 6ê°œì›” ë¯¸ë§Œ", "â„¹ï¸ 9ê°œì›” ë¯¸ë§Œ"])

def display_risk_summary(target_buckets, tab_obj, title):
    with tab_obj:
        risk_df = final_df[final_df[BUCKET_COL].isin(target_buckets)].copy()
        if risk_df.empty:
            st.success(f"âœ… {title} ë‚´ì— í•´ë‹¹í•˜ëŠ” ìì¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            summary = (
                risk_df.groupby([MAT_COL, MAT_NAME_COL], as_index=False)[[QTY_SRC_COL, VALUE_COL]]
                .sum()
                .sort_values(VALUE_COL, ascending=False)
                .reset_index(drop=True)
            )
            
            m1, m2, m3 = st.columns([1, 1, 2])
            m1.metric(f"{title} ìì¬ ìˆ˜", f"{len(summary)}ì¢…")
            m2.metric(f"ì´ ìœ„í—˜ ê¸ˆì•¡", f"â‚©{summary[VALUE_COL].sum():,.0f}")
            
            with m3:
                disp = summary.copy()
                disp[VALUE_COL] = disp[VALUE_COL].map('{:,.0f}'.format)
                disp[QTY_SRC_COL] = disp[QTY_SRC_COL].map('{:,.0f}'.format)
                st.dataframe(disp, use_container_width=True, height=200)

# ê° íƒ­ì— ë°ì´í„° ë§¤í•‘
display_risk_summary(["íê¸°í™•ì •(ìœ íš¨ê¸°í•œ ì§€ë‚¨)", "3ê°œì›” ë¯¸ë§Œ"], tab3, "3ê°œì›” ë¯¸ë§Œ")
display_risk_summary(["íê¸°í™•ì •(ìœ íš¨ê¸°í•œ ì§€ë‚¨)", "3ê°œì›” ë¯¸ë§Œ", "6ê°œì›” ë¯¸ë§Œ"], tab6, "6ê°œì›” ë¯¸ë§Œ")
display_risk_summary(["íê¸°í™•ì •(ìœ íš¨ê¸°í•œ ì§€ë‚¨)", "3ê°œì›” ë¯¸ë§Œ", "6ê°œì›” ë¯¸ë§Œ", "9ê°œì›” ë¯¸ë§Œ"], tab9, "9ê°œì›” ë¯¸ë§Œ")

st.divider()

# -----------------------------------------------------
# 2ï¸âƒ£ ìì¬-ë°°ì¹˜ ë‹¨ìœ„ ìƒì„¸ ë¶„ì„ (Drill-down)
# -----------------------------------------------------
st.subheader("ğŸ” ìì¬-ë°°ì¹˜ë³„ ìƒì„¸ ë¶„ì„")

# ë¶„ì„ ëŒ€ìƒ ë²„í‚· (3/6/9ê°œì›” ëª¨ë‘ í¬í•¨í•˜ì—¬ ì„ íƒ ê°€ëŠ¥í•˜ê²Œ í•¨)
target_risks = ["3ê°œì›” ë¯¸ë§Œ", "6ê°œì›” ë¯¸ë§Œ", "9ê°œì›” ë¯¸ë§Œ", "íê¸°í™•ì •(ìœ íš¨ê¸°í•œ ì§€ë‚¨)"]
df_risk_all = final_df[final_df[BUCKET_COL].isin(target_risks)].copy()

if not df_risk_all.empty:
    # 1. ìì¬ ì„ íƒ í•„í„°
    top_mats = (
        df_risk_all.groupby([MAT_COL, MAT_NAME_COL], as_index=False)[VALUE_COL].sum()
        .sort_values(VALUE_COL, ascending=False)
    )
    top_mats["label"] = top_mats[MAT_COL].astype(str) + " | " + top_mats[MAT_NAME_COL].astype(str)
    
    col_sel, col_chk = st.columns([2, 1])
    with col_sel:
        selected_label = st.selectbox("ìƒì„¸ ì¡°ì‚¬ê°€ í•„ìš”í•œ ìì¬ë¥¼ ì„ íƒí•˜ì„¸ìš”", options=top_mats["label"].tolist())
        selected_mat = selected_label.split(" | ")[0]
    with col_chk:
        show_all_batches = st.checkbox("ëª¨ë“  ìœ„í—˜ ë°°ì¹˜ ë³´ê¸° (ê¸ˆì•¡ìˆœ)", value=False)

    # 2. í•„í„°ë§ëœ ë°ì´í„° ì¤€ë¹„
    if show_all_batches:
        view_df = df_risk_all.sort_values(VALUE_COL, ascending=False).reset_index(drop=True)
    else:
        view_df = df_risk_all[df_risk_all[MAT_COL].astype(str) == selected_mat].sort_values(VALUE_COL, ascending=False).reset_index(drop=True)

    # 3. í…Œì´ë¸” ë° ì°¨íŠ¸
    st.write(f"### ğŸ“ ìƒì„¸ ë¦¬ìŠ¤íŠ¸ (ë¶„ì„ ëŒ€ìƒ: {selected_label if not show_all_batches else 'ì „ì²´ ìœ„í—˜ ë°°ì¹˜'})")
    
    v_disp = view_df[[MAT_COL, MAT_NAME_COL, BATCH_COL, BUCKET_COL, QTY_SRC_COL, VALUE_COL]].copy()
    v_disp[VALUE_COL] = v_disp[VALUE_COL].map('{:,.0f}'.format)
    v_disp[QTY_SRC_COL] = v_disp[QTY_SRC_COL].map('{:,.0f}'.format)
    st.dataframe(v_disp, use_container_width=True)

    # ì‹œê°í™”
    if not show_all_batches:
        fig, ax = plt.subplots(figsize=(10, 4))
        sns.barplot(data=view_df.head(15), x=BATCH_COL, y=VALUE_COL, hue=BUCKET_COL, 
                    palette="magma", ax=ax)
        ax.set_title(f"[{selected_label}] ë°°ì¹˜ë³„ ìì‚° ê°€ì¹˜ í˜„í™©")
        plt.xticks(rotation=45)
        st.pyplot(fig)
else:
    st.info("ê´€ë¦¬ ëŒ€ìƒ ìœ„í—˜ ì¬ê³ ê°€ ì—†ìŠµë‹ˆë‹¤.")

# =====================================================
# âœ… ë°ì´í„° ì €ì¥
# =====================================================
if "stock_data_registry" not in st.session_state:
    st.session_state["stock_data_registry"] = {"datasets": {}, "selected_id": None}

did = f"stock_final_{datetime.now().strftime('%Y%m%d')}"
st.session_state["stock_data_registry"]["datasets"][did] = {"df": final_df}
st.session_state["stock_data_registry"]["selected_id"] = did

# # import streamlit as st
# # import pandas as pd
# # from datetime import datetime
# # import matplotlib.pyplot as plt
# # import seaborn as sns
# # import matplotlib.font_manager as fm
# # import os

# # st.set_page_config(page_title="S&OP - Data Analysis", layout="wide")
# # st.title("ğŸ“ˆ Data Analysis (Stock)")

# # # =====================================================
# # # âœ… dfs key (íŒŒì¼ëª… ê·¸ëŒ€ë¡œ)
# # # =====================================================
# # PRICE_DF_KEY = "1. ê²°ì‚° ì¬ê³ ìˆ˜ë¶ˆë¶€(ì›ê°€).xls"
# # STOCK_DF_KEY = "2. ë°°ì¹˜ ì¬ê³ ìˆ˜ë¶ˆë¶€(ë°°ì¹˜).xls"
# # EXPIRY_DF_KEY = "3. ì°½ê³ ë³„ ì¬ê³ í˜„í™©(ìœ íš¨ê¸°í•œ)_1.19.xls"

# # # =====================================================
# # # âœ… í‘œì¤€ ì»¬ëŸ¼ëª…
# # # =====================================================
# # BATCH_COL = "ë°°ì¹˜"
# # MAT_COL = "ìì¬"
# # MAT_NAME_COL = "ìì¬ ë‚´ì—­"
# # EXPIRY_COL = "ìœ íš¨ ê¸°í•œ"
# # QTY_SRC_COL = "Stock Quantity on Period End"
# # UNIT_COST_COL = "ë‹¨ìœ„ì›ê°€"
# # VALUE_COL = "Stock Value on Period End"
# # BUCKET_COL = "expiry_bucket"
# # DAYS_COL = "days_to_expiry"

# # # =====================================================
# # # âœ… í™˜ê²½ ì„¤ì • (í°íŠ¸ ë“±)
# # # =====================================================
# # def set_korean_font():
# #     font_path = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "assets", "fonts", "NanumGothic-Regular.ttf"))
# #     if os.path.exists(font_path):
# #         fm.fontManager.addfont(font_path)
# #         plt.rcParams["font.family"] = fm.FontProperties(fname=font_path).get_name()
# #     else:
# #         plt.rcParams["font.family"] = "Malgun Gothic"
# #     plt.rcParams["axes.unicode_minus"] = False

# # set_korean_font()
# # sns.set_theme(style="whitegrid", font=plt.rcParams["font.family"])

# # # =====================================================
# # # ğŸ› ï¸ ë°ì´í„° ì²˜ë¦¬ í•¨ìˆ˜
# # # =====================================================
# # def to_numeric_safe(s): return pd.to_numeric(s, errors="coerce").fillna(0)

# # def build_final_df(dfs):
# #     # 1. ë‹¨ìœ„ì›ê°€ ê³„ì‚° (1ë²ˆ íŒŒì¼)
# #     df_price = dfs[PRICE_DF_KEY]
# #     tmp = df_price[[MAT_COL, "ê¸°ë§(ìˆ˜ëŸ‰)", "ê¸°ë§(ê¸ˆì•¡)í•©ê³„"]].copy()
# #     tmp["ê¸°ë§(ìˆ˜ëŸ‰)"] = to_numeric_safe(tmp["ê¸°ë§(ìˆ˜ëŸ‰)"])
# #     tmp["ê¸°ë§(ê¸ˆì•¡)í•©ê³„"] = to_numeric_safe(tmp["ê¸°ë§(ê¸ˆì•¡)í•©ê³„"])
# #     unit_cost_df = tmp.groupby(MAT_COL, as_index=False).sum()
# #     unit_cost_df[UNIT_COST_COL] = unit_cost_df.apply(lambda r: r["ê¸°ë§(ê¸ˆì•¡)í•©ê³„"] / r["ê¸°ë§(ìˆ˜ëŸ‰)"] if r["ê¸°ë§(ìˆ˜ëŸ‰)"] > 0 else 0, axis=1)
    
# #     # 2. ì¬ê³  + ìœ íš¨ê¸°í•œ ë³‘í•© (2ë²ˆ + 3ë²ˆ)
# #     df_stock = dfs[STOCK_DF_KEY]
# #     df_expiry = dfs[EXPIRY_DF_KEY][[BATCH_COL, EXPIRY_COL]].drop_duplicates(subset=[BATCH_COL])
# #     merged = df_stock.merge(df_expiry, on=BATCH_COL, how="left")
    
# #     # 3. ìˆ˜ëŸ‰ 0ì¸ ë°ì´í„° ì œì™¸
# #     merged[QTY_SRC_COL] = to_numeric_safe(merged[QTY_SRC_COL])
# #     merged = merged[merged[QTY_SRC_COL] > 0].copy()
    
# #     # 4. ìœ íš¨ê¸°í•œ ë²„í‚· ìƒì„±
# #     today = pd.Timestamp(datetime.now().date())
# #     merged[EXPIRY_COL] = pd.to_datetime(merged[EXPIRY_COL], errors="coerce")
# #     merged[DAYS_COL] = (merged[EXPIRY_COL] - today).dt.days
    
# #     def bucketize(days):
# #         if pd.isna(days): return "ìœ íš¨ê¸°í•œ ì—†ìŒ"
# #         if days <= 0: return "íê¸°í™•ì •(ìœ íš¨ê¸°í•œ ì§€ë‚¨)"
# #         if days <= 90: return "3ê°œì›” ë¯¸ë§Œ"
# #         if days <= 180: return "6ê°œì›” ë¯¸ë§Œ"
# #         if days <= 270: return "9ê°œì›” ë¯¸ë§Œ"
# #         if days <= 365: return "12ê°œì›” ë¯¸ë§Œ"
# #         return "12ê°œì›” ì´ìƒ"
    
# #     merged[BUCKET_COL] = merged[DAYS_COL].apply(bucketize)
    
# #     # 5. ê¸ˆì•¡ ê³„ì‚° ê²°í•©
# #     merged = merged.merge(unit_cost_df[[MAT_COL, UNIT_COST_COL]], on=MAT_COL, how="left")
# #     merged[UNIT_COST_COL] = merged[UNIT_COST_COL].fillna(0)
# #     merged[VALUE_COL] = merged[QTY_SRC_COL] * merged[UNIT_COST_COL]
    
# #     return merged

# # # =====================================================
# # # ğŸš€ ë©”ì¸ ì‹¤í–‰
# # # =====================================================
# # dfs = st.session_state.get("dfs")
# # if not dfs:
# #     st.warning("ë¨¼ì € ì—…ë¡œë“œ í˜ì´ì§€ì—ì„œ ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")
# #     st.stop()

# # final_df = build_final_df(dfs)

# # # -----------------------------------------------------
# # # 1ï¸âƒ£ [ìš°ì„  í™•ì¸] ìœ„í—˜ ê¸°ê°„ë³„ ìš”ì•½ (íƒ­ ë©”ë‰´)
# # # -----------------------------------------------------
# # st.subheader("ğŸš¨ ê¸°ê°„ë³„ ìœ„í—˜ ìì¬ ìš”ì•½")
# # st.write("ì˜ì‚¬ê²°ì •ì´ í•„ìš”í•œ ìœ„í—˜ êµ¬ê°„ì„ ì„ íƒí•˜ì„¸ìš”.")

# # # íƒ­ ìƒì„±
# # tab3, tab6, tab9 = st.tabs(["ğŸ”¥ 3ê°œì›” ë¯¸ë§Œ", "âš ï¸ 6ê°œì›” ë¯¸ë§Œ", "â„¹ï¸ 9ê°œì›” ë¯¸ë§Œ"])

# # def display_risk_summary(target_buckets, tab_obj, title):
# #     with tab_obj:
# #         risk_df = final_df[final_df[BUCKET_COL].isin(target_buckets)].copy()
# #         if risk_df.empty:
# #             st.success(f"âœ… {title} ë‚´ì— í•´ë‹¹í•˜ëŠ” ìì¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
# #         else:
# #             summary = (
# #                 risk_df.groupby([MAT_COL, MAT_NAME_COL], as_index=False)[[QTY_SRC_COL, VALUE_COL]]
# #                 .sum()
# #                 .sort_values(VALUE_COL, ascending=False)
# #                 .reset_index(drop=True)
# #             )
            
# #             m1, m2, m3 = st.columns([1, 1, 2])
# #             m1.metric(f"{title} ìì¬ ìˆ˜", f"{len(summary)}ì¢…")
# #             m2.metric(f"ì´ ìœ„í—˜ ê¸ˆì•¡", f"â‚©{summary[VALUE_COL].sum():,.0f}")
            
# #             with m3:
# #                 disp = summary.copy()
# #                 disp[VALUE_COL] = disp[VALUE_COL].map('{:,.0f}'.format)
# #                 disp[QTY_SRC_COL] = disp[QTY_SRC_COL].map('{:,.0f}'.format)
# #                 st.dataframe(disp, use_container_width=True, height=200)

# # # ê° íƒ­ì— ë°ì´í„° ë§¤í•‘
# # display_risk_summary(["íê¸°í™•ì •(ìœ íš¨ê¸°í•œ ì§€ë‚¨)", "3ê°œì›” ë¯¸ë§Œ"], tab3, "3ê°œì›” ë¯¸ë§Œ")
# # display_risk_summary(["íê¸°í™•ì •(ìœ íš¨ê¸°í•œ ì§€ë‚¨)", "3ê°œì›” ë¯¸ë§Œ", "6ê°œì›” ë¯¸ë§Œ"], tab6, "6ê°œì›” ë¯¸ë§Œ")
# # display_risk_summary(["íê¸°í™•ì •(ìœ íš¨ê¸°í•œ ì§€ë‚¨)", "3ê°œì›” ë¯¸ë§Œ", "6ê°œì›” ë¯¸ë§Œ", "9ê°œì›” ë¯¸ë§Œ"], tab9, "9ê°œì›” ë¯¸ë§Œ")

# # st.divider()

# # # -----------------------------------------------------
# # # 2ï¸âƒ£ ìì¬-ë°°ì¹˜ ë‹¨ìœ„ ìƒì„¸ ë¶„ì„ (Drill-down)
# # # -----------------------------------------------------
# # st.subheader("ğŸ” ìì¬-ë°°ì¹˜ë³„ ìƒì„¸ ë¶„ì„")

# # # ë¶„ì„ ëŒ€ìƒ ë²„í‚· (3/6/9ê°œì›” ëª¨ë‘ í¬í•¨í•˜ì—¬ ì„ íƒ ê°€ëŠ¥í•˜ê²Œ í•¨)
# # target_risks = ["3ê°œì›” ë¯¸ë§Œ", "6ê°œì›” ë¯¸ë§Œ", "9ê°œì›” ë¯¸ë§Œ", "íê¸°í™•ì •(ìœ íš¨ê¸°í•œ ì§€ë‚¨)"]
# # df_risk_all = final_df[final_df[BUCKET_COL].isin(target_risks)].copy()

# # if not df_risk_all.empty:
# #     # 1. ìì¬ ì„ íƒ í•„í„°
# #     top_mats = (
# #         df_risk_all.groupby([MAT_COL, MAT_NAME_COL], as_index=False)[VALUE_COL].sum()
# #         .sort_values(VALUE_COL, ascending=False)
# #     )
# #     top_mats["label"] = top_mats[MAT_COL].astype(str) + " | " + top_mats[MAT_NAME_COL].astype(str)
    
# #     col_sel, col_chk = st.columns([2, 1])
# #     with col_sel:
# #         selected_label = st.selectbox("ìƒì„¸ ì¡°ì‚¬ê°€ í•„ìš”í•œ ìì¬ë¥¼ ì„ íƒí•˜ì„¸ìš”", options=top_mats["label"].tolist())
# #         selected_mat = selected_label.split(" | ")[0]
# #     with col_chk:
# #         show_all_batches = st.checkbox("ëª¨ë“  ìœ„í—˜ ë°°ì¹˜ ë³´ê¸° (ê¸ˆì•¡ìˆœ)", value=False)

# #     # 2. í•„í„°ë§ëœ ë°ì´í„° ì¤€ë¹„
# #     if show_all_batches:
# #         view_df = df_risk_all.sort_values(VALUE_COL, ascending=False).reset_index(drop=True)
# #     else:
# #         view_df = df_risk_all[df_risk_all[MAT_COL].astype(str) == selected_mat].sort_values(VALUE_COL, ascending=False).reset_index(drop=True)

# #     # 3. í…Œì´ë¸” ë° ì°¨íŠ¸
# #     st.write(f"### ğŸ“ ìƒì„¸ ë¦¬ìŠ¤íŠ¸ (ë¶„ì„ ëŒ€ìƒ: {selected_label if not show_all_batches else 'ì „ì²´ ìœ„í—˜ ë°°ì¹˜'})")
    
# #     v_disp = view_df[[MAT_COL, MAT_NAME_COL, BATCH_COL, BUCKET_COL, QTY_SRC_COL, VALUE_COL]].copy()
# #     v_disp[VALUE_COL] = v_disp[VALUE_COL].map('{:,.0f}'.format)
# #     v_disp[QTY_SRC_COL] = v_disp[QTY_SRC_COL].map('{:,.0f}'.format)
# #     st.dataframe(v_disp, use_container_width=True)

# #     # ì‹œê°í™”
# #     if not show_all_batches:
# #         fig, ax = plt.subplots(figsize=(10, 4))
# #         sns.barplot(data=view_df.head(15), x=BATCH_COL, y=VALUE_COL, hue=BUCKET_COL, 
# #                     palette="magma", ax=ax)
# #         ax.set_title(f"[{selected_label}] ë°°ì¹˜ë³„ ìì‚° ê°€ì¹˜ í˜„í™©")
# #         plt.xticks(rotation=45)
# #         st.pyplot(fig)
# # else:
# #     st.info("ê´€ë¦¬ ëŒ€ìƒ ìœ„í—˜ ì¬ê³ ê°€ ì—†ìŠµë‹ˆë‹¤.")

# # # =====================================================
# # # âœ… ë°ì´í„° ì €ì¥
# # # =====================================================
# # if "stock_data_registry" not in st.session_state:
# #     st.session_state["stock_data_registry"] = {"datasets": {}, "selected_id": None}

# # did = f"stock_final_{datetime.now().strftime('%Y%m%d')}"
# # st.session_state["stock_data_registry"]["datasets"][did] = {"df": final_df}
# # st.session_state["stock_data_registry"]["selected_id"] = did

# import streamlit as st
# import pandas as pd
# from datetime import datetime
# import matplotlib.pyplot as plt
# import seaborn as sns
# import matplotlib.font_manager as fm
# import os

# st.set_page_config(page_title="S&OP - Data Analysis", layout="wide")
# st.title("ğŸ“ˆ Data Analysis (Stock)")

# # =====================================================
# # âœ… [ì¶”ê°€] Streamlit í‘œ/í…ìŠ¤íŠ¸ í•œê¸€ ê¹¨ì§ ë°©ì§€ìš© ì›¹í°íŠ¸ CSS
# #    - st.dataframe(í‘œ)ë„ ë¸Œë¼ìš°ì € í°íŠ¸ ì˜í–¥ì´ë¼ ì´ê²Œ ì¤‘ìš”!
# # =====================================================
# st.markdown(
#     """
#     <style>
#     @import url('https://fonts.googleapis.com/css2?family=Noto+Sans+KR:wght@400;600&display=swap');
#     html, body, [class*="css"]  {
#         font-family: 'Noto Sans KR', sans-serif !important;
#     }
#     /* dataframe/tableì—ë„ ì ìš© */
#     .stDataFrame, .stDataFrame * {
#         font-family: 'Noto Sans KR', sans-serif !important;
#     }
#     </style>
#     """,
#     unsafe_allow_html=True
# )

# # =====================================================
# # âœ… dfs key (íŒŒì¼ëª… ê·¸ëŒ€ë¡œ)
# # =====================================================
# PRICE_DF_KEY = "1. ê²°ì‚° ì¬ê³ ìˆ˜ë¶ˆë¶€(ì›ê°€).xls"
# STOCK_DF_KEY = "2. ë°°ì¹˜ ì¬ê³ ìˆ˜ë¶ˆë¶€(ë°°ì¹˜).xls"
# EXPIRY_DF_KEY = "3. ì°½ê³ ë³„ ì¬ê³ í˜„í™©(ìœ íš¨ê¸°í•œ)_1.19.xls"

# # =====================================================
# # âœ… í‘œì¤€ ì»¬ëŸ¼ëª…(ê³ ì •)
# # =====================================================
# BATCH_COL = "ë°°ì¹˜"
# MAT_COL = "ìì¬"
# MAT_DESC_COL = "ìì¬ ë‚´ì—­"   # âœ… [ì¶”ê°€] ìì¬ ë‚´ì—­ ì»¬ëŸ¼
# EXPIRY_COL = "ìœ íš¨ ê¸°í•œ"

# PRICE_QTY_COL = "ê¸°ë§(ìˆ˜ëŸ‰)"
# PRICE_AMT_COL = "ê¸°ë§(ê¸ˆì•¡)í•©ê³„"

# QTY_SRC_COL = "Stock Quantity on Period End"
# UNIT_COST_COL = "ë‹¨ìœ„ì›ê°€"
# VALUE_COL = "Stock Value on Period End"

# BUCKET_COL = "expiry_bucket"
# DAYS_COL = "days_to_expiry"

# # ìœ„í—˜ ìì¬ ìš”ì•½ ê¸°ì¤€ (3/6/9)
# RISK_BUCKETS_369 = ["3ê°œì›” ë¯¸ë§Œ", "6ê°œì›” ë¯¸ë§Œ", "9ê°œì›” ë¯¸ë§Œ"]

# # =====================================================
# # âœ… í°íŠ¸ + seaborn (ê·¸ë˜í”„ìš©)
# # =====================================================
# def set_korean_font():
#     font_path = os.path.abspath(
#         os.path.join(os.path.dirname(__file__), "..", "assets", "fonts", "NanumGothic-Regular.ttf")
#     )
#     if os.path.exists(font_path):
#         fm.fontManager.addfont(font_path)
#         font_name = fm.FontProperties(fname=font_path).get_name()
#         plt.rcParams["font.family"] = font_name
#         return font_name
#     else:
#         plt.rcParams["font.family"] = "DejaVu Sans"
#         return "DejaVu Sans"

# plt.rcParams["axes.unicode_minus"] = False
# font_name = set_korean_font()

# # seabornì—ë„ ê·¸ë˜í”„ í°íŠ¸ ë°˜ì˜ (ì¤‘ìš”)
# sns.set_theme(style="whitegrid", rc={"font.family": font_name, "axes.unicode_minus": False})

# # =====================================================
# # ìœ í‹¸
# # =====================================================
# def to_datetime_safe(s):
#     return pd.to_datetime(s, errors="coerce")

# def to_numeric_safe(s):
#     return pd.to_numeric(s, errors="coerce")

# def require_columns(df, cols, df_name):
#     missing = [c for c in cols if c not in df.columns]
#     if missing:
#         raise ValueError(f"[{df_name}] í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing}")

# # =====================================================
# # 1) ë‹¨ìœ„ì›ê°€ í…Œì´ë¸” ìƒì„± (1ë²ˆ ìë£Œ)
# # =====================================================
# def build_unit_cost_df(df_price: pd.DataFrame) -> pd.DataFrame:
#     require_columns(df_price, [MAT_COL, PRICE_QTY_COL, PRICE_AMT_COL], "1ë²ˆ(ì›ê°€ ìë£Œ)")

#     tmp = df_price[[MAT_COL, PRICE_QTY_COL, PRICE_AMT_COL]].copy()
#     tmp[PRICE_QTY_COL] = to_numeric_safe(tmp[PRICE_QTY_COL]).fillna(0)
#     tmp[PRICE_AMT_COL] = to_numeric_safe(tmp[PRICE_AMT_COL]).fillna(0)

#     grp = tmp.groupby(MAT_COL, as_index=False).sum()
#     grp[UNIT_COST_COL] = grp.apply(
#         lambda r: r[PRICE_AMT_COL] / r[PRICE_QTY_COL] if r[PRICE_QTY_COL] else 0,
#         axis=1
#     )
#     return grp[[MAT_COL, UNIT_COST_COL]]

# # =====================================================
# # 2) ì¬ê³  + ìœ íš¨ê¸°í•œ ë³‘í•© (2ë²ˆ + 3ë²ˆ)
# # =====================================================
# def build_stock_expiry_df(df_stock: pd.DataFrame, df_expiry: pd.DataFrame) -> pd.DataFrame:
#     # âœ… ìì¬ ë‚´ì—­ì´ ìˆìœ¼ë©´ ê°€ì ¸ì˜¤ê³ , ì—†ì–´ë„ ëŒì•„ê°€ê²Œ(ì˜µì…˜)
#     need_stock_cols = [BATCH_COL, MAT_COL, QTY_SRC_COL]
#     require_columns(df_stock, need_stock_cols, "2ë²ˆ(ë°°ì¹˜ ì¬ê³ ìˆ˜ë¶ˆë¶€)")

#     require_columns(df_expiry, [BATCH_COL, EXPIRY_COL], "3ë²ˆ(ìœ íš¨ê¸°í•œ)")

#     e = df_expiry[[BATCH_COL, EXPIRY_COL]].copy()
#     e[EXPIRY_COL] = to_datetime_safe(e[EXPIRY_COL])

#     merged = df_stock.merge(e, on=BATCH_COL, how="left")
#     merged[QTY_SRC_COL] = to_numeric_safe(merged[QTY_SRC_COL]).fillna(0)

#     return merged

# # =====================================================
# # 3) ìœ íš¨ê¸°í•œ bucket ìƒì„±
# # =====================================================
# def add_expiry_bucket(df: pd.DataFrame) -> pd.DataFrame:
#     df = df.copy()
#     today = pd.Timestamp(datetime.now().date())

#     df[EXPIRY_COL] = to_datetime_safe(df[EXPIRY_COL])
#     df[DAYS_COL] = (df[EXPIRY_COL] - today).dt.days

#     def bucketize(days):
#         if pd.isna(days):
#             return "ìœ íš¨ê¸°í•œ ì—†ìŒ"
#         if days <= 0:
#             return "íê¸°í™•ì •(ìœ íš¨ê¸°í•œ ì§€ë‚¨)"
#         if days <= 90:
#             return "3ê°œì›” ë¯¸ë§Œ"
#         if days <= 180:
#             return "6ê°œì›” ë¯¸ë§Œ"
#         if days <= 270:
#             return "9ê°œì›” ë¯¸ë§Œ"
#         if days <= 365:
#             return "12ê°œì›” ë¯¸ë§Œ"
#         if days <= 540:
#             return "18ê°œì›” ë¯¸ë§Œ"
#         if days <= 730:
#             return "24ê°œì›” ë¯¸ë§Œ"
#         return "24ê°œì›” ì´ìƒ"

#     df[BUCKET_COL] = df[DAYS_COL].apply(bucketize)
#     return df

# # =====================================================
# # 4) ë‹¨ìœ„ì›ê°€ ë¶™ì´ê³  Stock Value ê³„ì‚°
# # =====================================================
# def add_unit_cost_and_value(df: pd.DataFrame, unit_cost_df: pd.DataFrame) -> pd.DataFrame:
#     require_columns(df, [MAT_COL, QTY_SRC_COL], "ì¬ê³ DF")
#     require_columns(unit_cost_df, [MAT_COL, UNIT_COST_COL], "ë‹¨ìœ„ì›ê°€DF")

#     out = df.merge(unit_cost_df, on=MAT_COL, how="left")
#     out[UNIT_COST_COL] = to_numeric_safe(out[UNIT_COST_COL]).fillna(0)
#     out[VALUE_COL] = to_numeric_safe(out[QTY_SRC_COL]).fillna(0) * out[UNIT_COST_COL]
#     return out

# # =====================================================
# # âœ… dfs ë¡œë“œ
# # =====================================================
# dfs = st.session_state.get("dfs")
# if dfs is None:
#     st.warning("ë¨¼ì € ì—…ë¡œë“œ í˜ì´ì§€ì—ì„œ Raw ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")
#     st.stop()

# need_keys = [PRICE_DF_KEY, STOCK_DF_KEY, EXPIRY_DF_KEY]
# missing = [k for k in need_keys if k not in dfs]
# if missing:
#     st.error(f"dfsì— í•„ìš”í•œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {missing} (ì—…ë¡œë“œ íŒŒì¼ëª…ì„ í™•ì¸í•˜ì„¸ìš”)")
#     st.stop()

# df_price = dfs[PRICE_DF_KEY]
# df_stock = dfs[STOCK_DF_KEY]
# df_expiry = dfs[EXPIRY_DF_KEY]

# # =====================================================
# # âœ… ìµœì¢… ì¬ê³  ë°ì´í„°(final_df) ìƒì„±
# # =====================================================
# st.subheader("âœ… ìµœì¢… ì¬ê³  ë°ì´í„° ìë™ ìƒì„± (ë‹¨ìœ„ì›ê°€/ìœ íš¨ê¸°í•œ/ì¬ê³ ê¸ˆì•¡ í¬í•¨)")

# with st.spinner("1) ë‹¨ìœ„ì›ê°€ ê³„ì‚° â†’ 2) ì¬ê³ +ìœ íš¨ê¸°í•œ ë³‘í•© â†’ 3) ë²„í‚· ìƒì„± â†’ 4) ì¬ê³ ê¸ˆì•¡ ê³„ì‚°..."):
#     unit_cost_df = build_unit_cost_df(df_price)
#     stock_expiry = build_stock_expiry_df(df_stock, df_expiry)
#     stock_bucket = add_expiry_bucket(stock_expiry)
#     final_df = add_unit_cost_and_value(stock_bucket, unit_cost_df)

# st.success("âœ… final_df ìƒì„± ì™„ë£Œ!")

# # =====================================================
# # âœ… stock_data_registry ì €ì¥
# # =====================================================
# if "stock_data_registry" not in st.session_state:
#     st.session_state["stock_data_registry"] = {"datasets": {}, "selected_id": None}

# final_id = f"stock_final_{datetime.now().strftime('%Y%m%d')}"
# st.session_state["stock_data_registry"]["datasets"][final_id] = {
#     "domain": "stock",
#     "type": "final_stock",
#     "title": "ìµœì¢… ì¬ê³  ë°ì´í„°(ìœ íš¨ê¸°í•œ/ë‹¨ìœ„ì›ê°€/ì¬ê³ ê¸ˆì•¡ í¬í•¨)",
#     "df": final_df,
#     "created_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
# }
# st.session_state["stock_data_registry"]["selected_id"] = final_id

# # =====================================================
# # âœ… ìµœì¢… ì¬ê³  ë°ì´í„°(final_df) ìƒì„± ì™„ë£Œ ì´í›„:
# #    âŒ final_df ë¯¸ë¦¬ë³´ê¸° í‘œëŠ” ë³´ì—¬ì£¼ì§€ ì•ŠìŒ
# #    âœ… ê¸°ê°„ë³„ ìœ„í—˜ ìì¬ ìš”ì•½ë§Œ ë³´ì—¬ì¤Œ
# # =====================================================

# st.divider()
# st.subheader("ğŸš¨ ê¸°ê°„ë³„ ìœ„í—˜ ìì¬ ìš”ì•½")
# st.write("ì˜ì‚¬ê²°ì •ì´ í•„ìš”í•œ ìœ„í—˜ êµ¬ê°„ì„ ì„ íƒí•˜ì„¸ìš”.")

# # ---------------------------
# # í•„ìˆ˜ ì»¬ëŸ¼ ì²´í¬
# # ---------------------------
# need_cols = [MAT_COL, BUCKET_COL, QTY_SRC_COL, VALUE_COL]
# missing = [c for c in need_cols if c not in final_df.columns]
# if missing:
#     st.error(f"final_dfì— í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {missing}")
#     st.stop()

# # ìì¬ ë‚´ì—­ ì»¬ëŸ¼ì´ ì—†ë‹¤ë©´ ë¹ˆì¹¸ìœ¼ë¡œ ìƒì„±(ì˜¤ë¥˜ ë°©ì§€)
# if MAT_DESC_COL not in final_df.columns:
#     final_df[MAT_DESC_COL] = ""

# # ìˆ«ìí˜• ì•ˆì „ ì²˜ë¦¬
# final_df[QTY_SRC_COL] = pd.to_numeric(final_df[QTY_SRC_COL], errors="coerce").fillna(0)
# final_df[VALUE_COL]   = pd.to_numeric(final_df[VALUE_COL], errors="coerce").fillna(0)

# # ---------------------------
# # íƒ­ êµ¬ì„± (ìš”ì²­ UI)
# # ---------------------------
# tab3, tab6, tab9 = st.tabs(["ğŸ”¥ 3ê°œì›” ë¯¸ë§Œ", "âš ï¸ 6ê°œì›” ë¯¸ë§Œ", "â„¹ï¸ 9ê°œì›” ë¯¸ë§Œ"])


# def show_risk_tab(tab_obj, bucket_list, title):
#     with tab_obj:
#         risk_df = final_df[final_df[BUCKET_COL].isin(bucket_list)].copy()

#         risk_df = risk_df[(risk_df[QTY_SRC_COL] != 0) | (risk_df[VALUE_COL] != 0)]

#         if risk_df.empty:
#             st.success(f"âœ… {title} êµ¬ê°„ì— í•´ë‹¹í•˜ëŠ” ìì¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
#             return

#         # âœ… ìì¬ + ë°°ì¹˜ ê¸°ì¤€ ì§‘ê³„
#         summary = (
#             risk_df
#             .groupby([MAT_COL, MAT_DESC_COL, BATCH_COL], as_index=False)[[QTY_SRC_COL, VALUE_COL]]
#             .sum()
#             .sort_values(VALUE_COL, ascending=False)
#             .reset_index(drop=True)
#         )

#         # KPI (ìì¬ ìˆ˜ / ì´ ê¸ˆì•¡ì€ ìì¬ ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚°)
#         mat_cnt = summary[MAT_COL].nunique()
#         total_risk_value = float(summary[VALUE_COL].sum())

#         c1, c2 = st.columns(2)
#         c1.metric(f"{title} ìì¬ ìˆ˜", f"{mat_cnt:,}ì¢…")
#         c2.metric("ì´ ìœ„í—˜ ê¸ˆì•¡", f"â‚©{total_risk_value:,.0f}")

#         # âœ… í…Œì´ë¸” í‘œì‹œ (ë°°ì¹˜ í¬í•¨)
#         show_df = summary.rename(columns={
#             MAT_COL: "ìì¬",
#             MAT_DESC_COL: "ìì¬ ë‚´ì—­",
#             BATCH_COL: "ë°°ì¹˜",
#             QTY_SRC_COL: "ìˆ˜ëŸ‰",
#             VALUE_COL: "ê¸ˆì•¡(ì›)"
#         }).copy()

#         show_df["ìˆ˜ëŸ‰"] = show_df["ìˆ˜ëŸ‰"].map(lambda x: f"{x:,.0f}")
#         show_df["ê¸ˆì•¡(ì›)"] = show_df["ê¸ˆì•¡(ì›)"].map(lambda x: f"{x:,.0f}")

#         st.dataframe(show_df, use_container_width=True, height=350)



# # âœ… íƒ­ë³„ ê¸°ì¤€
# # - 3ê°œì›” íƒ­: íê¸° + 3ê°œì›”
# # - 6ê°œì›” íƒ­: íê¸° + 3 + 6ê°œì›”
# # - 9ê°œì›” íƒ­: íê¸° + 3 + 6 + 9ê°œì›”
# show_risk_tab(
#     tab3,
#     ["íê¸°í™•ì •(ìœ íš¨ê¸°í•œ ì§€ë‚¨)", "3ê°œì›” ë¯¸ë§Œ"],
#     "3ê°œì›” ë¯¸ë§Œ"
# )

# show_risk_tab(
#     tab6,
#     ["íê¸°í™•ì •(ìœ íš¨ê¸°í•œ ì§€ë‚¨)", "3ê°œì›” ë¯¸ë§Œ", "6ê°œì›” ë¯¸ë§Œ"],
#     "6ê°œì›” ë¯¸ë§Œ"
# )

# show_risk_tab(
#     tab9,
#     ["íê¸°í™•ì •(ìœ íš¨ê¸°í•œ ì§€ë‚¨)", "3ê°œì›” ë¯¸ë§Œ", "6ê°œì›” ë¯¸ë§Œ", "9ê°œì›” ë¯¸ë§Œ"],
#     "9ê°œì›” ë¯¸ë§Œ"
# )


# # # =====================================================
# # # âœ… final_df ë¯¸ë¦¬ë³´ê¸°
# # # =====================================================
# # st.write("### ğŸ“Œ ìµœì¢… ì¬ê³  ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")
# # preview_cols = [c for c in [BATCH_COL, MAT_COL, MAT_DESC_COL, EXPIRY_COL, DAYS_COL, BUCKET_COL, QTY_SRC_COL, UNIT_COST_COL, VALUE_COL] if c in final_df.columns]
# # st.dataframe(final_df[preview_cols].head(80), use_container_width=True)

# # st.download_button(
# #     "ğŸ“¥ ìµœì¢… ì¬ê³  ë°ì´í„°(final_df) CSV ë‹¤ìš´ë¡œë“œ",
# #     data=final_df.to_csv(index=False).encode("utf-8-sig"),
# #     file_name=f"{final_id}.csv",
# #     mime="text/csv"
# # )

# # =====================================================
# # âœ… [ì¶”ê°€] ìì¬-ë°°ì¹˜ ë‹¨ìœ„ ìœ„í—˜ì¬ê³ (3/6/9ê°œì›” ë¯¸ë§Œ) ìƒì„¸ í…Œì´ë¸” + ì‹œê°í™”
# # =====================================================
# st.divider()
# st.subheader("âœ… ìì¬-ë°°ì¹˜ ë‹¨ìœ„ ìœ„í—˜ì¬ê³  ìƒì„¸ (3/6/9ê°œì›” ë¯¸ë§Œ)")

# need = [MAT_COL, BATCH_COL, EXPIRY_COL, BUCKET_COL, QTY_SRC_COL, VALUE_COL]
# missing = [c for c in need if c not in final_df.columns]
# if missing:
#     st.error(f"final_dfì— í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {missing}")
#     st.stop()

# df_detail = final_df.copy()
# df_detail[QTY_SRC_COL] = pd.to_numeric(df_detail[QTY_SRC_COL], errors="coerce").fillna(0)
# df_detail[VALUE_COL] = pd.to_numeric(df_detail[VALUE_COL], errors="coerce").fillna(0)

# # 3/6/9ê°œì›” ë¯¸ë§Œë§Œ
# df_detail = df_detail[df_detail[BUCKET_COL].isin(RISK_BUCKETS_369)].copy()

# # âœ… [í•µì‹¬] ìì¬ì½”ë“œ â†’ ìì¬ ë‚´ì—­ ë§¤í•‘(ëŒ€í‘œê°’ 1ê°œ)
# if MAT_DESC_COL in df_detail.columns:
#     mat_master = (
#         df_detail[[MAT_COL, MAT_DESC_COL]]
#         .dropna()
#         .astype({MAT_COL: str, MAT_DESC_COL: str})
#         .drop_duplicates()
#         .groupby(MAT_COL, as_index=False)[MAT_DESC_COL]
#         .first()
#     )
# else:
#     mat_master = pd.DataFrame({MAT_COL: df_detail[MAT_COL].astype(str).unique(), MAT_DESC_COL: ""})

# # ë°°ì¹˜ ë‹¨ìœ„ë¡œ í•©ì¹˜ê¸° (ìì¬/ë°°ì¹˜/êµ¬ê°„)
# batch_table = (
#     df_detail.groupby([MAT_COL, BATCH_COL, BUCKET_COL], as_index=False)[[QTY_SRC_COL, VALUE_COL]]
#              .sum()
# )

# # âœ… ìì¬ ë‚´ì—­ ë¶™ì´ê¸°
# batch_table[MAT_COL] = batch_table[MAT_COL].astype(str)
# mat_master[MAT_COL] = mat_master[MAT_COL].astype(str)
# batch_table = batch_table.merge(mat_master, on=MAT_COL, how="left")

# # ë³´ê¸° ì¢‹ê²Œ ì •ë ¬
# bucket_order = ["3ê°œì›” ë¯¸ë§Œ", "6ê°œì›” ë¯¸ë§Œ", "9ê°œì›” ë¯¸ë§Œ"]
# batch_table[BUCKET_COL] = pd.Categorical(batch_table[BUCKET_COL], categories=bucket_order, ordered=True)
# batch_table = batch_table.sort_values([MAT_COL, BUCKET_COL, VALUE_COL], ascending=[True, True, False]).reset_index(drop=True)

# # UI: ìì¬ ì„ íƒ
# top_mat = (
#     batch_table.groupby(MAT_COL, as_index=False)[VALUE_COL].sum()
#               .sort_values(VALUE_COL, ascending=False)
#               .head(30)
# )

# mat_options = top_mat[MAT_COL].tolist()
# if len(mat_options) == 0:
#     st.info("3/6/9ê°œì›” ë¯¸ë§Œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
#     st.stop()

# col1, col2 = st.columns([2, 1])
# with col1:
#     selected_mat = st.selectbox("ìì¬ ì„ íƒ (ìœ„í—˜ê¸ˆì•¡ TOP ê¸°ì¤€)", options=mat_options)
# with col2:
#     show_all_mats = st.checkbox("ì „ì²´ ìì¬ ë³´ê¸°", value=False)

# if show_all_mats:
#     view_df = batch_table.copy()
# else:
#     view_df = batch_table[batch_table[MAT_COL] == str(selected_mat)].copy()

# st.write("### ğŸ“Œ ìì¬-ë°°ì¹˜ë³„ 3/6/9ê°œì›” ë¯¸ë§Œ ìƒì„¸ í…Œì´ë¸” (ìì¬ + ìì¬ ë‚´ì—­ í¬í•¨)")
# show_cols = [MAT_COL, MAT_DESC_COL, BATCH_COL, BUCKET_COL, QTY_SRC_COL, VALUE_COL]
# st.dataframe(view_df[show_cols], use_container_width=True)

# # ì €ì¥ + ë‹¤ìš´ë¡œë“œ
# detail_id = f"stock_mat_batch_risk_369_{datetime.now().strftime('%Y%m%d')}"
# st.session_state["stock_data_registry"]["datasets"][detail_id] = {
#     "domain": "stock",
#     "type": "material_batch_risk_369",
#     "title": "ìì¬-ë°°ì¹˜ë³„ ìœ„í—˜ì¬ê³ (3/6/9ê°œì›” ë¯¸ë§Œ) ìƒì„¸",
#     "df": batch_table,
#     "created_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
# }

# st.download_button(
#     "ğŸ“¥ (ìì¬-ë°°ì¹˜ ìœ„í—˜ì¬ê³  ìƒì„¸) CSV ë‹¤ìš´ë¡œë“œ",
#     data=batch_table.to_csv(index=False).encode("utf-8-sig"),
#     file_name=f"{detail_id}.csv",
#     mime="text/csv"
# )

# # -----------------------------
# # ì‹œê°í™” 1) ì„ íƒ ìì¬ì˜ ë°°ì¹˜ë³„ ê¸ˆì•¡ Bar
# # -----------------------------
# st.divider()
# st.subheader("ğŸ“Š ì‹œê°í™”: ì„ íƒ ìì¬ì˜ ë°°ì¹˜ë³„ ìœ„í—˜ ê¸ˆì•¡")

# if not show_all_mats:
#     top_n_batch = st.slider("TOP N ë°°ì¹˜ (ì„ íƒ ìì¬)", 5, 40, 15, 5)

#     plot_top = (
#         view_df.groupby([BATCH_COL, BUCKET_COL], as_index=False)[VALUE_COL]
#                .sum()
#                .sort_values(VALUE_COL, ascending=False)
#                .head(top_n_batch)
#     )

#     fig, ax = plt.subplots(figsize=(12, 6))
#     sns.barplot(data=plot_top, x=BATCH_COL, y=VALUE_COL, hue=BUCKET_COL, ax=ax)
#     ax.set_title(f"[{selected_mat}] ë°°ì¹˜ë³„ ìœ„í—˜ ì¬ê³ ê¸ˆì•¡ (3/6/9ê°œì›” ë¯¸ë§Œ)")
#     ax.set_xlabel("ë°°ì¹˜")
#     ax.set_ylabel("ê¸ˆì•¡")
#     plt.xticks(rotation=25, ha="right")
#     plt.tight_layout()
#     st.pyplot(fig)

# # -----------------------------
# # ì‹œê°í™” 2) ì„ íƒ ìì¬ì˜ êµ¬ê°„ë³„ ìˆ˜ëŸ‰/ê¸ˆì•¡ Pie
# # -----------------------------
# st.divider()
# st.subheader("ğŸ“Š ì‹œê°í™”: ì„ íƒ ìì¬ì˜ êµ¬ê°„ë³„ ë¹„ì¤‘")

# if not show_all_mats:
#     agg_mat = (
#         view_df.groupby(BUCKET_COL, as_index=False)[[QTY_SRC_COL, VALUE_COL]]
#                .sum()
#                .sort_values(BUCKET_COL)
#     )

#     c1, c2 = st.columns(2)

#     with c1:
#         fig, ax = plt.subplots(figsize=(6, 6))
#         ax.pie(
#             agg_mat[VALUE_COL].values,
#             labels=agg_mat[BUCKET_COL].astype(str).tolist(),
#             autopct=lambda p: f"{p:.1f}%" if p > 0 else ""
#         )
#         ax.set_title("êµ¬ê°„ë³„ ê¸ˆì•¡ ë¹„ì¤‘(%)")
#         plt.tight_layout()
#         st.pyplot(fig)

#     with c2:
#         fig, ax = plt.subplots(figsize=(6, 6))
#         ax.pie(
#             agg_mat[QTY_SRC_COL].values,
#             labels=agg_mat[BUCKET_COL].astype(str).tolist(),
#             autopct=lambda p: f"{p:.1f}%" if p > 0 else ""
#         )
#         ax.set_title("êµ¬ê°„ë³„ ìˆ˜ëŸ‰ ë¹„ì¤‘(%)")
#         plt.tight_layout()
#         st.pyplot(fig)
