import streamlit as st
import pandas as pd
import numpy as np
import io

# ======================================================
# Page
# ======================================================
st.set_page_config(page_title="S&OP System - ì¬ê³  ì‹œë®¬ë ˆì´ì…˜", layout="wide")
st.title("ğŸ§ª ì¬ê³  ì‹œë®¬ë ˆì´ì…˜ - ë¶„ë¥˜/ì›ê°€ìœ¨/í‰íŒ ë§¤í•‘(ìì¬ì½”ë“œ ê¸°ì¤€)")

# ======================================================
# 0) ì„¸ì…˜ ë°ì´í„° í™•ì¸
# ======================================================
dfs_all = st.session_state.get("dfs", {})
if not dfs_all:
    st.warning("ë¨¼ì € [ğŸ“¥ ë°ì´í„° ì—…ë¡œë“œ] í˜ì´ì§€ì—ì„œ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ë¡œë“œí•´ì£¼ì„¸ìš”.")
    st.stop()

# ======================================================
# 1) ì—°ë„ / ì›” ì„ íƒ
# ======================================================
years = sorted(dfs_all.keys())
sel_year = st.selectbox("ğŸ“… ì—°ë„ ì„ íƒ", years, index=len(years) - 1)

months = sorted(
    dfs_all[sel_year].keys(),
    key=lambda x: int(str(x).replace("ì›”", "")) if "ì›”" in str(x) else 0
)
sel_month = st.selectbox("ğŸ“† ì›” ì„ íƒ", months, index=len(months) - 1)

files_dict = dfs_all[sel_year][sel_month]
st.info(f"ğŸ“ ì„ íƒ ê¸°ì¤€: **{sel_year} {sel_month}**")

# ======================================================
# 2) íŒŒì¼ëª… ê³ ì •
# ======================================================
INV_FILE = "12ì›” ê¸°ë§ ì¬ê³ _Data.xlsx"
CLS_FILE = "ê¸°ì¤€ì •ë³´_ë¶„ë¥˜ ë° ì›ê°€ìœ¨.xlsx"
RATING_FILE = "ê¸°ì¤€ì •ë³´_í‰íŒ ê¸°ì¤€.xlsx"
CANCEL_FILE = "12ì›” ë§ ì œì¡°ì‚¬ ìˆ˜ì£¼ ì·¨ì†Œ í˜„í™©_ì½”ìŠ¤ë§¥ìŠ¤ ì·¨ì†Œ.xlsx"

required_files = [INV_FILE, CLS_FILE, RATING_FILE, CANCEL_FILE]
missing = [f for f in required_files if f not in files_dict]
if missing:
    st.error(f"âŒ í•„ìˆ˜ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {missing}")
    st.write("í˜„ì¬ íŒŒì¼ ëª©ë¡:", list(files_dict.keys()))
    st.stop()

# ======================================================
# Utils
# ======================================================
def pick_df(obj):
    """session_stateì—ì„œ sheet dictë¡œ ë“¤ì–´ì˜¨ ê²½ìš° ì²« df ë½‘ê¸°"""
    if isinstance(obj, dict):
        return obj[list(obj.keys())[0]]
    return obj

def normalize_code_to_int_string(s: pd.Series) -> pd.Series:
    """
    ìˆ«ì/ë¬¸ì/9310288.0/ê³µë°±/ì‰¼í‘œ ì„ì—¬ ìˆì–´ë„
    'ì •ìˆ˜ ë¬¸ìì—´'ë¡œ í†µì¼í•˜ì—¬ ë§¤í•‘ ì•ˆì •í™”
    """
    x = s.astype(str).str.strip().str.replace(",", "", regex=False)
    num = pd.to_numeric(x, errors="coerce")

    out = x.copy()
    mask = num.notna()
    out.loc[mask] = num.loc[mask].round(0).astype("Int64").astype(str)
    out = out.replace({"nan": "", "<NA>": ""})
    return out

def pick_col(df: pd.DataFrame, candidates):
    return next((c for c in candidates if c in df.columns), None)

def download_excel_openpyxl(df: pd.DataFrame, filename: str, sheet_name: str = "Report"):
    buffer = io.BytesIO()
    with pd.ExcelWriter(buffer, engine="openpyxl") as writer:
        df.to_excel(writer, index=False, sheet_name=sheet_name)
    buffer.seek(0)
    st.download_button(
        label="ğŸ“¥ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ",
        data=buffer,
        file_name=filename,
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )

# ======================================================
# 3) Mapping (ìì‚¬ ê¸°ë§ì¬ê³ ) - í†µí•© ë²„ì „
# ======================================================
def build_mapped_inventory_df(
    inv_df: pd.DataFrame,
    cls_df: pd.DataFrame,
    rating_df: pd.DataFrame,
    *,
    inv_code_col="ìì¬",
    cls_code_col="ìì¬ì½”ë“œ",
    rating_code_col="ìì¬",
    remove_keywords_regex="ìš©ì—­ë¹„|ë°°ì†¡ë¹„",
    inv_item_candidates=("ìì¬ ë‚´ì—­", "ìì¬ë‚´ì—­", "ìì¬ëª…", "ìì¬ ëª…"),
    drop_inv_cols=("í‰ê°€ ìœ í˜•", "í”ŒëœíŠ¸", "ì €ì¥ìœ„ì¹˜", "íŠ¹ë³„ì¬ê³ "),
    cls_take_cols=("ëŒ€ë¶„ë¥˜", "ì†Œë¶„ë¥˜", "ì›ê°€ìœ¨"),
    # âœ… ì–´ë–¤ í‰íŒì„ ì‚¬ìš©í• ì§€: "í‰íŒ" or "í‰íŒ * 1.38ë°°"
    rating_mode: str = "both",   # "both" / "plain" / "x138"
    dedup_by_material: bool = False,  # ìì¬ ì¤‘ë³µ ì‹œ ìˆ˜ëŸ‰/ê¸ˆì•¡ í•©ì³ 1í–‰
    set_expiry_2099_when_rating_zero: bool = True,
) -> pd.DataFrame:
    inv = inv_df.copy()
    cls = cls_df.copy()
    rating = rating_df.copy()

    # 1) ìš©ì—­ë¹„/ë°°ì†¡ë¹„ ì œê±°
    inv_item_col = next((c for c in inv_item_candidates if c in inv.columns), None)
    if inv_item_col is not None:
        inv = inv[~inv[inv_item_col].astype(str).str.contains(remove_keywords_regex, na=False)].copy()

    # 2) ë¶ˆí•„ìš” ì»¬ëŸ¼ drop
    inv = inv.drop(columns=[c for c in drop_inv_cols if c in inv.columns], errors="ignore")

    # 3) í•„ìˆ˜ ì»¬ëŸ¼ ì²´í¬
    for need_col, df_name, df_obj in [
        (inv_code_col, "ê¸°ë§ì¬ê³ ", inv),
        (cls_code_col, "ê¸°ì¤€ì •ë³´", cls),
        (rating_code_col, "í‰íŒê¸°ì¤€", rating),
    ]:
        if need_col not in df_obj.columns:
            raise ValueError(f"í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: [{df_name}]ì— '{need_col}' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    # 4) í‚¤ ì •ê·œí™”
    inv["_mat_key"] = normalize_code_to_int_string(inv[inv_code_col])
    cls["_mat_key"] = normalize_code_to_int_string(cls[cls_code_col])
    rating["_mat_key"] = normalize_code_to_int_string(rating[rating_code_col])

    # 5) ê¸°ì¤€ì •ë³´ ë§¤í•‘ í…Œì´ë¸”
    for col in cls_take_cols:
        if col not in cls.columns:
            raise ValueError(f"ê¸°ì¤€ì •ë³´ íŒŒì¼ì— '{col}' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    cls_small = (
        cls[["_mat_key"] + list(cls_take_cols)]
        .dropna(subset=["_mat_key"])
        .drop_duplicates(subset=["_mat_key"])
    )

    # 6) í‰íŒ ë§¤í•‘ í…Œì´ë¸” (modeë³„)
    if rating_mode == "both":
        rating_take_cols = ("í‰íŒ", "í‰íŒ * 1.38ë°°")
    elif rating_mode == "plain":
        rating_take_cols = ("í‰íŒ",)
    elif rating_mode == "x138":
        rating_take_cols = ("í‰íŒ * 1.38ë°°",)
    else:
        raise ValueError("rating_modeëŠ” 'both'/'plain'/'x138' ì¤‘ í•˜ë‚˜ì—¬ì•¼ í•©ë‹ˆë‹¤.")

    for col in rating_take_cols:
        if col not in rating.columns:
            raise ValueError(f"í‰íŒ ê¸°ì¤€ íŒŒì¼ì— '{col}' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    rating_small = (
        rating[["_mat_key"] + list(rating_take_cols)]
        .dropna(subset=["_mat_key"])
        .drop_duplicates(subset=["_mat_key"])
    )

    # 7) merge
    out = inv.merge(cls_small, on="_mat_key", how="left")
    out = out.merge(rating_small, on="_mat_key", how="left")

    # 8) ê²°ì¸¡ ì²˜ë¦¬
    out["ëŒ€ë¶„ë¥˜"] = out.get("ëŒ€ë¶„ë¥˜", "ë¯¸ë¶„ë¥˜").fillna("ë¯¸ë¶„ë¥˜")
    out["ì†Œë¶„ë¥˜"] = out.get("ì†Œë¶„ë¥˜", "ë¯¸ë¶„ë¥˜").fillna("ë¯¸ë¶„ë¥˜")

    # 9) ìì¬ ì¤‘ë³µ ì²˜ë¦¬(ì˜µì…˜)
    qty_candidates = ["ê¸°ë§ ì¬ê³  ìˆ˜ëŸ‰", "ê¸°ë§ìˆ˜ëŸ‰", "ì¬ê³ ìˆ˜ëŸ‰", "Stock Quantity on Period End"]
    amt_candidates = ["ê¸°ë§ ì¬ê³  ê¸ˆì•¡", "ê¸°ë§ê¸ˆì•¡", "ì¬ê³ ê¸ˆì•¡", "Stock Amount on Period End"]
    qty_col = pick_col(out, qty_candidates)
    amt_col = pick_col(out, amt_candidates)
    if qty_col is None or amt_col is None:
        raise ValueError(f"ìˆ˜ëŸ‰/ê¸ˆì•¡ ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. qty={qty_col}, amt={amt_col}")

    out[qty_col] = pd.to_numeric(out[qty_col], errors="coerce").fillna(0.0)
    out[amt_col] = pd.to_numeric(out[amt_col], errors="coerce").fillna(0.0)

    if dedup_by_material:
        group_key = inv_code_col if inv_code_col in out.columns else "_mat_key"
        agg_map = {qty_col: "sum", amt_col: "sum"}
        for c in out.columns:
            if c not in agg_map and c != group_key:
                agg_map[c] = "first"
        out = out.groupby(group_key, as_index=False).agg(agg_map)

    # 10) í‰íŒ ìˆ«ìí™” + (í‰íŒ0ì´ë©´ ìœ íš¨ê¸°í•œ 2099 ì„¸íŒ… ì˜µì…˜)
    expiry_candidates = ["ìœ íš¨ ê¸°í•œ", "ìœ íš¨ê¸°ê°„", "ìœ í†µê¸°í•œ"]
    expiry_col = next((c for c in expiry_candidates if c in out.columns), None)

    for col in ["í‰íŒ", "í‰íŒ * 1.38ë°°"]:
        if col in out.columns:
            out[col] = pd.to_numeric(out[col], errors="coerce").fillna(0.0)

    if set_expiry_2099_when_rating_zero and expiry_col is not None:
        # ê¸°ì¤€: plainì¼ ë•ŒëŠ” í‰íŒ, x138ì¼ ë•ŒëŠ” í‰íŒ*1.38ë°°
        if rating_mode == "x138":
            base_rating_col = "í‰íŒ * 1.38ë°°"
        else:
            base_rating_col = "í‰íŒ" if "í‰íŒ" in out.columns else None

        if base_rating_col:
            mask_zero = out[base_rating_col].fillna(0).eq(0)
            out.loc[mask_zero, expiry_col] = pd.Timestamp("2099-12-31")

    # 11) íŒŒìƒ ì»¬ëŸ¼ ê³„ì‚°
    qty_num = out[qty_col]
    amt_num = out[amt_col]

    out["ë‹¨ê°€"] = amt_num / qty_num.replace({0: pd.NA})

    # ì¶œí•˜ì›ê°€ ê¸°ì¤€: plainì´ë©´ í‰íŒ, x138ì´ë©´ í‰íŒ*1.38ë°°, bothë©´ í‰íŒ(ê¸°ì¡´ ë¡œì§ ìœ ì§€)
    if rating_mode == "x138":
        sales_col = "í‰íŒ * 1.38ë°°"
    else:
        sales_col = "í‰íŒ" if "í‰íŒ" in out.columns else None

    out["ì¶œí•˜ì›ê°€"] = pd.to_numeric(out["ë‹¨ê°€"], errors="coerce") * pd.to_numeric(out.get(sales_col, 0), errors="coerce")

    out["ì›ê°€ìœ¨"] = pd.to_numeric(out.get("ì›ê°€ìœ¨"), errors="coerce")
    out["ì¶œí•˜íŒê°€"] = out["ì¶œí•˜ì›ê°€"] / out["ì›ê°€ìœ¨"].replace({0: pd.NA})
    out["íŒê°€"] = amt_num / out["ì›ê°€ìœ¨"].replace({0: pd.NA})

    out["who"] = "ìì‚¬"
    return out

# ======================================================
# 4) Mapping (ì œì¡°ì‚¬ ì·¨ì†ŒPO) - í†µí•© ë²„ì „
# ======================================================
def build_mapped_cancel_po_df(
    cancel_df: pd.DataFrame,
    cls_df: pd.DataFrame,
    rating_df: pd.DataFrame,
    *,
    prod_code_candidates=("ì œí’ˆì½”ë“œ", "ì œí’ˆ ì½”ë“œ", "ìì¬", "ìì¬ì½”ë“œ"),
    prod_name_candidates=("ì œí’ˆëª…", "í’ˆëª…", "ìì¬ ë‚´ì—­", "ìì¬ëª…"),
    qty_candidates=("ì”ì—¬ PO", "ì”ì—¬PO", "ì”ì—¬_PO", "ìˆ˜ëŸ‰", "ì”ì—¬ìˆ˜ëŸ‰"),
    amt_candidates=("ê¸ˆì•¡", "ì¬ê³ ê¸ˆì•¡", "ì·¨ì†Œê¸ˆì•¡", "ì”ì—¬ê¸ˆì•¡"),
    cls_code_col="ìì¬ì½”ë“œ",
    rating_code_col="ìì¬",
    cls_take_cols=("ëŒ€ë¶„ë¥˜", "ì†Œë¶„ë¥˜", "ì›ê°€ìœ¨"),
    rating_mode="plain",    # "plain" / "x138" / "both"
    remove_keywords_regex="ìš©ì—­ë¹„|ë°°ì†¡ë¹„",
    dedup_by_material=True, # ì œì¡°ì‚¬ëŠ” ë³´í†µ ìì¬ë‹¹ 1í–‰ ìœ ì§€í•˜ê³  ì‹¶ì–´ì„œ default True
    expiry_default=pd.Timestamp("2028-12-31"),
) -> pd.DataFrame:
    base = cancel_df.copy()
    cls = cls_df.copy()
    rating = rating_df.copy()

    code_col = pick_col(base, prod_code_candidates)
    name_col = pick_col(base, prod_name_candidates)
    qty_col  = pick_col(base, qty_candidates)
    amt_col  = pick_col(base, amt_candidates)

    missing = [("ì œí’ˆì½”ë“œ", code_col), ("ì œí’ˆëª…", name_col), ("ì”ì—¬PO", qty_col), ("ê¸ˆì•¡", amt_col)]
    missing = [label for label, col in missing if col is None]
    if missing:
        raise ValueError(f"[ì·¨ì†Œí˜„í™©] í•„ìˆ˜ ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {missing}\ní˜„ì¬ ì»¬ëŸ¼: {list(base.columns)}")

    # ìš©ì—­ë¹„/ë°°ì†¡ë¹„ ì œê±°
    base = base[~base[name_col].astype(str).str.contains(remove_keywords_regex, na=False)].copy()

    out = pd.DataFrame({
        "ìì¬": base[code_col],
        "ìì¬ ë‚´ì—­": base[name_col],
        "ê¸°ë§ ì¬ê³  ìˆ˜ëŸ‰": pd.to_numeric(base[qty_col], errors="coerce").fillna(0.0),
        "ê¸°ë§ ì¬ê³  ê¸ˆì•¡": pd.to_numeric(base[amt_col], errors="coerce").fillna(0.0),
    })

    # í‚¤ ì •ê·œí™”
    out["_mat_key"] = normalize_code_to_int_string(out["ìì¬"])
    cls["_mat_key"] = normalize_code_to_int_string(cls[cls_code_col])
    rating["_mat_key"] = normalize_code_to_int_string(rating[rating_code_col])

    # ê¸°ì¤€ì •ë³´
    cls_small = (
        cls[["_mat_key"] + list(cls_take_cols)]
        .dropna(subset=["_mat_key"])
        .drop_duplicates("_mat_key")
    )

    # í‰íŒ mode
    if rating_mode == "both":
        rating_take_cols = ("í‰íŒ", "í‰íŒ * 1.38ë°°")
    elif rating_mode == "plain":
        rating_take_cols = ("í‰íŒ",)
    elif rating_mode == "x138":
        rating_take_cols = ("í‰íŒ * 1.38ë°°",)
    else:
        raise ValueError("rating_modeëŠ” 'both'/'plain'/'x138' ì¤‘ í•˜ë‚˜ì—¬ì•¼ í•©ë‹ˆë‹¤.")

    rating_small = (
        rating[["_mat_key"] + list(rating_take_cols)]
        .dropna(subset=["_mat_key"])
        .drop_duplicates("_mat_key")
    )

    out = out.merge(cls_small, on="_mat_key", how="left")
    out = out.merge(rating_small, on="_mat_key", how="left")

    out["ëŒ€ë¶„ë¥˜"] = out.get("ëŒ€ë¶„ë¥˜", "ë¯¸ë¶„ë¥˜").fillna("ë¯¸ë¶„ë¥˜")
    out["ì†Œë¶„ë¥˜"] = out.get("ì†Œë¶„ë¥˜", "ë¯¸ë¶„ë¥˜").fillna("ë¯¸ë¶„ë¥˜")
    out["ì›ê°€ìœ¨"] = pd.to_numeric(out.get("ì›ê°€ìœ¨"), errors="coerce").fillna(0.0)

    for col in ["í‰íŒ", "í‰íŒ * 1.38ë°°"]:
        if col in out.columns:
            out[col] = pd.to_numeric(out[col], errors="coerce").fillna(0.0)

    # ìì¬ ì¤‘ë³µì´ë©´ ìˆ˜ëŸ‰/ê¸ˆì•¡ sum, ë‚˜ë¨¸ì§€ first
    if dedup_by_material:
        agg_map = {"ê¸°ë§ ì¬ê³  ìˆ˜ëŸ‰": "sum", "ê¸°ë§ ì¬ê³  ê¸ˆì•¡": "sum"}
        for c in out.columns:
            if c not in agg_map and c not in ["ìì¬", "_mat_key"]:
                agg_map[c] = "first"
        out = out.groupby("ìì¬", as_index=False).agg(agg_map)

    # íŒŒìƒ
    out["ë‹¨ê°€"] = out["ê¸°ë§ ì¬ê³  ê¸ˆì•¡"] / out["ê¸°ë§ ì¬ê³  ìˆ˜ëŸ‰"].replace({0: pd.NA})

    sales_col = "í‰íŒ * 1.38ë°°" if rating_mode == "x138" else ("í‰íŒ" if "í‰íŒ" in out.columns else None)
    out["ì¶œí•˜ì›ê°€"] = pd.to_numeric(out["ë‹¨ê°€"], errors="coerce") * pd.to_numeric(out.get(sales_col, 0), errors="coerce")
    out["ì¶œí•˜íŒê°€"] = out["ì¶œí•˜ì›ê°€"] / out["ì›ê°€ìœ¨"].replace({0: pd.NA})
    out["íŒê°€"] = out["ê¸°ë§ ì¬ê³  ê¸ˆì•¡"] / out["ì›ê°€ìœ¨"].replace({0: pd.NA})

    out["ìœ íš¨ê¸°ê°„"] = expiry_default
    out["who"] = "ì œì¡°ì‚¬"
    return out

# ======================================================
# 5) ëŒ€ë¶„ë¥˜ ì†Œê³„ í¬í•¨ ë¦¬í¬íŠ¸ (ì›ê°€/íŒê°€ë§Œ)
# ======================================================
def build_major_only_report_table(
    df_self: pd.DataFrame,
    df_manu: pd.DataFrame,
    *,
    major_col="ëŒ€ë¶„ë¥˜",
    sub_col="ì†Œë¶„ë¥˜",
    cost_col="ê¸°ë§ ì¬ê³  ê¸ˆì•¡",
    price_col="íŒê°€",
    self_name="ìì‚¬",
    manu_name="ì œì¡°ì‚¬",
    include_total=True,
    include_major_subtotal=True,
):
    s = df_self.copy()
    m = df_manu.copy()

    for d in [s, m]:
        if major_col not in d.columns: d[major_col] = "ë¯¸ë¶„ë¥˜"
        if sub_col not in d.columns:   d[sub_col] = "ë¯¸ë¶„ë¥˜"

    s["_who"] = self_name
    m["_who"] = manu_name

    s["_cost"] = pd.to_numeric(s.get(cost_col), errors="coerce").fillna(0.0)
    m["_cost"] = pd.to_numeric(m.get(cost_col), errors="coerce").fillna(0.0)
    s["_price"] = pd.to_numeric(s.get(price_col), errors="coerce").fillna(0.0)
    m["_price"] = pd.to_numeric(m.get(price_col), errors="coerce").fillna(0.0)

    base = pd.concat([s[[major_col, sub_col, "_who", "_cost", "_price"]],
                      m[[major_col, sub_col, "_who", "_cost", "_price"]]], ignore_index=True)

    piv = base.pivot_table(
        index=[major_col, sub_col],
        columns="_who",
        values=["_cost", "_price"],
        aggfunc="sum",
        fill_value=0.0
    )

    def col_name(measure, who):
        return f"{who} ì›ê°€" if measure == "_cost" else f"{who} íŒê°€"

    piv.columns = [col_name(measure, who) for (measure, who) in piv.columns]
    piv = piv.reset_index()

    # ë³´ì •
    for c in [f"{self_name} ì›ê°€", f"{self_name} íŒê°€", f"{manu_name} ì›ê°€", f"{manu_name} íŒê°€"]:
        if c not in piv.columns:
            piv[c] = 0.0

    piv["í•©ê³„ ì›ê°€"] = piv[f"{self_name} ì›ê°€"] + piv[f"{manu_name} ì›ê°€"]
    piv["í•©ê³„ íŒê°€"] = piv[f"{self_name} íŒê°€"] + piv[f"{manu_name} íŒê°€"]

    rows = []
    if include_total:
        rows.append(pd.DataFrame([{
            major_col: "ì´ê³„", sub_col: "",
            f"{self_name} ì›ê°€": piv[f"{self_name} ì›ê°€"].sum(),
            f"{self_name} íŒê°€": piv[f"{self_name} íŒê°€"].sum(),
            f"{manu_name} ì›ê°€": piv[f"{manu_name} ì›ê°€"].sum(),
            f"{manu_name} íŒê°€": piv[f"{manu_name} íŒê°€"].sum(),
            "í•©ê³„ ì›ê°€": piv["í•©ê³„ ì›ê°€"].sum(),
            "í•©ê³„ íŒê°€": piv["í•©ê³„ íŒê°€"].sum(),
        }]))

    for maj, maj_df in piv.groupby(major_col, sort=False):
        if include_major_subtotal:
            rows.append(pd.DataFrame([{
                major_col: maj, sub_col: "ì†Œê³„",
                f"{self_name} ì›ê°€": maj_df[f"{self_name} ì›ê°€"].sum(),
                f"{self_name} íŒê°€": maj_df[f"{self_name} íŒê°€"].sum(),
                f"{manu_name} ì›ê°€": maj_df[f"{manu_name} ì›ê°€"].sum(),
                f"{manu_name} íŒê°€": maj_df[f"{manu_name} íŒê°€"].sum(),
                "í•©ê³„ ì›ê°€": maj_df["í•©ê³„ ì›ê°€"].sum(),
                "í•©ê³„ íŒê°€": maj_df["í•©ê³„ íŒê°€"].sum(),
            }]))
        rows.append(maj_df)

    final = pd.concat(rows, ignore_index=True)

    # ìƒì„¸í–‰ì—ì„œ ëŒ€ë¶„ë¥˜ ê³µë°± ì²˜ë¦¬
    mask_detail = (final[major_col] != "ì´ê³„") & (final[sub_col] != "ì†Œê³„")
    final.loc[mask_detail, major_col] = ""

    return final[[major_col, sub_col,
                  f"{self_name} ì›ê°€", f"{self_name} íŒê°€",
                  f"{manu_name} ì›ê°€", f"{manu_name} íŒê°€",
                  "í•©ê³„ ì›ê°€", "í•©ê³„ íŒê°€"]]

# ======================================================
# 6) ì¬ê³  ì†Œì§„ ì‹œë®¬ë ˆì´ì…˜ (ì‹œì¦Œì½”ë“œ 5~8ì›”ë§Œ íŒë§¤)
# ======================================================
# def simulate_monthly_remaining_amount(
#     df: pd.DataFrame,
#     start_ym=(2026, 1),
#     end_ym=(2028, 12),
#     amount_col="ê¸°ë§ ì¬ê³  ê¸ˆì•¡",
#     burn_col="ì¶œí•˜ì›ê°€",
#     expiry_candidates=("ìœ íš¨ê¸°ê°„", "ìœ íš¨ ê¸°í•œ", "ìœ í†µê¸°í•œ"),
#     mat_col_candidates=("ìì¬", "ìì¬ì½”ë“œ", "ìì¬ ì½”ë“œ"),
#     season_mat_codes=None,
#     season_months=(5, 6, 7, 8),
#     col_fmt=lambda y, m: f"{str(y)[-2:]}_{m}"
# ):
#     out = df.copy()

#     mat_col = next((c for c in mat_col_candidates if c in out.columns), None)
#     season_set = set(str(x).strip() for x in (season_mat_codes or []))
#     is_season_item = out[mat_col].astype(str).str.strip().isin(season_set) if mat_col else pd.Series(False, index=out.index)

#     expiry_col = next((c for c in expiry_candidates if c in out.columns), None)
#     if expiry_col is None:
#         # ìœ íš¨ê¸°ê°„ ì—†ìœ¼ë©´ ì›” ì»¬ëŸ¼ë§Œ ìƒì„±
#         y, m = start_ym
#         ey, em = end_ym
#         while (y < ey) or (y == ey and m <= em):
#             out[col_fmt(y, m)] = 0.0
#             m += 1
#             if m == 13: y, m = y + 1, 1
#         return out

#     exp_dt = pd.to_datetime(out[expiry_col].astype(str).str.strip(), errors="coerce")
#     has_expiry = exp_dt.notna()

#     cutoff_dt = exp_dt - pd.DateOffset(months=6)
#     cut_y = cutoff_dt.dt.year
#     cut_m = cutoff_dt.dt.month

#     remaining = pd.to_numeric(out.get(amount_col), errors="coerce").fillna(0.0)
#     burn = pd.to_numeric(out.get(burn_col), errors="coerce").fillna(0.0)

#     # ì›” ë¦¬ìŠ¤íŠ¸
#     months = []
#     y, m = start_ym
#     ey, em = end_ym
#     while (y < ey) or (y == ey and m <= em):
#         months.append((y, m))
#         m += 1
#         if m == 13: y, m = y + 1, 1

#     for (y, m) in months:
#         col_name = col_fmt(y, m)
#         out[col_name] = 0.0

#         can_sell_by_cutoff = has_expiry & ((y < cut_y) | ((y == cut_y) & (m <= cut_m)))

#         season_allowed = pd.Series(True, index=out.index) if (m in season_months) else pd.Series(False, index=out.index)
#         season_filter = (~is_season_item) | (is_season_item & season_allowed)

#         can_sell = can_sell_by_cutoff & season_filter

#         remaining = remaining.where(~can_sell, (remaining - burn).clip(lower=0))
#         out.loc[has_expiry, col_name] = remaining.loc[has_expiry]

#     return out

def add_obsolete_cols_at_cutoff_6m(
    df: pd.DataFrame,
    *,
    expiry_candidates=("ìœ íš¨ê¸°ê°„", "ìœ íš¨ ê¸°í•œ", "ìœ í†µê¸°í•œ"),
    col_fmt=lambda y, m: f"{str(y)[-2:]}_{m}",
    amount_col="ê¸°ë§ ì¬ê³  ê¸ˆì•¡",
    burn_col="ì¶œí•˜ì›ê°€",
) -> pd.DataFrame:
    out = df.copy()
    out["ë¶€ì§„ì¬ê³ ëŸ‰"] = 0.0
    out["ë¶€ì§„ì¬ê³ ì§„ì…ì‹œì "] = 0
    out["ë¶€ì§„ì¬ê³ ì§„ì…ë¶„ê¸°"] = 0
    out["íšŒì „ì›”"] = 0.0

    amt = pd.to_numeric(out.get(amount_col), errors="coerce")
    burn = pd.to_numeric(out.get(burn_col), errors="coerce")
    mask_turn = burn.notna() & (burn != 0) & amt.notna()
    out.loc[mask_turn, "íšŒì „ì›”"] = amt.loc[mask_turn] / burn.loc[mask_turn]

    expiry_col = next((c for c in expiry_candidates if c in out.columns), None)
    if expiry_col is None:
        return out

    exp_dt = pd.to_datetime(out[expiry_col], errors="coerce")
    has_expiry = exp_dt.notna()
    if not has_expiry.any():
        return out

    cutoff_dt = exp_dt - pd.DateOffset(months=6)
    cut_y = cutoff_dt.dt.year
    cut_m = cutoff_dt.dt.month

    for idx in out.index:
        if not has_expiry.loc[idx]:
            continue
        y = int(cut_y.loc[idx]); m = int(cut_m.loc[idx])
        cut_col = col_fmt(y, m)
        if cut_col not in out.columns:
            continue

        val = pd.to_numeric(out.at[idx, cut_col], errors="coerce")
        if pd.isna(val):
            continue

        out.at[idx, "ë¶€ì§„ì¬ê³ ëŸ‰"] = float(val)

        if float(val) > 0:
            entry_dt = cutoff_dt.loc[idx]
            out.at[idx, "ë¶€ì§„ì¬ê³ ì§„ì…ì‹œì "] = entry_dt
            q = (entry_dt.month - 1) // 3 + 1
            yy = str(entry_dt.year)[-2:]
            out.at[idx, "ë¶€ì§„ì¬ê³ ì§„ì…ë¶„ê¸°"] = f"{yy}ë…„ {q}Q"

    return out

def simulate_monthly_remaining_amount_fefo(
    df: pd.DataFrame,
    start_ym=(2026, 1),
    end_ym=(2028, 12),
    *,
    mat_col="ìì¬",
    batch_col="ë°°ì¹˜",
    expiry_candidates=("ìœ íš¨ê¸°ê°„", "ìœ íš¨ ê¸°í•œ", "ìœ í†µê¸°í•œ"),
    amount_col="ê¸°ë§ ì¬ê³  ê¸ˆì•¡",
    burn_col="ì¶œí•˜ì›ê°€",   # "ì›”ì— ì†Œì§„ë˜ëŠ” ê¸ˆì•¡" (ë‹¨ê°€*í‰íŒ)
    season_mat_codes=None,
    season_months=(5, 6, 7, 8),
    col_fmt=lambda y, m: f"{str(y)[-2:]}_{m}",
):
    out = df.copy()

    # ---- ì»¬ëŸ¼ í™•ì¸ ----
    if mat_col not in out.columns:
        raise KeyError(f"'{mat_col}' ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    if batch_col not in out.columns:
        raise KeyError(f"FEFOë¥¼ í•˜ë ¤ë©´ '{batch_col}'(ë°°ì¹˜) ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    exp_col = next((c for c in expiry_candidates if c in out.columns), None)
    if exp_col is None:
        raise KeyError(f"ìœ íš¨ê¸°ê°„ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. í›„ë³´={expiry_candidates}")

    # ---- íƒ€ì… ì •ë¦¬ ----
    out[amount_col] = pd.to_numeric(out.get(amount_col), errors="coerce").fillna(0.0)
    out[burn_col]   = pd.to_numeric(out.get(burn_col), errors="coerce").fillna(0.0)
    out["_exp_dt"]  = pd.to_datetime(out[exp_col].astype(str).str.strip(), errors="coerce")
    out["_has_exp"] = out["_exp_dt"].notna()

    # cutoff (D-6ê°œì›”) : ì´ ì‹œì (ì›”)ê¹Œì§€ëŠ” íŒë§¤ ê°€ëŠ¥, ì´í›„ëŠ” íŒë§¤ ë¶ˆê°€ë¡œ ê°„ì£¼
    out["_cutoff_dt"] = out["_exp_dt"] - pd.DateOffset(months=6)
    out["_cut_y"] = out["_cutoff_dt"].dt.year
    out["_cut_m"] = out["_cutoff_dt"].dt.month

    # ì‹œì¦Œ ì•„ì´í…œ í”Œë˜ê·¸
    season_set = set(str(x).strip() for x in (season_mat_codes or []))
    out["_is_season"] = out[mat_col].astype(str).str.strip().isin(season_set)

    # ì›” ë¦¬ìŠ¤íŠ¸
    months = []
    y, m = start_ym
    ey, em = end_ym
    while (y < ey) or (y == ey and m <= em):
        months.append((y, m))
        m += 1
        if m == 13:
            y, m = y + 1, 1

    # ì›” ì»¬ëŸ¼ ìƒì„± (ë°°ì¹˜ë³„ ì”ì•¡)
    for (yy, mm) in months:
        out[col_fmt(yy, mm)] = 0.0

    # ---- FEFO: ìì¬ë³„ë¡œ ë°°ì¹˜ë¥¼ ìœ íš¨ê¸°ê°„ ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬í•´ì„œ, ì›” burnë¥¼ ì• ë°°ì¹˜ë¶€í„° ì†Œì§„ ----
    # ìƒíƒœ: ê° í–‰(ë°°ì¹˜)ì˜ remaining_amountë¥¼ ë“¤ê³  ê°
    remaining = out[amount_col].to_numpy().copy()

    # ìì¬ë³„ ì¸ë±ìŠ¤ ë¬¶ê¸°
    # FEFO ìˆœì„œ: exp_dt ì˜¤ë¦„ì°¨ìˆœ (NaTëŠ” ë’¤ë¡œ)
    grouped = (
        out.reset_index()
           .sort_values(by=[mat_col, "_has_exp", "_exp_dt"], ascending=[True, False, True])
           .groupby(mat_col)["index"]
           .apply(list)
           .to_dict()
    )

    for (yy, mm) in months:
        col = col_fmt(yy, mm)

        # ì›”ë³„ë¡œ "íŒë§¤ ê°€ëŠ¥í•œ ë°°ì¹˜"ë§Œ ëŒ€ìƒìœ¼ë¡œ burnë¥¼ ì ìš©
        # íŒë§¤ ê°€ëŠ¥ ì¡°ê±´:
        # 1) ìœ íš¨ê¸°ê°„ ìˆìŒ
        # 2) (í˜„ì¬ ì›”) <= cutoff ì›”  (D-6ê°œì›”ê¹Œì§€ íŒë§¤ë¡œ ê°„ì£¼)
        # 3) ì‹œì¦Œì½”ë“œë©´ 5~8ì›”ë§Œ íŒë§¤
        season_allowed = (mm in season_months)

        for mat, idx_list in grouped.items():
            # ì´ ìì¬ì˜ ì›” burn (í‰íŒ ê¸°ë°˜): ìì¬ ë‹¨ìœ„ë¡œ 1ë²ˆë§Œ ì ìš©í•´ì•¼ í•¨
            # - ê·¸ëŸ°ë° dfê°€ ë°°ì¹˜ë‹¨ìœ„ë¼ burn_col ê°’ì´ ë°°ì¹˜ë³„ë¡œ ì¤‘ë³µë  ìˆ˜ ìˆìŒ
            #   â†’ "ì²« ë°°ì¹˜ì˜ burn"ì„ ìì¬ burnë¡œ ì‚¬ìš© (ë„ˆ ë¡œì§ìƒ í‰íŒì€ ìì¬ ê³ ìœ ê°’ì´ë‹ˆê¹Œ)
            #   â†’ ë” ì•ˆì „í•˜ê²Œ í•˜ë ¤ë©´ ìì¬ë³„ burnì„ ë³„ë„ë¡œ ë§Œë“  ë’¤ mergeí•˜ëŠ” ê²Œ ë² ìŠ¤íŠ¸
            mat_burn = float(out.loc[idx_list[0], burn_col]) if len(idx_list) else 0.0
            if mat_burn <= 0:
                continue

            # ì‹œì¦Œì´ë©´ ì‹œì¦Œì›” ì•„ë‹ˆë©´ íŒë§¤ ë¶ˆê°€
            # (ì´ ìì¬ê°€ ì‹œì¦Œì¸ì§€ ì—¬ë¶€ëŠ” ì•„ë¬´ ë°°ì¹˜ë‚˜ ë™ì¼í•˜ë‹¤ê³  ê°€ì •)
            is_season_item = bool(out.loc[idx_list[0], "_is_season"])
            if is_season_item and (not season_allowed):
                continue

            # ìì¬ë³„ burnë¥¼ FEFOë¡œ ë¶„ë°°
            burn_left = mat_burn

            for i in idx_list:
                # ìœ íš¨ê¸°ê°„ ì—†ëŠ” ë°°ì¹˜ëŠ” íŒë§¤ ë¶ˆê°€ë¡œ ì¹˜ê³  ìŠ¤í‚µ
                if not bool(out.at[i, "_has_exp"]):
                    continue

                # cutoff ì´í›„ë©´ íŒë§¤ ë¶ˆê°€
                cy = out.at[i, "_cut_y"]; cm = out.at[i, "_cut_m"]
                if pd.isna(cy) or pd.isna(cm):
                    continue
                cy = int(cy); cm = int(cm)
                if (yy > cy) or (yy == cy and mm > cm):
                    continue

                if burn_left <= 0:
                    break

                # ì´ ë°°ì¹˜ì—ì„œ ì†Œì§„
                use = min(remaining[i], burn_left)
                remaining[i] -= use
                burn_left -= use

                if burn_left <= 0:
                    break

        # ì›”ë§ ì”ì•¡ ê¸°ë¡(ìœ íš¨ê¸°ê°„ ìˆëŠ” ë°°ì¹˜ì—ë§Œ ê¸°ë¡)
        out.loc[out["_has_exp"], col] = remaining[out["_has_exp"].to_numpy()]

    # ì •ë¦¬ ì»¬ëŸ¼ ì œê±°ëŠ” ì„ íƒ (í•„ìš”í•˜ë©´ ì‚­ì œ)
    out = out.drop(columns=["_exp_dt","_has_exp","_cutoff_dt","_cut_y","_cut_m","_is_season"], errors="ignore")
    return out


# ======================================================
# 7) ë¶„ê¸° ì§‘ê³„í‘œ (ì¹´í…Œê³ ë¦¬ë³„ + KPI + ë¶„ê¸° ì”ì•¡)
#    - "ìì¬ ë‹¨ìœ„ ì¬ì§‘ê³„"ë¡œ ì¶œí•˜ì›ê°€/ì¶œí•˜íŒê°€ ì¤‘ë³µ ë¬¸ì œ ë°©ì§€
# ======================================================
def make_quarter_cols(start_year: int, end_year: int):
    cols = []
    for y in range(start_year, end_year + 1):
        yy = str(y)[-2:]
        for q in [1,2,3,4]:
            cols.append(f"{yy}ë…„ {q}Q")
    return cols

def build_category_quarter_table(
    df: pd.DataFrame,
    *,
    cat_cols=("ëŒ€ë¶„ë¥˜", "ì†Œë¶„ë¥˜"),
    value_col="ë¶€ì§„ì¬ê³ ëŸ‰",
    quarter_col="ë¶€ì§„ì¬ê³ ì§„ì…ë¶„ê¸°",
    start_year=2026,
    end_year=2028,
    cost_col="ê¸°ë§ ì¬ê³  ê¸ˆì•¡",
    qty_col="ê¸°ë§ ì¬ê³  ìˆ˜ëŸ‰",
    sales_col="í‰íŒ",
    sales_fallback_cols=("í‰íŒ * 1.38ë°°", "í‰íŒ"),
    cost_rate_col="ì›ê°€ìœ¨",
    ship_cost_col="ì¶œí•˜ì›ê°€",
    ship_price_col="ì¶œí•˜íŒê°€",
    mat_col="ìì¬",
):
    base = df.copy()
    quarter_cols = make_quarter_cols(start_year, end_year)

    if quarter_col not in base.columns:
        raise KeyError(f"'{quarter_col}' ì»¬ëŸ¼ ì—†ìŒ. columns={list(base.columns)}")

    base["_ë¶„ê¸°"] = base[quarter_col].where(base[quarter_col].isin(quarter_cols), pd.NA)

    # Pivot: ë¶„ê¸°ë³„ ë¶€ì§„ì¬ê³ ëŸ‰
    for c in [*cat_cols, value_col]:
        if c not in base.columns:
            raise KeyError(f"'{c}' ì»¬ëŸ¼ ì—†ìŒ. columns={list(base.columns)}")

    pivot_detail = (
        base.dropna(subset=["_ë¶„ê¸°"])
        .pivot_table(index=list(cat_cols), columns="_ë¶„ê¸°", values=value_col, aggfunc="sum", fill_value=0.0)
        .reindex(columns=quarter_cols, fill_value=0.0)
    )
    pivot_detail["í•©ê³„"] = pivot_detail.sum(axis=1)
    pivot_detail = pivot_detail.reset_index()

    # sales_col fallback
    if sales_col not in base.columns:
        found = next((c for c in sales_fallback_cols if c in base.columns), None)
        if found is None:
            hint = [c for c in base.columns if "í‰íŒ" in str(c)]
            raise KeyError(f"sales_col='{sales_col}'ë„ ì—†ê³  fallbackë„ ì—†ìŒ. í›„ë³´={hint}")
        sales_col = found

    # ìì¬ ë‹¨ìœ„ ì¬ì§‘ê³„
    for c in [mat_col, *cat_cols, cost_col, qty_col, sales_col, cost_rate_col]:
        if c not in base.columns:
            raise KeyError(f"'{c}' ì»¬ëŸ¼ ì—†ìŒ. columns={list(base.columns)}")

    tmp = base.copy()
    tmp[cost_col] = pd.to_numeric(tmp[cost_col], errors="coerce").fillna(0.0)
    tmp[qty_col] = pd.to_numeric(tmp[qty_col], errors="coerce").fillna(0.0)
    tmp[sales_col] = pd.to_numeric(tmp[sales_col], errors="coerce").fillna(0.0)
    tmp[cost_rate_col] = pd.to_numeric(tmp[cost_rate_col], errors="coerce").fillna(0.0)

    mat_agg = (
        tmp.groupby(mat_col, dropna=False)
        .agg(
            **{
                cat_cols[0]: (cat_cols[0], "first"),
                cat_cols[1]: (cat_cols[1], "first"),
                cost_col: (cost_col, "sum"),
                qty_col: (qty_col, "sum"),
                sales_col: (sales_col, "first"),
                cost_rate_col: (cost_rate_col, "first"),
            }
        )
        .reset_index()
    )

    mat_agg["_ì›ê°€ë‹¨ê°€"] = 0.0
    m_qty = mat_agg[qty_col] != 0
    mat_agg.loc[m_qty, "_ì›ê°€ë‹¨ê°€"] = mat_agg.loc[m_qty, cost_col] / mat_agg.loc[m_qty, qty_col]

    mat_agg[ship_cost_col] = mat_agg["_ì›ê°€ë‹¨ê°€"] * mat_agg[sales_col]

    mat_agg[ship_price_col] = 0.0
    m_rate = mat_agg[cost_rate_col] != 0
    mat_agg.loc[m_rate, ship_price_col] = mat_agg.loc[m_rate, ship_cost_col] / mat_agg.loc[m_rate, cost_rate_col]

    # ì¹´í…Œê³ ë¦¬ KPI
    kpi = (
        mat_agg.groupby(list(cat_cols), dropna=False)
        .agg(
            ì›ê°€=(cost_col, "sum"),
            ì¶œí•˜ì›ê°€=(ship_cost_col, "sum"),
            ì¶œí•˜íŒê°€=(ship_price_col, "sum"),
        )
        .reset_index()
    )

    kpi["íšŒì „ì›”"] = 0.0
    m_ship = kpi["ì¶œí•˜ì›ê°€"] != 0
    kpi.loc[m_ship, "íšŒì „ì›”"] = kpi.loc[m_ship, "ì›ê°€"] / kpi.loc[m_ship, "ì¶œí•˜ì›ê°€"]

    detail = kpi.merge(pivot_detail, on=list(cat_cols), how="left").fillna(0.0)

    # ëŒ€ë¶„ë¥˜ ì†Œê³„
    major_kpi = (
        mat_agg.groupby(cat_cols[0], dropna=False)
        .agg(
            ì›ê°€=(cost_col, "sum"),
            ì¶œí•˜ì›ê°€=(ship_cost_col, "sum"),
            ì¶œí•˜íŒê°€=(ship_price_col, "sum"),
        )
        .reset_index()
    )
    major_kpi["íšŒì „ì›”"] = 0.0
    m2 = major_kpi["ì¶œí•˜ì›ê°€"] != 0
    major_kpi.loc[m2, "íšŒì „ì›”"] = major_kpi.loc[m2, "ì›ê°€"] / major_kpi.loc[m2, "ì¶œí•˜ì›ê°€"]

    major_q = (
        base.dropna(subset=["_ë¶„ê¸°"])
        .groupby([cat_cols[0], "_ë¶„ê¸°"])[value_col]
        .sum()
        .unstack("_ë¶„ê¸°")
        .reindex(columns=quarter_cols, fill_value=0.0)
        .reset_index()
    )
    major_q["í•©ê³„"] = major_q[quarter_cols].sum(axis=1)

    major_tbl = major_kpi.merge(major_q, on=cat_cols[0], how="left").fillna(0.0)
    major_tbl[cat_cols[1]] = "ì†Œê³„"

    # ì´ê³„
    total_cost = mat_agg[cost_col].sum()
    total_ship_cost = mat_agg[ship_cost_col].sum()
    total = pd.DataFrame([{
        cat_cols[0]: "ì´ê³„",
        cat_cols[1]: "",
        "ì›ê°€": total_cost,
        "ì¶œí•˜ì›ê°€": total_ship_cost,
        "ì¶œí•˜íŒê°€": mat_agg[ship_price_col].sum(),
        "íšŒì „ì›”": (total_cost / total_ship_cost if total_ship_cost != 0 else 0),
        **{q: base.loc[base["_ë¶„ê¸°"] == q, value_col].sum() for q in quarter_cols},
        "í•©ê³„": base[value_col].sum()
    }])

    rows = [total]
    for d in major_tbl[cat_cols[0]].unique():
        rows.append(major_tbl[major_tbl[cat_cols[0]] == d])
        rows.append(detail[detail[cat_cols[0]] == d])

    final = pd.concat(rows, ignore_index=True)
    final = final[[*cat_cols, "ì›ê°€", "ì¶œí•˜ì›ê°€", "ì¶œí•˜íŒê°€", "íšŒì „ì›”", "í•©ê³„", *quarter_cols]]

    # ìƒì„¸í–‰ì—ì„œ ëŒ€ë¶„ë¥˜ ê³µë°± ì²˜ë¦¬
    major_name, sub_name = cat_cols[0], cat_cols[1]
    mask_detail = (final[major_name] != "ì´ê³„") & (final[sub_name] != "ì†Œê³„")
    final.loc[mask_detail, major_name] = ""

    return final

# ======================================================
# 8) cat_table ë¶™ì´ê¸°(ìµœì¢… ë³´ê³ ì„œ merged)
# ======================================================
def add_merge_keys(df: pd.DataFrame, major="ëŒ€ë¶„ë¥˜", sub="ì†Œë¶„ë¥˜") -> pd.DataFrame:
    out = df.copy()
    if "ì†Œë¶„" in out.columns and sub not in out.columns:
        out = out.rename(columns={"ì†Œë¶„": sub})
    if major not in out.columns or sub not in out.columns:
        raise ValueError(f"'{major}', '{sub}' ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤. í˜„ì¬ columns={list(out.columns)}")
    out["merge_major"] = out[major].replace("", np.nan).ffill()
    out["merge_sub"] = out[sub].fillna("")
    return out

def attach_cat_table(
    base_df: pd.DataFrame,
    cat_df: pd.DataFrame,
    *,
    prefix: str,
    drop_mode: str = "cost_price_only",   # "cost_price_only" / "cost_price_ship_turn"
    include_ship_cols: bool = True,
    major="ëŒ€ë¶„ë¥˜",
    sub="ì†Œë¶„ë¥˜",
) -> pd.DataFrame:
    ct = cat_df.copy()

    if drop_mode == "cost_price_ship_turn":
        drop_keywords = ["ì›ê°€", "íŒê°€", "ì¶œí•˜", "íšŒì „"]
        drop_cols = [c for c in ct.columns if any(k in c for k in drop_keywords)]
    elif drop_mode == "cost_price_only":
        def is_drop_col(c: str) -> bool:
            has_cost_price = ("ì›ê°€" in c) or ("íŒê°€" in c)
            if not has_cost_price:
                return False
            if include_ship_cols:
                is_ship = ("ì¶œí•˜" in c)
                return has_cost_price and (not is_ship)
            return True
        drop_cols = [c for c in ct.columns if is_drop_col(c)]
    else:
        raise ValueError("drop_modeëŠ” 'cost_price_only' ë˜ëŠ” 'cost_price_ship_turn'ë§Œ ê°€ëŠ¥í•©ë‹ˆë‹¤.")

    ct = ct.drop(columns=drop_cols, errors="ignore")

    ct = add_merge_keys(ct, major=major, sub=sub)
    value_cols = [c for c in ct.columns if c not in [major, sub, "merge_major", "merge_sub"]]
    ct_small = ct[["merge_major", "merge_sub"] + value_cols].copy()

    rename_map = {c: f"{prefix}_{c}" for c in value_cols}
    ct_small = ct_small.rename(columns=rename_map)
    renamed_cols = [rename_map[c] for c in value_cols]

    if ("merge_major" not in base_df.columns) or ("merge_sub" not in base_df.columns):
        raise ValueError("base_dfì— merge_major/merge_subê°€ ì—†ìŠµë‹ˆë‹¤. (dropí•˜ê¸° ì „ì— ë¶™ì—¬ì•¼ í•©ë‹ˆë‹¤)")

    tmp = base_df[["merge_major", "merge_sub"]].merge(
        ct_small, on=["merge_major", "merge_sub"], how="left"
    )
    tmp[renamed_cols] = tmp[renamed_cols].fillna(0)

    return pd.concat([base_df, tmp[renamed_cols]], axis=1)

# ======================================================
# 9) Data Load
# ======================================================
inv_df = pick_df(files_dict[INV_FILE]).copy()
cls_df = pick_df(files_dict[CLS_FILE]).copy()
rating_df = pick_df(files_dict[RATING_FILE]).copy()
cancel_df = pick_df(files_dict[CANCEL_FILE]).copy()

# ======================================================
# 10) Run: ìì‚¬ ë§¤í•‘ 2ì¢…(plain / x138) + (ì˜µì…˜) dedupë²„ì „
# ======================================================
mapped_self_plain = build_mapped_inventory_df(inv_df, cls_df, rating_df, rating_mode="plain", dedup_by_material=True)
mapped_self_x138  = build_mapped_inventory_df(inv_df, cls_df, rating_df, rating_mode="x138",  dedup_by_material=True)

# ì œì¡°ì‚¬ ë§¤í•‘ 2ì¢…(plain / x138)
mapped_manu_plain = build_mapped_cancel_po_df(cancel_df, cls_df, rating_df, rating_mode="plain", dedup_by_material=True)
mapped_manu_x138  = build_mapped_cancel_po_df(cancel_df, cls_df, rating_df, rating_mode="x138",  dedup_by_material=True)

st.subheader("âœ… ë§¤í•‘ ê²°ê³¼(ìƒ˜í”Œ)")
st.dataframe(mapped_self_plain.head(50), use_container_width=True)
st.dataframe(mapped_manu_plain.head(50), use_container_width=True)

# ======================================================
# 11) ëŒ€ë¶„ë¥˜ ì†Œê³„ ë¦¬í¬íŠ¸
# ======================================================
major_report_df = build_major_only_report_table(
    df_self=mapped_self_plain,
    df_manu=mapped_manu_plain,
    major_col="ëŒ€ë¶„ë¥˜",
    sub_col="ì†Œë¶„ë¥˜",
    self_name="ìì‚¬",
    manu_name="ì œì¡°ì‚¬",
)
st.subheader("ğŸ“Œ ëŒ€ë¶„ë¥˜ ì†Œê³„ í¬í•¨ í†µí•© ë¦¬í¬íŠ¸")
st.dataframe(major_report_df, use_container_width=True)

# ======================================================
# 12) ì‹œë®¬ë ˆì´ì…˜ ì¤€ë¹„ (ìì‚¬+ì œì¡°ì‚¬ / plain & x138 / ìì‚¬ë§Œ / ìì‚¬x138ë§Œ)
# ======================================================
season_codes = [
    "9305997","9307728","9307905","9307906","9308000","9308231",
    "9308427","9310455","9310878","9311190","9311191","9311719"
]

combined_plain = pd.concat([mapped_self_plain, mapped_manu_plain], ignore_index=True, sort=False)
combined_x138  = pd.concat([mapped_self_x138,  mapped_manu_x138],  ignore_index=True, sort=False)

# sim_plain = simulate_monthly_remaining_amount(
#     combined_plain, amount_col="ê¸°ë§ ì¬ê³  ê¸ˆì•¡", burn_col="ì¶œí•˜ì›ê°€",
#     season_mat_codes=season_codes, season_months=(5,6,7,8),
# )
# sim_plain = add_obsolete_cols_at_cutoff_6m(sim_plain)

# sim_x138 = simulate_monthly_remaining_amount(
#     combined_x138, amount_col="ê¸°ë§ ì¬ê³  ê¸ˆì•¡", burn_col="ì¶œí•˜ì›ê°€",
#     season_mat_codes=season_codes, season_months=(5,6,7,8),
# )
# sim_x138 = add_obsolete_cols_at_cutoff_6m(sim_x138)

# sim_self_plain = add_obsolete_cols_at_cutoff_6m(
#     simulate_monthly_remaining_amount(mapped_self_plain, season_mat_codes=season_codes, season_months=(5,6,7,8))
# )
# sim_self_x138 = add_obsolete_cols_at_cutoff_6m(
#     simulate_monthly_remaining_amount(mapped_self_x138, season_mat_codes=season_codes, season_months=(5,6,7,8))
# )

sim_plain = simulate_monthly_remaining_amount_fefo(
    combined_plain, amount_col="ê¸°ë§ ì¬ê³  ê¸ˆì•¡", burn_col="ì¶œí•˜ì›ê°€",
    season_mat_codes=season_codes, season_months=(5,6,7,8),
)

sim_x138 = simulate_monthly_remaining_amount_fefo(
    combined_x138, amount_col="ê¸°ë§ ì¬ê³  ê¸ˆì•¡", burn_col="ì¶œí•˜ì›ê°€",
    season_mat_codes=season_codes, season_months=(5,6,7,8),
)

sim_self_plain = simulate_monthly_remaining_amount_fefo(
    mapped_self_plain, amount_col="ê¸°ë§ ì¬ê³  ê¸ˆì•¡", burn_col="ì¶œí•˜ì›ê°€",
    season_mat_codes=season_codes, season_months=(5,6,7,8),
)

sim_self_x138 = simulate_monthly_remaining_amount_fefo(
    mapped_self_x138, amount_col="ê¸°ë§ ì¬ê³  ê¸ˆì•¡", burn_col="ì¶œí•˜ì›ê°€",
    season_mat_codes=season_codes, season_months=(5,6,7,8),
)
sim_plain = add_obsolete_cols_at_cutoff_6m(sim_plain)
sim_x138  = add_obsolete_cols_at_cutoff_6m(sim_x138)
sim_self_plain = add_obsolete_cols_at_cutoff_6m(sim_self_plain)
sim_self_x138  = add_obsolete_cols_at_cutoff_6m(sim_self_x138)


st.subheader("ğŸ“Œ ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼(ìš”ì•½)")
st.dataframe(sim_plain.head(30), use_container_width=True)
st.dataframe(sim_x138.head(30), use_container_width=True)

# ======================================================
# 13) ë¶„ê¸° ì§‘ê³„í‘œ 4ì¢…
# ======================================================
cat_table_plain = build_category_quarter_table(sim_plain, sales_col="í‰íŒ")
cat_table_x138  = build_category_quarter_table(sim_x138,  sales_col="í‰íŒ * 1.38ë°°")
cat_table_self_plain = build_category_quarter_table(sim_self_plain, sales_col="í‰íŒ")
cat_table_self_x138  = build_category_quarter_table(sim_self_x138,  sales_col="í‰íŒ * 1.38ë°°")

st.subheader("ğŸ“Š ë¶„ê¸° ì§‘ê³„í‘œ")
st.dataframe(cat_table_plain, use_container_width=True)
st.dataframe(cat_table_x138, use_container_width=True)

# ======================================================
# 14) major_report_df + cat_tableë“¤ì„ ì˜¤ë¥¸ìª½ì— ë¶™ì—¬ ìµœì¢… ë³´ê³ ì„œ ë§Œë“¤ê¸°
# ======================================================
mr = add_merge_keys(major_report_df, major="ëŒ€ë¶„ë¥˜", sub="ì†Œë¶„ë¥˜")

merged = attach_cat_table(
    base_df=mr, cat_df=cat_table_plain,
    prefix="ìì‚¬+ì œì¡°ì‚¬",
    drop_mode="cost_price_only",
    include_ship_cols=True
)

merged = attach_cat_table(
    base_df=merged, cat_df=cat_table_x138,
    prefix="ìì‚¬+ì œì¡°ì‚¬1.38ë°°",
    drop_mode="cost_price_only",
    include_ship_cols=True
)

merged = attach_cat_table(
    base_df=merged, cat_df=cat_table_self_plain,
    prefix="ìì‚¬",
    drop_mode="cost_price_only",
    include_ship_cols=True
)

merged = attach_cat_table(
    base_df=merged, cat_df=cat_table_self_x138,
    prefix="ìì‚¬1.38ë°°",
    drop_mode="cost_price_only",
    include_ship_cols=True
)

merged2 = merged.drop(columns=["merge_major", "merge_sub"], errors="ignore")

# 1ì–µ ë‹¨ìœ„ ë³€í™˜(ìˆ«ì ì»¬ëŸ¼ë§Œ / íšŒì „ í¬í•¨ ì œì™¸)
EOK = 100_000_000
num_cols = merged2.select_dtypes(include="number").columns.tolist()
num_cols = [c for c in num_cols if "íšŒì „" not in c]
merged2[num_cols] = merged2[num_cols] / EOK

st.subheader("ğŸ“Œ ë””ì—”ì½”ìŠ¤ë©”í‹±ìŠ¤ ë³´ìœ ì¬ê³  ìš´ì˜ ì‹œë®¬ë ˆì´ì…˜ ë³´ê³ ")
st.dataframe(merged2, use_container_width=True, height=900)

download_excel_openpyxl(
    merged2,
    filename="ë””ì—”ì½”ìŠ¤ë©”í‹±ìŠ¤ ë³´ìœ ì¬ê³  ìš´ì˜ ì‹œë®¬ë ˆì´ì…˜ ë³´ê³ .xlsx",
    sheet_name="MergedReport"
)
